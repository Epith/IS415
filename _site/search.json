[
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take-Home Exercise 1",
    "section": "",
    "text": "Millions of people have their lives shattered by armed conflict – wars – every year.\nArmed conflict has been on the rise since about 2012, after a decline in the 1990s and early 2000s. First came conflicts in Libya, Syria and Yemen, triggered by the 2011 Arab uprisings. Libya’s instability spilled south, helping set off a protracted crisis in the Sahel region. A fresh wave of major combat followed: the 2020 Azerbaijani-Armenian war over the Nagorno-Karabakh enclave, horrific fighting in Ethiopia’s northern Tigray region that began weeks later, the conflict prompted by the Myanmar army’s 2021 power grab and Russia’s 2022 assault on Ukraine. Add to those 2023’s devastation in Sudan and Gaza. Around the globe, more people are dying in fighting, being forced from their homes or in need of life-saving aid than in decades."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#background",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#background",
    "title": "Take-Home Exercise 1",
    "section": "",
    "text": "Millions of people have their lives shattered by armed conflict – wars – every year.\nArmed conflict has been on the rise since about 2012, after a decline in the 1990s and early 2000s. First came conflicts in Libya, Syria and Yemen, triggered by the 2011 Arab uprisings. Libya’s instability spilled south, helping set off a protracted crisis in the Sahel region. A fresh wave of major combat followed: the 2020 Azerbaijani-Armenian war over the Nagorno-Karabakh enclave, horrific fighting in Ethiopia’s northern Tigray region that began weeks later, the conflict prompted by the Myanmar army’s 2021 power grab and Russia’s 2022 assault on Ukraine. Add to those 2023’s devastation in Sudan and Gaza. Around the globe, more people are dying in fighting, being forced from their homes or in need of life-saving aid than in decades."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#objectives",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#objectives",
    "title": "Take-Home Exercise 1",
    "section": "Objectives",
    "text": "Objectives\nGeospatial analytics hold tremendous potential to address complex problems facing society. In this study, you are tasked to apply spatial point patterns analysis methods to discover the spatial and spatio-temporal distribution of armed conflict in Myanmar"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#dataset",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#dataset",
    "title": "Take-Home Exercise 1",
    "section": "Dataset",
    "text": "Dataset\nArmed conflict data of Myanmar between 2021-2024 from Armed Conflict Location & Event Data (ACLED)\nGeospatial data on Myanmar Information Management Unit, MIMU\nOpenStreetMap of Myanmar"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#packages",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#packages",
    "title": "Take-Home Exercise 1",
    "section": "Packages",
    "text": "Packages\nMost of the packages used are what is taught in class:\n\nsf (Simple Features): Provides tools for working with spatial vector data (points, lines, polygons) using simple features, a standardized way to store and process spatial data.\nraster: Handles spatial raster data (grids, images, or maps) and allows reading, writing, manipulating, and analyzing raster datasets.\nspatstat: Focuses on spatial point pattern analysis. It provides tools for analyzing and modeling the spatial distribution of points, like trees or crime locations.\ntmap: A visualization package for thematic maps. It makes creating static and interactive maps using spatial data intuitive, supporting both raster and vector data.\ntidyverse: A collection of packages designed for data manipulation, exploration, and visualization using a consistent syntax (e.g., ggplot2, dplyr, tidyr). It’s not specifically for spatial data but is often used in combination with spatial packages for data wrangling.\nsparr: Used for kernel density estimation and analysis of spatial point patterns, particularly for risk estimation and spatio temporal analysis.\nsp: Provides classes and methods for handling and analyzing spatial data in both vector and raster formats. It’s the predecessor to sf and raster, widely used before sf became the preferred package for vector data\n\n\npacman::p_load(sf, raster, spatstat, tmap, tidyverse,sparr,sp)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#import-the-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#import-the-data",
    "title": "Take-Home Exercise 1",
    "section": "Import the Data",
    "text": "Import the Data\n\nAspatial Data\nFirst step would be to import the armed conflict data which is in csv format, st_read will be used to read the csv file. In addition we are creating an additional column quarter, since we would need to know which quarter does an entry belong to. Luckily for us we can easily use quarter function on the event_date to know which quarter it belongs to. This package is found in lubridate package which is loaded in together with tidyverse. Note we have converted the CRS to Myanmar’s CRS at this point.\n\nacled_sf &lt;- st_read(\"data/ACLED_Myanmar.csv\") %&gt;%\n  st_as_sf(coords = c(\n    \"longitude\", \"latitude\"),\n    crs=4326) %&gt;%\n  st_transform(crs = 32647) %&gt;%\n  mutate(event_date = dmy(event_date),quarter = quarter(event_date))\n\nReading layer `ACLED_Myanmar' from data source \n  `C:\\SMU\\Y4S1\\IS415\\IS415\\Take-home_Ex\\Take-home_Ex01\\data\\ACLED_Myanmar.csv' \n  using driver `CSV'\n\n\nWarning: no simple feature geometries present: returning a data.frame or tbl_df\n\n\nNext I would like to split up the acled_sf into chucks for easier management of the data. I will split the data into chunks separating them by the different years 2021, 2022, 2023, 2024.\n\nacled_sf_2021 &lt;- acled_sf %&gt;%\n  filter(year == 2021)\n\nacled_sf_2022 &lt;- acled_sf %&gt;%\n  filter(year == 2022)\n\nacled_sf_2023 &lt;- acled_sf %&gt;%\n  filter(year == 2023)\n\nacled_sf_2024 &lt;- acled_sf %&gt;%\n  filter(year == 2024)\n\n\n\nSpatial Data\nNext is to import the boundary data of Myanmar, likewise st_read will be used. Note we have converted the CRS to Myanmars CRS at this point.\n\nmyanmar_sf &lt;- st_read(dsn=\"data/\",layer = \"mmr_polbnda2_adm1_250k_mimu_1\") %&gt;%\n  st_transform(crs=32647)\n\nReading layer `mmr_polbnda2_adm1_250k_mimu_1' from data source \n  `C:\\SMU\\Y4S1\\IS415\\IS415\\Take-home_Ex\\Take-home_Ex01\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 18 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.1721 ymin: 9.696844 xmax: 101.17 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\n\n\nmyanmar_sf\n\nSimple feature collection with 18 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -210008.6 ymin: 1072026 xmax: 724647.6 ymax: 3158467\nProjected CRS: WGS 84 / UTM zone 47N\nFirst 10 features:\n   OBJECTID          ST ST_PCODE  ST_RG               ST_MMR PCode_V\n1         1  Ayeyarwady   MMR017 Region       ဧရာဝတီတိုင်းဒေသကြီး     9.4\n2         2 Bago (East)   MMR007 Region   ပဲခူးတိုင်းဒေသကြီး (အရှေ့)     9.4\n3         3 Bago (West)   MMR008 Region ပဲခူးတိုင်းဒေသကြီး (အနောက်)     9.4\n4         4        Chin   MMR004  State            ချင်းပြည်နယ်     9.4\n5         5      Kachin   MMR001  State            ကချင်ပြည်နယ်     9.4\n6         6       Kayah   MMR002  State            ကယားပြည်နယ်     9.4\n7         7       Kayin   MMR003  State             ကရင်ပြည်နယ်     9.4\n8         8      Magway   MMR009 Region        မကွေးတိုင်းဒေသကြီး     9.4\n9         9    Mandalay   MMR010 Region      မန္တလေးတိုင်းဒေသကြီး     9.4\n10       10         Mon   MMR011  State              မွန်ပြည်နယ်     9.4\n                         geometry\n1  MULTIPOLYGON (((93411.72 17...\n2  MULTIPOLYGON (((203949.9 21...\n3  MULTIPOLYGON (((153405.1 21...\n4  MULTIPOLYGON (((-72918.03 2...\n5  MULTIPOLYGON (((362696.3 31...\n6  MULTIPOLYGON (((309155.7 22...\n7  MULTIPOLYGON (((373551.3 18...\n8  MULTIPOLYGON (((-1717.607 2...\n9  MULTIPOLYGON (((208184.3 26...\n10 MULTIPOLYGON (((364238.4 16...\n\n\nLooking at the data the only columns that seem interesting to me are OBJECTID, ST, ST_RG and geometry, so I will be only extracting those columns\n\nmyanmar_sf &lt;- myanmar_sf %&gt;% select('OBJECTID', 'ST', 'ST_RG', 'geometry')\nsummary(myanmar_sf)\n\n    OBJECTID          ST               ST_RG                    geometry \n Min.   : 1.00   Length:18          Length:18          MULTIPOLYGON :18  \n 1st Qu.: 5.25   Class :character   Class :character   epsg:32647   : 0  \n Median : 9.50   Mode  :character   Mode  :character   +proj=utm ...: 0  \n Mean   : 9.50                                                           \n 3rd Qu.:13.75                                                           \n Max.   :18.00                                                           \n\n\n\n\nOpenStreetMap\nNext is to import the OpenStreetMap of Myanmar st_read is used again\n\nosm = st_read(\"data/myanmar_osm.shp.zip\", layer=\"gis_osm_roads_free_1\")\n\nReading layer `gis_osm_roads_free_1' from data source \n  `C:\\SMU\\Y4S1\\IS415\\IS415\\Take-home_Ex\\Take-home_Ex01\\data\\myanmar_osm.shp.zip' \n  using driver `ESRI Shapefile'\nSimple feature collection with 558412 features and 10 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 92.13721 ymin: 9.783255 xmax: 101.2285 ymax: 28.37868\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-wrangling",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-wrangling",
    "title": "Take-Home Exercise 1",
    "section": "Data Wrangling",
    "text": "Data Wrangling\n\nCRS check\nFirst would be to check that acled_sf and myanmar_sf are in the correct projected system after crs transformation\n\nst_crs(acled_sf)\n\nCoordinate Reference System:\n  User input: EPSG:32647 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 47N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 47N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",99,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\"],\n        BBOX[0,96,84,102]],\n    ID[\"EPSG\",32647]]\n\nst_crs(acled_sf_2021)\n\nCoordinate Reference System:\n  User input: EPSG:32647 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 47N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 47N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",99,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\"],\n        BBOX[0,96,84,102]],\n    ID[\"EPSG\",32647]]\n\nst_crs(acled_sf_2022)\n\nCoordinate Reference System:\n  User input: EPSG:32647 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 47N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 47N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",99,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\"],\n        BBOX[0,96,84,102]],\n    ID[\"EPSG\",32647]]\n\nst_crs(acled_sf_2023)\n\nCoordinate Reference System:\n  User input: EPSG:32647 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 47N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 47N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",99,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\"],\n        BBOX[0,96,84,102]],\n    ID[\"EPSG\",32647]]\n\nst_crs(acled_sf_2024)\n\nCoordinate Reference System:\n  User input: EPSG:32647 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 47N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 47N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",99,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\"],\n        BBOX[0,96,84,102]],\n    ID[\"EPSG\",32647]]\n\nst_crs(myanmar_sf)\n\nCoordinate Reference System:\n  User input: EPSG:32647 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 47N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 47N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",99,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\"],\n        BBOX[0,96,84,102]],\n    ID[\"EPSG\",32647]]\n\n\n\n\nOpenStreetMap\nWorking with OpenStreetMap is something different as there were no in class tutorials on this, and in a sense its not really traditional GIS data as its all store in one big database. First step is to see what fields there is.\n\nosm\n\nSimple feature collection with 558412 features and 10 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 92.13721 ymin: 9.783255 xmax: 101.2285 ymax: 28.37868\nGeodetic CRS:  WGS 84\nFirst 10 features:\n    osm_id code       fclass              name  ref oneway maxspeed layer\n1  4360720 5113      primary         ကမ်းနားလမ်း &lt;NA&gt;      F       50     0\n2  4360721 5114    secondary San Da Koo Street &lt;NA&gt;      B        0     0\n3  4360722 5121 unclassified              &lt;NA&gt; &lt;NA&gt;      B        0     0\n4  4360723 5113      primary        မဟာဗန္ဓုလလမ်း &lt;NA&gt;      F       50     0\n5  4360725 5113      primary   Min Nandar Road &lt;NA&gt;      B       70     0\n6  4360727 5113      primary Maha Bandula Road &lt;NA&gt;      F        0     0\n7  4360728 5114    secondary              &lt;NA&gt; &lt;NA&gt;      F        0     0\n8  4360731 5113      primary        မဟာဗန္ဓုလလမ်း &lt;NA&gt;      F        0     0\n9  4360732 5114    secondary            စက်ရုံလမ်း &lt;NA&gt;      F        0     0\n10 4361462 5122  residential  Man Daing Street &lt;NA&gt;      B       20     0\n   bridge tunnel                       geometry\n1       F      F LINESTRING (96.14182 16.774...\n2       F      F LINESTRING (96.17792 16.769...\n3       F      F LINESTRING (96.17826 16.775...\n4       F      F LINESTRING (96.16004 16.774...\n5       F      F LINESTRING (96.19497 16.804...\n6       F      F LINESTRING (96.18572 16.782...\n7       F      F LINESTRING (96.18465 16.782...\n8       F      F LINESTRING (96.18582 16.782...\n9       F      F LINESTRING (96.17552 16.790...\n10      F      F LINESTRING (96.18204 16.782...\n\n\nThe interesting fields to me are osm_id and fclass, in one of the fclass entries it says residential which could be useful in plotting and distinguish where the conflicts take place. Looking into osm documentation, osm_id might not be useful for me, but for fclass there are many features some of the examples below. So lets expand on the fclass.\n\n\n\nunique(osm$fclass)\n\n [1] \"primary\"        \"secondary\"      \"unclassified\"   \"residential\"   \n [5] \"trunk_link\"     \"primary_link\"   \"tertiary\"       \"service\"       \n [9] \"footway\"        \"track\"          \"trunk\"          \"path\"          \n[13] \"living_street\"  \"track_grade4\"   \"secondary_link\" \"unknown\"       \n[17] \"track_grade5\"   \"motorway\"       \"steps\"          \"track_grade2\"  \n[21] \"track_grade1\"   \"track_grade3\"   \"tertiary_link\"  \"motorway_link\" \n[25] \"pedestrian\"     \"cycleway\"       \"bridleway\"     \n\n\nDue to the overwhelming size of the osm file and after reading the documentation I decided to keep a few of the interesting ones that could be helpful in my analysis\n\nroads &lt;- c(\"primary\", \"secondary\", \"residential\", \"trunk_link\", \"primary_link\", \"tertiary\", \"footway\", \"trunk\", \"secondary_link\", \"tertiary_link\")\n\nosm &lt;- osm[osm$fclass %in% roads, ]\n\n\nosm\n\nSimple feature collection with 277773 features and 10 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 92.13721 ymin: 9.94157 xmax: 101.1935 ymax: 28.0503\nGeodetic CRS:  WGS 84\nFirst 10 features:\n    osm_id code      fclass                 name  ref oneway maxspeed layer\n1  4360720 5113     primary            ကမ်းနားလမ်း &lt;NA&gt;      F       50     0\n2  4360721 5114   secondary    San Da Koo Street &lt;NA&gt;      B        0     0\n4  4360723 5113     primary           မဟာဗန္ဓုလလမ်း &lt;NA&gt;      F       50     0\n5  4360725 5113     primary      Min Nandar Road &lt;NA&gt;      B       70     0\n6  4360727 5113     primary    Maha Bandula Road &lt;NA&gt;      F        0     0\n7  4360728 5114   secondary                 &lt;NA&gt; &lt;NA&gt;      F        0     0\n8  4360731 5113     primary           မဟာဗန္ဓုလလမ်း &lt;NA&gt;      F        0     0\n9  4360732 5114   secondary               စက်ရုံလမ်း &lt;NA&gt;      F        0     0\n10 4361462 5122 residential     Man Daing Street &lt;NA&gt;      B       20     0\n11 4361463 5122 residential Seik Kan Thar Street &lt;NA&gt;      B        0     0\n   bridge tunnel                       geometry\n1       F      F LINESTRING (96.14182 16.774...\n2       F      F LINESTRING (96.17792 16.769...\n4       F      F LINESTRING (96.16004 16.774...\n5       F      F LINESTRING (96.19497 16.804...\n6       F      F LINESTRING (96.18572 16.782...\n7       F      F LINESTRING (96.18465 16.782...\n8       F      F LINESTRING (96.18582 16.782...\n9       F      F LINESTRING (96.17552 16.790...\n10      F      F LINESTRING (96.18204 16.782...\n11      F      F LINESTRING (96.18182 16.782...\n\n\nLet’s select only the useful columns that are interest of us, which is fclass, but let’s keep osm_id in case it there is a use case for it despite it having duplicates\n\nosm &lt;- osm %&gt;% select('osm_id', 'fclass')\n\nThe number of features have been greatly reduced, also before forgetting let’s transform osm CRS to Myanmars like for the previous 2 dataset\n\nosm &lt;- st_transform(osm, crs = 32647)\n\n\nst_crs(osm)\n\nCoordinate Reference System:\n  User input: EPSG:32647 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 47N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 47N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",99,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\"],\n        BBOX[0,96,84,102]],\n    ID[\"EPSG\",32647]]\n\n\n\nmerged_myanmar &lt;- st_union(myanmar_sf)\nosm_myanmar &lt;- st_intersection(osm, merged_myanmar)\n\n\nsummary(osm_myanmar)\n\nThere are some geometry in osm that is saved as MULTILINESTRING which could caused problems with KDE calculation, so let’s split it into individual LINESTRING\n\nosm_myanmar &lt;- st_cast(st_cast(osm_myanmar, \"MULTILINESTRING\"),\"LINESTRING\")\nsummary(osm_myanmar)\n\nLet’s save this data this data\n\nwrite_rds(osm_myanmar, \"data/rds/osm_myanmar.rds\")\n\n\n\nPPP object\nLet’s prepare to calculating the KDE by converting them into PPP objects\n\nacled_2021_Q1_ppp &lt;- acled_sf_2021 %&gt;% filter(quarter == 1) %&gt;% {as.ppp(st_coordinates(.),st_bbox(.))}\n\nWarning: data contain duplicated points\n\nacled_2021_Q2_ppp &lt;- acled_sf_2021 %&gt;% filter(quarter == 2) %&gt;% {as.ppp(st_coordinates(.),st_bbox(.))}\n\nWarning: data contain duplicated points\n\nacled_2021_Q3_ppp &lt;- acled_sf_2021 %&gt;% filter(quarter == 3) %&gt;% {as.ppp(st_coordinates(.),st_bbox(.))}\n\nWarning: data contain duplicated points\n\nacled_2021_Q4_ppp &lt;- acled_sf_2021 %&gt;% filter(quarter == 4) %&gt;% {as.ppp(st_coordinates(.),st_bbox(.))}\n\nWarning: data contain duplicated points\n\nacled_2022_Q1_ppp &lt;- acled_sf_2022 %&gt;% filter(quarter == 1) %&gt;% {as.ppp(st_coordinates(.),st_bbox(.))}\n\nWarning: data contain duplicated points\n\nacled_2022_Q2_ppp &lt;- acled_sf_2022 %&gt;% filter(quarter == 2) %&gt;% {as.ppp(st_coordinates(.),st_bbox(.))}\n\nWarning: data contain duplicated points\n\nacled_2022_Q3_ppp &lt;- acled_sf_2022 %&gt;% filter(quarter == 3) %&gt;% {as.ppp(st_coordinates(.),st_bbox(.))}\n\nWarning: data contain duplicated points\n\nacled_2022_Q4_ppp &lt;- acled_sf_2022 %&gt;% filter(quarter == 4) %&gt;% {as.ppp(st_coordinates(.),st_bbox(.))}\n\nWarning: data contain duplicated points\n\nacled_2023_Q1_ppp &lt;- acled_sf_2023 %&gt;% filter(quarter == 1) %&gt;% {as.ppp(st_coordinates(.),st_bbox(.))}\n\nWarning: data contain duplicated points\n\nacled_2023_Q2_ppp &lt;- acled_sf_2023 %&gt;% filter(quarter == 2) %&gt;% {as.ppp(st_coordinates(.),st_bbox(.))}\n\nWarning: data contain duplicated points\n\nacled_2023_Q3_ppp &lt;- acled_sf_2023 %&gt;% filter(quarter == 3) %&gt;% {as.ppp(st_coordinates(.),st_bbox(.))}\n\nWarning: data contain duplicated points\n\nacled_2023_Q4_ppp &lt;- acled_sf_2023 %&gt;% filter(quarter == 4) %&gt;% {as.ppp(st_coordinates(.),st_bbox(.))}\n\nWarning: data contain duplicated points\n\nacled_2024_Q1_ppp &lt;- acled_sf_2024 %&gt;% filter(quarter == 1) %&gt;% {as.ppp(st_coordinates(.),st_bbox(.))}\n\nWarning: data contain duplicated points\n\nacled_2024_Q2_ppp &lt;- acled_sf_2024 %&gt;% filter(quarter == 2) %&gt;% {as.ppp(st_coordinates(.),st_bbox(.))}\n\nWarning: data contain duplicated points\n\n\nIt gives us warnings about duplicated points so let’s remove them\n\nacled_2021_Q1_ppp &lt;- rjitter(acled_2021_Q1_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\nacled_2021_Q2_ppp &lt;- rjitter(acled_2021_Q2_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\nacled_2021_Q3_ppp &lt;- rjitter(acled_2021_Q3_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\nacled_2021_Q4_ppp &lt;- rjitter(acled_2021_Q4_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\nacled_2022_Q1_ppp &lt;- rjitter(acled_2022_Q1_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\nacled_2022_Q2_ppp &lt;- rjitter(acled_2022_Q2_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\nacled_2022_Q3_ppp &lt;- rjitter(acled_2022_Q3_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\nacled_2022_Q4_ppp &lt;- rjitter(acled_2022_Q4_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\nacled_2023_Q1_ppp &lt;- rjitter(acled_2023_Q1_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\nacled_2023_Q2_ppp &lt;- rjitter(acled_2023_Q2_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\nacled_2023_Q3_ppp &lt;- rjitter(acled_2023_Q3_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\nacled_2023_Q4_ppp &lt;- rjitter(acled_2023_Q4_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\nacled_2024_Q1_ppp &lt;- rjitter(acled_2024_Q1_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\nacled_2024_Q2_ppp &lt;- rjitter(acled_2024_Q2_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\nLet’s double check again to see if there are any duplicates\n\nany(duplicated(acled_2021_Q1_ppp))\n\n[1] FALSE\n\nany(duplicated(acled_2021_Q2_ppp))\n\n[1] FALSE\n\nany(duplicated(acled_2021_Q3_ppp))\n\n[1] FALSE\n\nany(duplicated(acled_2021_Q4_ppp))\n\n[1] FALSE\n\nany(duplicated(acled_2022_Q1_ppp))\n\n[1] FALSE\n\nany(duplicated(acled_2022_Q2_ppp))\n\n[1] FALSE\n\nany(duplicated(acled_2022_Q3_ppp))\n\n[1] FALSE\n\nany(duplicated(acled_2022_Q4_ppp))\n\n[1] FALSE\n\nany(duplicated(acled_2023_Q1_ppp))\n\n[1] FALSE\n\nany(duplicated(acled_2023_Q2_ppp))\n\n[1] FALSE\n\nany(duplicated(acled_2023_Q3_ppp))\n\n[1] FALSE\n\nany(duplicated(acled_2023_Q4_ppp))\n\n[1] FALSE\n\nany(duplicated(acled_2024_Q1_ppp))\n\n[1] FALSE\n\nany(duplicated(acled_2024_Q2_ppp))\n\n[1] FALSE\n\n\nLet’s create an OWIN object of Myanmar\n\nmyanmar_owin &lt;- as.owin(myanmar_sf)\n\n\nplot(myanmar_owin)\n\n\n\n\n\n\n\n\nThen let’s extract the different conflict events into the Myanmar owin object\n\nacledMyanmar_ppp_2021_Q1 = acled_2021_Q1_ppp[myanmar_owin]\nacledMyanmar_ppp_2021_Q2 = acled_2021_Q2_ppp[myanmar_owin]\nacledMyanmar_ppp_2021_Q3 = acled_2021_Q3_ppp[myanmar_owin]\nacledMyanmar_ppp_2021_Q4 = acled_2021_Q4_ppp[myanmar_owin]\nacledMyanmar_ppp_2022_Q1 = acled_2022_Q1_ppp[myanmar_owin]\nacledMyanmar_ppp_2022_Q2 = acled_2022_Q2_ppp[myanmar_owin]\nacledMyanmar_ppp_2022_Q3 = acled_2022_Q3_ppp[myanmar_owin]\nacledMyanmar_ppp_2022_Q4 = acled_2022_Q4_ppp[myanmar_owin]\nacledMyanmar_ppp_2023_Q1 = acled_2023_Q1_ppp[myanmar_owin]\nacledMyanmar_ppp_2023_Q2 = acled_2023_Q2_ppp[myanmar_owin]\nacledMyanmar_ppp_2023_Q3 = acled_2023_Q3_ppp[myanmar_owin]\nacledMyanmar_ppp_2023_Q4 = acled_2023_Q4_ppp[myanmar_owin]\nacledMyanmar_ppp_2024_Q1 = acled_2024_Q1_ppp[myanmar_owin]\nacledMyanmar_ppp_2024_Q2 = acled_2024_Q2_ppp[myanmar_owin]\n\nLet’s simply plot for this year 2024 to see what we have, not much can be seen on where most of the conflicts take place.\n\nplot(acledMyanmar_ppp_2024_Q1)\n\n\n\n\n\n\n\nplot(acledMyanmar_ppp_2024_Q2)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#quarterly-kde",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#quarterly-kde",
    "title": "Take-Home Exercise 1",
    "section": "Quarterly KDE",
    "text": "Quarterly KDE\nLet’s actually calculate the quarterly KDE for the different years now. First we would rescale the PPP into KM\n\nacledMyanmar_ppp_2021_Q1.km &lt;- rescale.ppp(acledMyanmar_ppp_2021_Q1, 1000, \"km\")\nacledMyanmar_ppp_2021_Q2.km &lt;- rescale.ppp(acledMyanmar_ppp_2021_Q2, 1000, \"km\")\nacledMyanmar_ppp_2021_Q3.km &lt;- rescale.ppp(acledMyanmar_ppp_2021_Q3, 1000, \"km\")\nacledMyanmar_ppp_2021_Q4.km &lt;- rescale.ppp(acledMyanmar_ppp_2021_Q4, 1000, \"km\")\nacledMyanmar_ppp_2022_Q1.km &lt;- rescale.ppp(acledMyanmar_ppp_2022_Q1, 1000, \"km\")\nacledMyanmar_ppp_2022_Q2.km &lt;- rescale.ppp(acledMyanmar_ppp_2022_Q2, 1000, \"km\")\nacledMyanmar_ppp_2022_Q3.km &lt;- rescale.ppp(acledMyanmar_ppp_2022_Q3, 1000, \"km\")\nacledMyanmar_ppp_2022_Q4.km &lt;- rescale.ppp(acledMyanmar_ppp_2022_Q4, 1000, \"km\")\nacledMyanmar_ppp_2023_Q1.km &lt;- rescale.ppp(acledMyanmar_ppp_2023_Q1, 1000, \"km\")\nacledMyanmar_ppp_2023_Q2.km &lt;- rescale.ppp(acledMyanmar_ppp_2023_Q2, 1000, \"km\")\nacledMyanmar_ppp_2023_Q3.km &lt;- rescale.ppp(acledMyanmar_ppp_2023_Q3, 1000, \"km\")\nacledMyanmar_ppp_2023_Q4.km &lt;- rescale.ppp(acledMyanmar_ppp_2023_Q4, 1000, \"km\")\nacledMyanmar_ppp_2024_Q1.km &lt;- rescale.ppp(acledMyanmar_ppp_2024_Q1, 1000, \"km\")\nacledMyanmar_ppp_2024_Q2.km &lt;- rescale.ppp(acledMyanmar_ppp_2024_Q2, 1000, \"km\")\n\nNow we can plot the KDE, lets do it for Q1 of 2021\n\nconflict.bw &lt;- density(acledMyanmar_ppp_2021_Q1.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\")\nplot(conflict.bw)\n\n\n\n\n\n\n\n\nThe map seems a bit dark, so I wanted to try other automatic sigma methods\n\nbw.CvLbw.pplbw.scott\n\n\n\nconflict.bw &lt;- density(acledMyanmar_ppp_2021_Q1.km, \n             sigma=bw.CvL, \n             edge=TRUE, \n             kernel=\"gaussian\")\nplot(conflict.bw)\n\n\n\n\n\n\n\n\n\n\n\nconflict.bw &lt;- density(acledMyanmar_ppp_2021_Q1.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"gaussian\")\nplot(conflict.bw)\n\n\n\n\n\n\n\n\n\n\n\nconflict.bw &lt;- density(acledMyanmar_ppp_2021_Q1.km, \n             sigma=bw.scott, \n             edge=TRUE, \n             kernel=\"gaussian\")\nplot(conflict.bw)\n\n\n\n\n\n\n\n\n\n\n\nLet’s try declaring our own sigma value\n\nSigma value 20Sigma Value 25Sigma Value 30\n\n\n\nconflict.bw &lt;- density(acledMyanmar_ppp_2021_Q1.km, \n             sigma=20, \n             edge=TRUE, \n             kernel=\"gaussian\")\nplot(conflict.bw)\n\n\n\n\n\n\n\n\n\n\n\nconflict.bw &lt;- density(acledMyanmar_ppp_2021_Q1.km, \n             sigma=25, \n             edge=TRUE, \n             kernel=\"gaussian\")\nplot(conflict.bw)\n\n\n\n\n\n\n\n\n\n\n\nconflict.bw &lt;- density(acledMyanmar_ppp_2021_Q1.km, \n             sigma=30, \n             edge=TRUE, \n             kernel=\"gaussian\")\nplot(conflict.bw)\n\n\n\n\n\n\n\n\n\n\n\nUltimately I think i will settle for sigma value of 25 and it seems to give the best results without over emphasizing the results.\nLet’s plot the quarterly KDE for the different years now\n\n2021202220232024\n\n\n\npar(mfrow=c(2,2), cex.main = 3.5)\nplot(density(acledMyanmar_ppp_2021_Q1.km, \n             sigma=25, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"2021 Q1\")\nplot(density(acledMyanmar_ppp_2021_Q2.km, \n             sigma=25, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"2021 Q2\")\nplot(density(acledMyanmar_ppp_2021_Q3.km, \n             sigma=25, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"2021 Q3\")\nplot(density(acledMyanmar_ppp_2021_Q4.km, \n             sigma=25, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"2021 Q4\")\n\n\n\n\n\n\n\n\n\n\n\npar(mfrow=c(2,2), cex.main = 3.5)\nplot(density(acledMyanmar_ppp_2022_Q1.km, \n             sigma=25, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"2022 Q1\")\nplot(density(acledMyanmar_ppp_2022_Q2.km, \n             sigma=25, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"2022 Q2\")\nplot(density(acledMyanmar_ppp_2022_Q3.km, \n             sigma=25, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"2022 Q3\")\nplot(density(acledMyanmar_ppp_2022_Q4.km, \n             sigma=25, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"2022 Q4\")\n\n\n\n\n\n\n\n\n\n\n\npar(mfrow=c(2,2), cex.main = 3.5)\nplot(density(acledMyanmar_ppp_2023_Q1.km, \n             sigma=25, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"2023 Q1\")\nplot(density(acledMyanmar_ppp_2023_Q2.km, \n             sigma=25, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"2023 Q2\")\nplot(density(acledMyanmar_ppp_2023_Q3.km, \n             sigma=25, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"2023 Q3\")\nplot(density(acledMyanmar_ppp_2023_Q4.km, \n             sigma=25, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"2023 Q4\")\n\n\n\n\n\n\n\n\n\n\n\npar(mfrow=c(1,2), cex.main = 3.5)\nplot(density(acledMyanmar_ppp_2024_Q1.km, \n             sigma=25, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"2024 Q1\")\nplot(density(acledMyanmar_ppp_2024_Q2.km, \n             sigma=25, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"2024 Q2\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#second-order-spatial-point-patterns-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#second-order-spatial-point-patterns-analysis",
    "title": "Take-Home Exercise 1",
    "section": "Second-order Spatial Point Patterns Analysis",
    "text": "Second-order Spatial Point Patterns Analysis\n\nScoped down owin object\nBased on the derived KDEs there is a lot of activities in the middle of Myanmar and according to https://www.citypopulation.de/en/myanmar/cities/\n\nMandalay is one of the highest population so let’s focus on it and it happens to be in our myanmar_sf boundary.\nLet’s filter to only get Madalay out of our myanmar_sf\n\nmandalay &lt;- myanmar_sf %&gt;%\n  filter(ST == \"Mandalay\")\n\nLet’s create a owin object out of mandalay\n\nmandalay_owin = as.owin(mandalay)\n\n\nplot(mandalay_owin)\n\n\n\n\n\n\n\n\n\n\nPPP object\nBefore converting the acled_sf into a ppp object, I would like to split up the data further to focus on four main event types: battles, explosion/remote violence, strategic developments, violence against civilians. Also further splitting it by the different years. Because by not doing this and performing 2nd order analysis we don’t know which are the events that are clustered or random dispersed. Also doing it for all the 4 years worth of data its bound to be clustered\n\nacled_ppp_battles_2021 &lt;- acled_sf_2021 %&gt;% filter(event_type == \"Battles\") %&gt;% {as.ppp(st_coordinates(.),st_bbox(.))}\n\nWarning: data contain duplicated points\n\nacled_ppp_battles_2022 &lt;- acled_sf_2022 %&gt;% filter(event_type == \"Battles\") %&gt;% {as.ppp(st_coordinates(.),st_bbox(.))}\n\nWarning: data contain duplicated points\n\nacled_ppp_battles_2023 &lt;- acled_sf_2023 %&gt;% filter(event_type == \"Battles\") %&gt;% {as.ppp(st_coordinates(.),st_bbox(.))}\n\nWarning: data contain duplicated points\n\nacled_ppp_battles_2024 &lt;- acled_sf_2024 %&gt;% filter(event_type == \"Battles\") %&gt;% {as.ppp(st_coordinates(.),st_bbox(.))}\n\nWarning: data contain duplicated points\n\nacled_ppp_explosion_2021 &lt;- acled_sf_2021 %&gt;% filter(event_type == \"Explosions/Remote violence\") %&gt;% {as.ppp(st_coordinates(.),st_bbox(.))}\n\nWarning: data contain duplicated points\n\nacled_ppp_explosion_2022 &lt;- acled_sf_2022 %&gt;% filter(event_type == \"Explosions/Remote violence\") %&gt;% {as.ppp(st_coordinates(.),st_bbox(.))}\n\nWarning: data contain duplicated points\n\nacled_ppp_explosion_2023 &lt;- acled_sf_2023 %&gt;% filter(event_type == \"Explosions/Remote violence\") %&gt;% {as.ppp(st_coordinates(.),st_bbox(.))}\n\nWarning: data contain duplicated points\n\nacled_ppp_explosion_2024 &lt;- acled_sf_2024 %&gt;% filter(event_type == \"Explosions/Remote violence\") %&gt;% {as.ppp(st_coordinates(.),st_bbox(.))}\n\nWarning: data contain duplicated points\n\nacled_ppp_strat_2021 &lt;- acled_sf_2021 %&gt;% filter(event_type == \"Strategic developments\") %&gt;% {as.ppp(st_coordinates(.),st_bbox(.))}\n\nWarning: data contain duplicated points\n\nacled_ppp_strat_2022 &lt;- acled_sf_2022 %&gt;% filter(event_type == \"Strategic developments\") %&gt;% {as.ppp(st_coordinates(.),st_bbox(.))}\n\nWarning: data contain duplicated points\n\nacled_ppp_strat_2023 &lt;- acled_sf_2023 %&gt;% filter(event_type == \"Strategic developments\") %&gt;% {as.ppp(st_coordinates(.),st_bbox(.))}\n\nWarning: data contain duplicated points\n\nacled_ppp_strat_2024 &lt;- acled_sf_2024 %&gt;% filter(event_type == \"Strategic developments\") %&gt;% {as.ppp(st_coordinates(.),st_bbox(.))}\n\nWarning: data contain duplicated points\n\nacled_ppp_violence_2021 &lt;- acled_sf_2021 %&gt;% filter(event_type == \"Violence against civilians\") %&gt;% {as.ppp(st_coordinates(.),st_bbox(.))}\n\nWarning: data contain duplicated points\n\nacled_ppp_violence_2022 &lt;- acled_sf_2022 %&gt;% filter(event_type == \"Violence against civilians\") %&gt;% {as.ppp(st_coordinates(.),st_bbox(.))}\n\nWarning: data contain duplicated points\n\nacled_ppp_violence_2023 &lt;- acled_sf_2023 %&gt;% filter(event_type == \"Violence against civilians\") %&gt;% {as.ppp(st_coordinates(.),st_bbox(.))}\n\nWarning: data contain duplicated points\n\nacled_ppp_violence_2024 &lt;- acled_sf_2024 %&gt;% filter(event_type == \"Violence against civilians\") %&gt;% {as.ppp(st_coordinates(.),st_bbox(.))}\n\nWarning: data contain duplicated points\n\n\nSince it gives us warnings of duplicated data let’s remove them\n\nacled_ppp_battles_2021 &lt;- rjitter(acled_ppp_battles_2021, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\nacled_ppp_battles_2022 &lt;- rjitter(acled_ppp_battles_2022, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\nacled_ppp_battles_2023 &lt;- rjitter(acled_ppp_battles_2023, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\nacled_ppp_battles_2024 &lt;- rjitter(acled_ppp_battles_2024, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\nacled_ppp_explosion_2021 &lt;- rjitter(acled_ppp_explosion_2021, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\nacled_ppp_explosion_2022 &lt;- rjitter(acled_ppp_explosion_2022, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\nacled_ppp_explosion_2023 &lt;- rjitter(acled_ppp_explosion_2023, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\nacled_ppp_explosion_2024 &lt;- rjitter(acled_ppp_explosion_2024, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\nacled_ppp_strat_2021 &lt;- rjitter(acled_ppp_strat_2021, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\nacled_ppp_strat_2022 &lt;- rjitter(acled_ppp_strat_2022, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\nacled_ppp_strat_2023 &lt;- rjitter(acled_ppp_strat_2023, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\nacled_ppp_strat_2024 &lt;- rjitter(acled_ppp_strat_2024, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\nacled_ppp_violence_2021 &lt;- rjitter(acled_ppp_violence_2021, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\nacled_ppp_violence_2022 &lt;- rjitter(acled_ppp_violence_2022, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\nacled_ppp_violence_2023 &lt;- rjitter(acled_ppp_violence_2023, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\nacled_ppp_violence_2024 &lt;- rjitter(acled_ppp_violence_2024, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nany(duplicated(acled_ppp_battles_2021))\n\n[1] FALSE\n\nany(duplicated(acled_ppp_battles_2022))\n\n[1] FALSE\n\nany(duplicated(acled_ppp_battles_2023))\n\n[1] FALSE\n\nany(duplicated(acled_ppp_battles_2024))\n\n[1] FALSE\n\nany(duplicated(acled_ppp_explosion_2021))\n\n[1] FALSE\n\nany(duplicated(acled_ppp_explosion_2022))\n\n[1] FALSE\n\nany(duplicated(acled_ppp_explosion_2023))\n\n[1] FALSE\n\nany(duplicated(acled_ppp_explosion_2024))\n\n[1] FALSE\n\nany(duplicated(acled_ppp_strat_2021))\n\n[1] FALSE\n\nany(duplicated(acled_ppp_strat_2022))\n\n[1] FALSE\n\nany(duplicated(acled_ppp_strat_2023))\n\n[1] FALSE\n\nany(duplicated(acled_ppp_strat_2024))\n\n[1] FALSE\n\nany(duplicated(acled_ppp_violence_2021))\n\n[1] FALSE\n\nany(duplicated(acled_ppp_violence_2022))\n\n[1] FALSE\n\nany(duplicated(acled_ppp_violence_2023))\n\n[1] FALSE\n\nany(duplicated(acled_ppp_violence_2024))\n\n[1] FALSE\n\n\nGreat there’s no more duplicates, next let’s combine the ppp object by event types with the mandalay owin that we have created\n\nacledMyanmar_ppp_mandalay_battles_2021 = acled_ppp_battles_2021[mandalay_owin]\nacledMyanmar_ppp_mandalay_battles_2022 = acled_ppp_battles_2022[mandalay_owin]\nacledMyanmar_ppp_mandalay_battles_2023 = acled_ppp_battles_2023[mandalay_owin]\nacledMyanmar_ppp_mandalay_battles_2024 = acled_ppp_battles_2024[mandalay_owin]\n\n\nacledMyanmar_ppp_mandalay_explosion_2021 = acled_ppp_explosion_2021[mandalay_owin]\nacledMyanmar_ppp_mandalay_explosion_2022 = acled_ppp_explosion_2022[mandalay_owin]\nacledMyanmar_ppp_mandalay_explosion_2023 = acled_ppp_explosion_2023[mandalay_owin]\nacledMyanmar_ppp_mandalay_explosion_2024 = acled_ppp_explosion_2024[mandalay_owin]\n\nacledMyanmar_ppp_mandalay_strat_2021 = acled_ppp_strat_2021[mandalay_owin]\nacledMyanmar_ppp_mandalay_strat_2022 = acled_ppp_strat_2022[mandalay_owin]\nacledMyanmar_ppp_mandalay_strat_2023 = acled_ppp_strat_2023[mandalay_owin]\nacledMyanmar_ppp_mandalay_strat_2024 = acled_ppp_strat_2024[mandalay_owin]\n\nacledMyanmar_ppp_mandalay_violence_2021 = acled_ppp_violence_2021[mandalay_owin]\nacledMyanmar_ppp_mandalay_violence_2022 = acled_ppp_violence_2021[mandalay_owin]\nacledMyanmar_ppp_mandalay_violence_2023 = acled_ppp_violence_2021[mandalay_owin]\nacledMyanmar_ppp_mandalay_violence_2024 = acled_ppp_violence_2021[mandalay_owin]\n\nI will be using G function for my 2nd Order Analysis as it could help to determine clustering tendencies.\n\nBattles\n\n2021202220232024\n\n\n\nG_battles_2021 = Gest(acledMyanmar_ppp_mandalay_battles_2021, correction = \"border\")\nplot(G_battles_2021, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n\nG_battles_2022 = Gest(acledMyanmar_ppp_mandalay_battles_2022, correction = \"border\")\nplot(G_battles_2022, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n\nG_battles_2023 = Gest(acledMyanmar_ppp_mandalay_battles_2023, correction = \"border\")\nplot(G_battles_2023, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n\nG_battles_2024 = Gest(acledMyanmar_ppp_mandalay_battles_2024, correction = \"border\")\nplot(G_battles_2024, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n\n\n\nExplosion/Remote Violence\n\n2021202220232024\n\n\n\nG_explosion_2021 = Gest(acledMyanmar_ppp_mandalay_explosion_2021, correction = \"border\")\nplot(G_explosion_2021, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n\nG_explosion_2022 = Gest(acledMyanmar_ppp_mandalay_explosion_2022, correction = \"border\")\nplot(G_explosion_2022, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n\nG_explosion_2023 = Gest(acledMyanmar_ppp_mandalay_explosion_2023, correction = \"border\")\nplot(G_explosion_2023, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n\nG_explosion_2024 = Gest(acledMyanmar_ppp_mandalay_explosion_2024, correction = \"border\")\nplot(G_explosion_2024, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n\n\n\nStrategic Developments\n\n2021202220232024\n\n\n\nG_strat_2021 = Gest(acledMyanmar_ppp_mandalay_strat_2021, correction = \"border\")\nplot(G_strat_2021, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n\nG_strat_2022 = Gest(acledMyanmar_ppp_mandalay_strat_2022, correction = \"border\")\nplot(G_strat_2022, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n\nG_strat_2023 = Gest(acledMyanmar_ppp_mandalay_strat_2023, correction = \"border\")\nplot(G_strat_2023, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n\nG_strat_2024 = Gest(acledMyanmar_ppp_mandalay_strat_2024, correction = \"border\")\nplot(G_strat_2024, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n\n\n\nViolence against civilians\n\n2021202220232024\n\n\n\nG_violence_2021 = Gest(acledMyanmar_ppp_mandalay_violence_2021, correction = \"border\")\nplot(G_violence_2021, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n\nG_violence_2022 = Gest(acledMyanmar_ppp_mandalay_violence_2022, correction = \"border\")\nplot(G_violence_2022, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n\nG_violence_2023 = Gest(acledMyanmar_ppp_mandalay_violence_2023, correction = \"border\")\nplot(G_violence_2023, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n\nG_violence_2024 = Gest(acledMyanmar_ppp_mandalay_violence_2024, correction = \"border\")\nplot(G_violence_2024, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\nTo see if the the different event types are cluster or randomly dispersed. The hypothesis and test are as follows:\nHo = The distribution of a certain event at Mandalay region are randomly distributed.\nH1 = The distribution of a certain event at Mandalay region are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\n\nBattles\n\n2021202220232024\n\n\n\nG_battles_2021.csr &lt;- envelope(acledMyanmar_ppp_mandalay_battles_2021, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(G_battles_2021.csr)\n\n\n\n\n\n\n\n\n\n\n\nG_battles_2022.csr &lt;- envelope(acledMyanmar_ppp_mandalay_battles_2022, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(G_battles_2022.csr)\n\n\n\n\n\n\n\n\n\n\n\nG_battles_2023.csr &lt;- envelope(acledMyanmar_ppp_mandalay_battles_2023, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(G_battles_2023.csr)\n\n\n\n\n\n\n\n\n\n\n\nG_battles_2024.csr &lt;- envelope(acledMyanmar_ppp_mandalay_battles_2024, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(G_battles_2024.csr)\n\n\n\n\n\n\n\n\n\n\n\nFor 2021 and 2022, the points are generally clustered however towards the end there are signs to show that there are some homogeneous distribution with it being in the envelope. For the year 2023 and 2024 it is generally clustered as it falls above the envelope however for 2024 there some points of homogeneous distribution due to it falling inside the envelope.\n\n\nExplosion/Remote violence\n\n2021202220232024\n\n\n\nG_explosion_2021.csr &lt;- envelope(acledMyanmar_ppp_mandalay_explosion_2021, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(G_explosion_2021.csr)\n\n\n\n\n\n\n\n\n\n\n\nG_explosion_2022.csr &lt;- envelope(acledMyanmar_ppp_mandalay_explosion_2022, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(G_explosion_2022.csr)\n\n\n\n\n\n\n\n\n\n\n\nG_explosion_2023.csr &lt;- envelope(acledMyanmar_ppp_mandalay_explosion_2023, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(G_explosion_2023.csr)\n\n\n\n\n\n\n\n\n\n\n\nG_explosion_2024.csr &lt;- envelope(acledMyanmar_ppp_mandalay_explosion_2024, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(G_explosion_2024.csr)\n\n\n\n\n\n\n\n\n\n\n\nFor 2021-2023 it is generally clustered as it fals above the envelope however for 2024 there were some signs of homogeneous distribution where it falls within the envelope however it is still a clustered distribution\n\n\nStrategic Developments\n\n2021202220232024\n\n\n\nG_strat_2021.csr &lt;- envelope(acledMyanmar_ppp_mandalay_strat_2021, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(G_strat_2021.csr)\n\n\n\n\n\n\n\n\n\n\n\nG_strat_2022.csr &lt;- envelope(acledMyanmar_ppp_mandalay_strat_2022, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(G_strat_2022.csr)\n\n\n\n\n\n\n\n\n\n\n\nG_strat_2023.csr &lt;- envelope(acledMyanmar_ppp_mandalay_strat_2023, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(G_strat_2023.csr)\n\n\n\n\n\n\n\n\n\n\n\nG_strat_2024.csr &lt;- envelope(acledMyanmar_ppp_mandalay_strat_2024, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(G_strat_2024.csr)\n\n\n\n\n\n\n\n\n\n\n\nFor all the years it is generally a clustered distribution due to it being above the envelope\n\n\nViolence against civilians\n\n2021202220232024\n\n\n\nG_violence_2021.csr &lt;- envelope(acledMyanmar_ppp_mandalay_violence_2021, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(G_violence_2021.csr)\n\n\n\n\n\n\n\n\n\n\n\nG_violence_2022.csr &lt;- envelope(acledMyanmar_ppp_mandalay_violence_2022, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(G_violence_2022.csr)\n\n\n\n\n\n\n\n\n\n\n\nG_violence_2023.csr &lt;- envelope(acledMyanmar_ppp_mandalay_violence_2023, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(G_violence_2023.csr)\n\n\n\n\n\n\n\n\n\n\n\nG_violence_2024.csr &lt;- envelope(acledMyanmar_ppp_mandalay_violence_2024, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(G_violence_2024.csr)\n\n\n\n\n\n\n\n\n\n\n\nFor all the years it is generally a clustered distribution due to it being above the envelope"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#computing-stkde-by-quarters",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#computing-stkde-by-quarters",
    "title": "Take-Home Exercise 1",
    "section": "Computing STKDE by quarters",
    "text": "Computing STKDE by quarters\nFor computing STKDE let’s split the acled_sf data that I have split by the years and selecting the quarter column, as we don’t the other other unwanted fields and only the mark field\n\nconflict_quarter_2021 &lt;- acled_sf_2021 %&gt;% \n  select(quarter)\n\nconflict_quarter_2022 &lt;- acled_sf_2022 %&gt;% \n  select(quarter)\n\nconflict_quarter_2023 &lt;- acled_sf_2023 %&gt;% \n  select(quarter)\n\nconflict_quarter_2024 &lt;- acled_sf_2024 %&gt;% \n  select(quarter)\n\n\nPPP object\nNext is to convert the different simple frames into ppp objects\n\nconflict_quarter_ppp_2021 &lt;- as.ppp(conflict_quarter_2021)\n\nconflict_quarter_ppp_2022 &lt;- as.ppp(conflict_quarter_2022)\n\nconflict_quarter_ppp_2023 &lt;- as.ppp(conflict_quarter_2023)\n\nconflict_quarter_ppp_2024 &lt;- as.ppp(conflict_quarter_2024)\n\nLet’s check for any duplicates in the data\n\nany(duplicated(conflict_quarter_ppp_2021))\n\n[1] TRUE\n\nany(duplicated(conflict_quarter_ppp_2022))\n\n[1] TRUE\n\nany(duplicated(conflict_quarter_ppp_2023))\n\n[1] TRUE\n\nany(duplicated(conflict_quarter_ppp_2024))\n\n[1] TRUE\n\n\nSince there are duplicates let’s perform jitter to remove them\n\nconflict_quarter_ppp_2021 &lt;- rjitter(conflict_quarter_ppp_2021, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\nconflict_quarter_ppp_2022 &lt;- rjitter(conflict_quarter_ppp_2022, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\nconflict_quarter_ppp_2023 &lt;- rjitter(conflict_quarter_ppp_2023, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\nconflict_quarter_ppp_2024 &lt;- rjitter(conflict_quarter_ppp_2024, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\nChecking for duplicates again\n\nany(duplicated(conflict_quarter_ppp_2021))\n\n[1] FALSE\n\nany(duplicated(conflict_quarter_ppp_2022))\n\n[1] FALSE\n\nany(duplicated(conflict_quarter_ppp_2023))\n\n[1] FALSE\n\nany(duplicated(conflict_quarter_ppp_2024))\n\n[1] FALSE\n\n\nGreat now that there are no duplicates let’s combine the myanmar_owin we created earlier from earlier section with the newly created ppp objects\n\nconflict_quarter_owin_2021 &lt;- conflict_quarter_ppp_2021[myanmar_owin]\n\nconflict_quarter_owin_2022 &lt;- conflict_quarter_ppp_2022[myanmar_owin]\n\nconflict_quarter_owin_2023 &lt;- conflict_quarter_ppp_2023[myanmar_owin]\n\nconflict_quarter_owin_2024 &lt;- conflict_quarter_ppp_2024[myanmar_owin]\n\nLet’s plot it out to see the correctness of the data\n\nplot(conflict_quarter_owin_2021)\n\n\n\n\n\n\n\nplot(conflict_quarter_owin_2022)\n\n\n\n\n\n\n\nplot(conflict_quarter_owin_2023)\n\n\n\n\n\n\n\nplot(conflict_quarter_owin_2024)\n\n\n\n\n\n\n\n\n\n\nSTKDE\nNow to actually compute the STKDE as from the previous plot everything is looking, we will be using spattemp.density\n\n2021202220232024\n\n\n\nconflict_kde_2021 &lt;- spattemp.density(conflict_quarter_owin_2021)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nsummary(conflict_kde_2021)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 50227.29 (spatial)\n  lambda = 0.0013 (temporal)\n\nNo. of observations\n  16201 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [-210008.6, 724647.6] x [1072026, 3158467]\n\nTemporal bound\n  [1, 4]\n\nEvaluation\n  128 x 128 x 4 trivariate lattice\n  Density range: [7.327186e-14, 2.151153e-09]\n\n\n\n\n\nconflict_kde_2022 &lt;- spattemp.density(conflict_quarter_owin_2022)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nsummary(conflict_kde_2022)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 45138.17 (spatial)\n  lambda = 0.0014 (temporal)\n\nNo. of observations\n  15889 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [-210008.6, 724647.6] x [1072026, 3158467]\n\nTemporal bound\n  [1, 4]\n\nEvaluation\n  128 x 128 x 4 trivariate lattice\n  Density range: [7.782675e-18, 2.242807e-09]\n\n\n\n\n\nconflict_kde_2023 &lt;- spattemp.density(conflict_quarter_owin_2023)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nsummary(conflict_kde_2023)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 53221.25 (spatial)\n  lambda = 0.0017 (temporal)\n\nNo. of observations\n  13183 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [-210008.6, 724647.6] x [1072026, 3158467]\n\nTemporal bound\n  [1, 4]\n\nEvaluation\n  128 x 128 x 4 trivariate lattice\n  Density range: [4.966659e-20, 1.527295e-09]\n\n\n\n\n\nconflict_kde_2024 &lt;- spattemp.density(conflict_quarter_owin_2024)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nsummary(conflict_kde_2024)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 64168.77 (spatial)\n  lambda = 8e-04 (temporal)\n\nNo. of observations\n  5986 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [-210008.6, 724647.6] x [1072026, 3158467]\n\nTemporal bound\n  [1, 2]\n\nEvaluation\n  128 x 128 x 2 trivariate lattice\n  Density range: [9.766716e-13, 4.460034e-09]\n\n\n\n\n\nNow let’s plot the graphs for the computed STKDE\n\n2021202220232024\n\n\n\ntims &lt;- c(1,2,3,4)\n\npar(mfrow=c(1,4), cex.main = 1.5)\nfor(i in tims){\n  plot(conflict_kde_2021, i, \n       fix.range=TRUE,\n       override.par=FALSE,\n       main=paste(\"STKDE Q\",i))\n}\n\n\n\n\n\n\n\n\n\n\n\npar(mfrow=c(1,4), cex.main = 1.5)\nfor(i in tims){\n  plot(conflict_kde_2022, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"STKDE Q\",i))\n}\n\n\n\n\n\n\n\n\n\n\n\npar(mfrow=c(1,4),cex.main = 1.5)\n\nfor(i in tims){\n  plot(conflict_kde_2023, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"STKDE Q\",i))\n}\n\n\n\n\n\n\n\n\n\n\n\ntims_2 &lt;- c(1,2)\n\npar(mfrow=c(1,2), cex.main = 1.2)\nfor(i in tims_2){\n  plot(conflict_kde_2024, i, \n       override.par=FALSE, \n       fix.range=TRUE,\n       main=paste(\"STKDE Q\",i))\n}"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#nd-order-stkde-by-quarters",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#nd-order-stkde-by-quarters",
    "title": "Take-Home Exercise 1",
    "section": "7.0 2nd Order STKDE by quarters",
    "text": "7.0 2nd Order STKDE by quarters\n\n#conflict_quarter &lt;- acled_sf %&gt;% \n#  select(quarter)\n#conflict_quarter_ppp &lt;- as.ppp(conflict_quarter)\n\n\n#conflict_quarter_ppp &lt;- rjitter(conflict_quarter_ppp, \n#                             retry=TRUE, \n#                             nsim=1, \n#                             drop=TRUE)\n\n\n#any(duplicated(conflict_quarter_ppp))\n\n\n#acledConflictMyanmar_ppp_mandalay = conflict_quarter_ppp[mandalay_owin]\n\n\n#G_CK_conflict = Gest(acledConflictMyanmar_ppp_mandalay, correction = \"border\")\n\n#plot(G_CK_conflict, xlim=c(0,500))\n\n\n#G_CK_conflict.csr &lt;- envelope(acledConflictMyanmar_ppp_mandalay, Gest, nsim = 999)\n\n\n#plot(G_CK_conflict.csr)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "title": "In Class Exercise 5",
    "section": "",
    "text": "Geographically weighted summary statistics with adaptive bandwidth\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr, GWmodel)\n\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\n\nhunan &lt;- left_join(hunan,hunan2012) %&gt;%\n  select(1:3,7,15,16,31,32)\n\n\nwrite_rds(hunan, \"data/rds/hunan.rds\")\n\n\nhunan_sp &lt;- hunan %&gt;%\n  as_Spatial()\n\n\nbw_AIC &lt;- bw.gwr(GDPPC ~ 1,\n                 data = hunan_sp,\n                 approach=\"AIC\",\n                 adaptive = TRUE,\n                 kernel = \"bisquare\",\n                 longlat = T)\n\nAdaptive bandwidth (number of nearest neighbours): 62 AICc value: 1923.156 \nAdaptive bandwidth (number of nearest neighbours): 46 AICc value: 1920.469 \nAdaptive bandwidth (number of nearest neighbours): 36 AICc value: 1917.324 \nAdaptive bandwidth (number of nearest neighbours): 29 AICc value: 1916.661 \nAdaptive bandwidth (number of nearest neighbours): 26 AICc value: 1914.897 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \n\n\n\nbw_CV &lt;- bw.gwr(GDPPC ~ 1,\n                 data = hunan_sp,\n                 approach=\"CV\",\n                 adaptive = TRUE,\n                 kernel = \"bisquare\",\n                 longlat = T)\n\nAdaptive bandwidth: 62 CV score: 15515442343 \nAdaptive bandwidth: 46 CV score: 14937956887 \nAdaptive bandwidth: 36 CV score: 14408561608 \nAdaptive bandwidth: 29 CV score: 14198527496 \nAdaptive bandwidth: 26 CV score: 13898800611 \nAdaptive bandwidth: 22 CV score: 13662299974 \nAdaptive bandwidth: 22 CV score: 13662299974 \n\n\n\nbw_CV_fixed &lt;- bw.gwr(GDPPC ~ 1,\n                 data = hunan_sp,\n                 approach=\"CV\",\n                 adaptive = FALSE,\n                 kernel = \"bisquare\",\n                 longlat = T)\n\nFixed bandwidth: 357.4897 CV score: 16265191728 \nFixed bandwidth: 220.985 CV score: 14954930931 \nFixed bandwidth: 136.6204 CV score: 14134185837 \nFixed bandwidth: 84.48025 CV score: 13693362460 \nFixed bandwidth: 52.25585 CV score: Inf \nFixed bandwidth: 104.396 CV score: 13891052305 \nFixed bandwidth: 72.17162 CV score: 13577893677 \nFixed bandwidth: 64.56447 CV score: 14681160609 \nFixed bandwidth: 76.8731 CV score: 13444716890 \nFixed bandwidth: 79.77877 CV score: 13503296834 \nFixed bandwidth: 75.07729 CV score: 13452450771 \nFixed bandwidth: 77.98296 CV score: 13457916138 \nFixed bandwidth: 76.18716 CV score: 13442911302 \nFixed bandwidth: 75.76323 CV score: 13444600639 \nFixed bandwidth: 76.44916 CV score: 13442994078 \nFixed bandwidth: 76.02523 CV score: 13443285248 \nFixed bandwidth: 76.28724 CV score: 13442844774 \nFixed bandwidth: 76.34909 CV score: 13442864995 \nFixed bandwidth: 76.24901 CV score: 13442855596 \nFixed bandwidth: 76.31086 CV score: 13442847019 \nFixed bandwidth: 76.27264 CV score: 13442846793 \nFixed bandwidth: 76.29626 CV score: 13442844829 \nFixed bandwidth: 76.28166 CV score: 13442845238 \nFixed bandwidth: 76.29068 CV score: 13442844678 \nFixed bandwidth: 76.29281 CV score: 13442844691 \nFixed bandwidth: 76.28937 CV score: 13442844698 \nFixed bandwidth: 76.2915 CV score: 13442844676 \nFixed bandwidth: 76.292 CV score: 13442844679 \nFixed bandwidth: 76.29119 CV score: 13442844676 \nFixed bandwidth: 76.29099 CV score: 13442844676 \nFixed bandwidth: 76.29131 CV score: 13442844676 \nFixed bandwidth: 76.29138 CV score: 13442844676 \nFixed bandwidth: 76.29126 CV score: 13442844676 \nFixed bandwidth: 76.29123 CV score: 13442844676 \n\n\n\nbw_AIC_fixed &lt;- bw.gwr(GDPPC ~ 1,\n                 data = hunan_sp,\n                 approach=\"AIC\",\n                 adaptive = FALSE,\n                 kernel = \"bisquare\",\n                 longlat = T)\n\nFixed bandwidth: 357.4897 AICc value: 1927.631 \nFixed bandwidth: 220.985 AICc value: 1921.547 \nFixed bandwidth: 136.6204 AICc value: 1919.993 \nFixed bandwidth: 84.48025 AICc value: 1940.603 \nFixed bandwidth: 168.8448 AICc value: 1919.457 \nFixed bandwidth: 188.7606 AICc value: 1920.007 \nFixed bandwidth: 156.5362 AICc value: 1919.41 \nFixed bandwidth: 148.929 AICc value: 1919.527 \nFixed bandwidth: 161.2377 AICc value: 1919.392 \nFixed bandwidth: 164.1433 AICc value: 1919.403 \nFixed bandwidth: 159.4419 AICc value: 1919.393 \nFixed bandwidth: 162.3475 AICc value: 1919.394 \nFixed bandwidth: 160.5517 AICc value: 1919.391 \n\n\nComputing geographically weighted summary statistics\n\ngwstat &lt;- gwss(data= hunan_sp,\n               vars = \"GDPPC\",\n               bw = bw_AIC,\n               kernel = \"bisquare\",\n               adaptive = TRUE,\n               longlat = T)\n\nPrepare the output data\n\ngwstat_df &lt;- as.data.frame(gwstat$SDF)\n\n\nhunan_gstat &lt;- cbind(hunan, gwstat_df)\n\n\ntm_shape(hunan_gstat) +\n  tm_fill(\"GDPPC_LM\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Distributation of geographically weighted mean\",\n            main.title.position = \"center\",\n            main.title.size = 2.0,\n            legend.text.size = 1.2,\n            legend.height = 1.5,\n            legend.width = 1.5,\n            frame= TRUE)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/data/rawdata/Kepulauan_Bangka_Belitung.html",
    "href": "In-class_Ex/In-class_Ex04/data/rawdata/Kepulauan_Bangka_Belitung.html",
    "title": "IS415",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     \n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "title": "In class exercise 2",
    "section": "",
    "text": "pacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#getting-started",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#getting-started",
    "title": "In class exercise 2",
    "section": "",
    "text": "pacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#importing-the-data-into-r",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#importing-the-data-into-r",
    "title": "In class exercise 2",
    "section": "2.0 Importing the data into R",
    "text": "2.0 Importing the data into R\nMaster Plan 2014 Subzone Boundary (Web) (SHP)\nMaster Plan 2014 Subzone Boundary (Web) (KML)\nImport Master Plan 2014 Subzone Boundary (Web) Shapefile\n\nmpsz &lt;- st_read(dsn = \"data/\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\SMU\\Y4S1\\IS415\\IS415\\In-class_Ex\\In-class_Ex02\\data' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nWrite Master Plan 2014 Subzone Boundary (Web) Shapefile into KML format as the one provided is corrupted\n\nst_write(mpsz,\"data/MP14_SUBZONE_WEB_PL.kml\", delete_dsn = TRUE)\n\nDeleting source `data/MP14_SUBZONE_WEB_PL.kml' using driver `KML'\nWriting layer `MP14_SUBZONE_WEB_PL' to data source \n  `data/MP14_SUBZONE_WEB_PL.kml' using driver `KML'\nWriting 323 features with 15 fields and geometry type Multi Polygon.\n\n\nImport newly created KML file\n\nmp_kml_14 = st_read(\"data/MP14_SUBZONE_WEB_PL.kml\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\SMU\\Y4S1\\IS415\\IS415\\In-class_Ex\\In-class_Ex02\\data\\MP14_SUBZONE_WEB_PL.kml' \n  using driver `KML'\nSimple feature collection with 323 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\nImport Master Plan 2019 Subzone Boundary (Web) ShapeFile\n\nmpsz19 &lt;- st_read(dsn = \"data/\", \n                layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\SMU\\Y4S1\\IS415\\IS415\\In-class_Ex\\In-class_Ex02\\data' using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\nImport Master Plan 2019 Subzone Boundary (Web) KML\n\nmp_kml_19 = st_read(\"data/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\")\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `C:\\SMU\\Y4S1\\IS415\\IS415\\In-class_Ex\\In-class_Ex02\\data\\MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nImport Population CSV file\n\npopdata &lt;- read_csv(\"data/respopagesextod2023.csv\")\n\nRows: 100928 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#data-wrangling",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#data-wrangling",
    "title": "In class exercise 2",
    "section": "3.0 Data Wrangling",
    "text": "3.0 Data Wrangling\n\npopdata2023 &lt;- popdata %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\ncolnames(popdata2023)\n\n [1] \"PA\"          \"SZ\"          \"0_to_4\"      \"10_to_14\"    \"15_to_19\"   \n [6] \"20_to_24\"    \"25_to_29\"    \"30_to_34\"    \"35_to_39\"    \"40_to_44\"   \n[11] \"45_to_49\"    \"50_to_54\"    \"55_to_59\"    \"5_to_9\"      \"60_to_64\"   \n[16] \"65_to_69\"    \"70_to_74\"    \"75_to_79\"    \"80_to_84\"    \"85_to_89\"   \n[21] \"90_and_Over\"\n\n\nData Processing\n\npopdata2023 &lt;- popdata2023 %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[14])) %&gt;%\n  mutate(`ECONOMY ACTIVE` = rowSums(.[7:13])+\n  rowSums(.[15]))%&gt;%\n  mutate(`AGED`=rowSums(.[16:21])) %&gt;%\n  mutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \n  mutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n  /`ECONOMY ACTIVE`) %&gt;%\n    select(`PA`, `SZ`, `YOUNG`, \n         `ECONOMY ACTIVE`, `AGED`, \n         `TOTAL`, `DEPENDENCY`)\n\nJoin popdata2023 and mpsz_19\n\npopdata2023 &lt;- popdata2023 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper))\n\n\nmpsz_pop2023 &lt;- left_join(mpsz19, popdata2023,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\npop2023_mpsz &lt;- left_join(popdata2023, mpsz19,\n                          by = c(\"SZ\" = \"SUBZONE_N\"))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "title": "In-class Exercise 1",
    "section": "",
    "text": "Edit: Add Categories"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "Hands-On Exercise 6: Global Measures of Spatial Autocorrelation",
    "section": "",
    "text": "How to compute Global Measures of Spatial Autocorrelation (GMSA) by using spdep package"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#overview",
    "title": "Hands-On Exercise 6: Global Measures of Spatial Autocorrelation",
    "section": "",
    "text": "How to compute Global Measures of Spatial Autocorrelation (GMSA) by using spdep package"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started",
    "title": "Hands-On Exercise 6: Global Measures of Spatial Autocorrelation",
    "section": "Getting started",
    "text": "Getting started\n\npacman::p_load(sf, spdep, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#importing-the-data",
    "title": "Hands-On Exercise 6: Global Measures of Spatial Autocorrelation",
    "section": "Importing the data",
    "text": "Importing the data\n2 dataset are used\n\nHunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.\n\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\SMU\\Y4S1\\IS415\\IS415\\Hands-on_Ex\\Hands-on_Ex06\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nLeft joined is used to join the hunan and hunan2012 data\n\nhunan &lt;- left_join(hunan,hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`\n\n\n\nVisualising Regional Development Indicator\nTo prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 qtm() of tmap package is used\n\nequal &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation",
    "title": "Hands-On Exercise 6: Global Measures of Spatial Autocorrelation",
    "section": "Global Measures of Spatial Autocorrelation",
    "text": "Global Measures of Spatial Autocorrelation\n\nComputing Contiguity Spatial Weights\nBefore we can compute the global spatial autocorrelation statistics, we need to construct a spatial weights of the study area. The spatial weights is used to define the neighbourhood relationships between the geographical units (i.e. county) in the study area.\nIn the code chunk below, poly2nb() of spdep package is used to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. If you look at the documentation you will see that you can pass a “queen” argument that takes TRUE or FALSE as options. If you do not specify this argument the default is set to TRUE, that is, if you don’t specify queen = FALSE this function will return a list of first order neighbours using the Queen criteria.\n\nwm_q &lt;- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\n\n\nRow-standardised weights matrix\nIn our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summaries the neighbors’ values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data.\n\nrswm_q &lt;- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation-morans-i",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation-morans-i",
    "title": "Hands-On Exercise 6: Global Measures of Spatial Autocorrelation",
    "section": "Global Measures of Spatial Autocorrelation: Moran’s I",
    "text": "Global Measures of Spatial Autocorrelation: Moran’s I\nMoran’s I statistical testing using moran.test() of spdep\n\nmoran.test(hunan$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\nComputing Monte Carlo Moran’s I\nThe code chunk below performs permutation test for Moran’s I statistic by using moran.mc() of spdep. A total of 1000 simulation will be performed.\n\nset.seed(1234)\nbperm= moran.mc(hunan$GDPPC, \n                listw=rswm_q, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\n\nQuestion: What statistical conclustion can you draw from the output above?\nThere is a significant positive spatial autocorrelation in the GDP per capita data across the Hunan region. This suggests that neighboring regions tend to have similar levels of GDP per capita, which could be due to factors such as geographical proximity.\n\n\n\nVisualising Monte Carlo Moran’s I\n\nmean(bperm$res[1:999])\n\n[1] -0.01504572\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\n\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation-gearys-c",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation-gearys-c",
    "title": "Hands-On Exercise 6: Global Measures of Spatial Autocorrelation",
    "section": "Global Measures of Spatial Autocorrelation: Geary’s C",
    "text": "Global Measures of Spatial Autocorrelation: Geary’s C\n\nGeary’s C test\nGeary’s C test for spatial autocorrelation by using geary.test() of spdep.\n\ngeary.test(hunan$GDPPC, listw=rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q   \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\n\n\nComputing Monte Carlo Geary’s C\npermutation test for Geary’s C statistic by using geary.mc() of spdep\n\nset.seed(1234)\nbperm=geary.mc(hunan$GDPPC, \n               listw=rswm_q, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\nVisualising the Monte Carlo Geary’s C\n\nmean(bperm$res[1:999])\n\n[1] 1.004402\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.007436493\n\n\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\n\n\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary c\")\nabline(v=1, col=\"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#spatial-correlogram",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#spatial-correlogram",
    "title": "Hands-On Exercise 6: Global Measures of Spatial Autocorrelation",
    "section": "Spatial Correlogram",
    "text": "Spatial Correlogram\nSpatial correlograms are great to examine patterns of spatial autocorrelation in your data or model residuals. They show how correlated are pairs of spatial observations when you increase the distance (lag) between them - they are plots of some index of autocorrelation (Moran’s I or Geary’s c) against distance.Although correlograms are not as fundamental as variograms (a keystone concept of geostatistics), they are very useful as an exploratory and descriptive tool. For this purpose they actually provide richer information than variograms.\n\nCompute Moran’s I correlogram\nsp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Moran’s I. The plot() of base Graph is then used to plot the output.\n\nMI_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\n\n\n\n\nBy plotting the output might not allow us to provide complete interpretation. This is because not all autocorrelation values are statistically significant. Hence, it is important for us to examine the full analysis report by printing out the analysis results\n\nprint(MI_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nCompute Geary’s C correlogram and plot\nsp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Geary’s C. The plot() of base Graph is then used to plot the output.\n\nGC_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\n\n\n\n\nAgain we will need to print out the analysis report\n\nprint(GC_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#creating-a-lisa-cluster-map",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#creating-a-lisa-cluster-map",
    "title": "Hands-On Exercise 6: Global Measures of Spatial Autocorrelation",
    "section": "Creating a LISA Cluster Map",
    "text": "Creating a LISA Cluster Map\nThe LISA Cluster Map shows the significant locations color coded by type of spatial autocorrelation. The first step before we can generate the LISA cluster map is to plot the Moran scatterplot.\n\nPlotting Moran Scatterplot\n\nnci &lt;- moran.plot(hunan$GDPPC, rswm_q,\n                  labels=as.character(hunan$County), \n                  xlab=\"GDPPC 2012\", \n                  ylab=\"Spatially Lag GDPPC 2012\")\n\n\n\n\n\n\n\n\n\n\nPlotting Moran scatterplot with standardised variable\nWe will use scale() to center and scale the variable. Here centering is done by subtracting the mean (omitting NAs) the corresponding columns, and scaling is done by dividing the (centered) variable by their standard deviations.\n\nhunan$Z.GDPPC &lt;- scale(hunan$GDPPC) %&gt;% \n  as.vector \n\n\nnci2 &lt;- moran.plot(hunan$Z.GDPPC, rswm_q,\n                   labels=as.character(hunan$County),\n                   xlab=\"z-GDPPC 2012\", \n                   ylab=\"Spatially Lag z-GDPPC 2012\")\n\n\n\n\n\n\n\n\n\n\nPreparing LISA map classes\n\nquadrant &lt;- vector(mode=\"numeric\",length=nrow(localMI))\n\nNext, derives the spatially lagged variable of interest (i.e. GDPPC) and centers the spatially lagged variable around its mean.\n\nhunan$lag_GDPPC &lt;- lag.listw(rswm_q, hunan$GDPPC)\nDV &lt;- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \n\nThis is follow by centering the local Moran’s around the mean.\n\nLM_I &lt;- localMI[,1] - mean(localMI[,1])    \n\nNext, we will set a statistical significance level for the local Moran.\n\nsignif &lt;- 0.05       \n\nThese four command lines define the low-low (1), low-high (2), high-low (3) and high-high (4) categories.\n\nquadrant[DV &lt;0 & LM_I&gt;0] &lt;- 1\nquadrant[DV &gt;0 & LM_I&lt;0] &lt;- 2\nquadrant[DV &lt;0 & LM_I&lt;0] &lt;- 3  \nquadrant[DV &gt;0 & LM_I&gt;0] &lt;- 4      \n\nLastly, places non-significant Moran in the category 0.\n\nquadrant[localMI[,5]&gt;signif] &lt;- 0\n\n\n\nPlotting LISA map\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\n\n\n\n\n\n\n\nFor effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\ntmap_arrange(gdppc, LISAmap, \n             asp=1, ncol=2)\n\n\n\n\n\n\n\n\nWe can also include the local Moran’s I map and p-value map as shown below for easy comparison.\n\nlocalMI.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)\n\nVariable(s) \"Ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#hot-spot-and-cold-spot-area-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#hot-spot-and-cold-spot-area-analysis",
    "title": "Hands-On Exercise 6: Global Measures of Spatial Autocorrelation",
    "section": "Hot Spot and Cold Spot Area Analysis",
    "text": "Hot Spot and Cold Spot Area Analysis\nBeside detecting cluster and outliers, localised spatial statistics can be also used to detect hot spot and/or cold spot areas.\nThe term ‘hot spot’ has been used generically across disciplines to describe a region or value that is higher relative to its surroundings (Lepers et al 2005, Aben et al 2012, Isobe et al 2015).\n\nGetis and Ord’s G-Statistics\nAn alternative spatial statistics to detect spatial anomalies is the Getis and Ord’s G-statistics (Getis and Ord, 1972; Ord and Getis, 1995). It looks at neighbours within a defined proximity to identify where either high or low values clutser spatially. Here, statistically significant hot-spots are recognised as areas of high values where other areas within a neighbourhood range also share high values too.\nThe analysis consists of three steps:\n\nDeriving spatial weight matrix\nComputing Gi statistics\nMapping Gi statistics\n\n\n\nDeriving distance-based weight matrix\nFirst, we need to define a new set of neighbours. Whist the spatial autocorrelation considered units which shared borders, for Getis-Ord we are defining neighbours based on distance.\nThere are two type of distance-based proximity matrix, they are:\n\nfixed distance weight matrix; and\nadaptive distance weight matrix.\n\n\nDeriving the centroid\nWe will need points to associate with each polygon before we can make our connectivity graph. It will be a little more complicated than just running st_centroid() on the sf object: us.bound. We need the coordinates in a separate data frame for this to work. To do this we will use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of us.bound. Our function will be st_centroid(). We will be using map_dbl variation of map from the purrr package. For more documentation, check out map documentation\nTo get our longitude values we map the st_centroid() function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\n\ncoords &lt;- cbind(longitude, latitude)\n\n\n\nDetermine the cut-off distance\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\nk1 &lt;- knn2nb(knearneigh(coords))\n\nWarning in knn2nb(knearneigh(coords)): neighbour object has 25 sub-graphs\n\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\nComputing fixed distance weight matrix\ncompute the distance weight matrix by using dnearneigh() \n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nnb2listw() is used to convert the nb object into spatial weights object.\n\nwm62_lw &lt;- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440\n\n\n\n\n\nComputing adaptive distance weight matrix\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry\n\nknn &lt;- knn2nb(knearneigh(coords, k=8))\nknn\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\nnb2listw() is used to convert the nb object into spatial weights object.\n\nknn_lw &lt;- nb2listw(knn, style = 'B')\nsummary(knn_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-gi-statistics",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-gi-statistics",
    "title": "Hands-On Exercise 6: Global Measures of Spatial Autocorrelation",
    "section": "Computing Gi statistics",
    "text": "Computing Gi statistics\n\nGi statistics using fixed distance\n\nfips &lt;- order(hunan$County)\ngi.fixed &lt;- localG(hunan$GDPPC, wm62_lw)\ngi.fixed\n\n [1]  0.436075843 -0.265505650 -0.073033665  0.413017033  0.273070579\n [6] -0.377510776  2.863898821  2.794350420  5.216125401  0.228236603\n[11]  0.951035346 -0.536334231  0.176761556  1.195564020 -0.033020610\n[16]  1.378081093 -0.585756761 -0.419680565  0.258805141  0.012056111\n[21] -0.145716531 -0.027158687 -0.318615290 -0.748946051 -0.961700582\n[26] -0.796851342 -1.033949773 -0.460979158 -0.885240161 -0.266671512\n[31] -0.886168613 -0.855476971 -0.922143185 -1.162328599  0.735582222\n[36] -0.003358489 -0.967459309 -1.259299080 -1.452256513 -1.540671121\n[41] -1.395011407 -1.681505286 -1.314110709 -0.767944457 -0.192889342\n[46]  2.720804542  1.809191360 -1.218469473 -0.511984469 -0.834546363\n[51] -0.908179070 -1.541081516 -1.192199867 -1.075080164 -1.631075961\n[56] -0.743472246  0.418842387  0.832943753 -0.710289083 -0.449718820\n[61] -0.493238743 -1.083386776  0.042979051  0.008596093  0.136337469\n[66]  2.203411744  2.690329952  4.453703219 -0.340842743 -0.129318589\n[71]  0.737806634 -1.246912658  0.666667559  1.088613505 -0.985792573\n[76]  1.233609606 -0.487196415  1.626174042 -1.060416797  0.425361422\n[81] -0.837897118 -0.314565243  0.371456331  4.424392623 -0.109566928\n[86]  1.364597995 -1.029658605 -0.718000620\nattr(,\"internals\")\n               Gi      E(Gi)        V(Gi)        Z(Gi) Pr(z != E(Gi))\n [1,] 0.064192949 0.05747126 2.375922e-04  0.436075843   6.627817e-01\n [2,] 0.042300020 0.04597701 1.917951e-04 -0.265505650   7.906200e-01\n [3,] 0.044961480 0.04597701 1.933486e-04 -0.073033665   9.417793e-01\n [4,] 0.039475779 0.03448276 1.461473e-04  0.413017033   6.795941e-01\n [5,] 0.049767939 0.04597701 1.927263e-04  0.273070579   7.847990e-01\n [6,] 0.008825335 0.01149425 4.998177e-05 -0.377510776   7.057941e-01\n [7,] 0.050807266 0.02298851 9.435398e-05  2.863898821   4.184617e-03\n [8,] 0.083966739 0.04597701 1.848292e-04  2.794350420   5.200409e-03\n [9,] 0.115751554 0.04597701 1.789361e-04  5.216125401   1.827045e-07\n[10,] 0.049115587 0.04597701 1.891013e-04  0.228236603   8.194623e-01\n[11,] 0.045819180 0.03448276 1.420884e-04  0.951035346   3.415864e-01\n[12,] 0.049183846 0.05747126 2.387633e-04 -0.536334231   5.917276e-01\n[13,] 0.048429181 0.04597701 1.924532e-04  0.176761556   8.596957e-01\n[14,] 0.034733752 0.02298851 9.651140e-05  1.195564020   2.318667e-01\n[15,] 0.011262043 0.01149425 4.945294e-05 -0.033020610   9.736582e-01\n[16,] 0.065131196 0.04597701 1.931870e-04  1.378081093   1.681783e-01\n[17,] 0.027587075 0.03448276 1.385862e-04 -0.585756761   5.580390e-01\n[18,] 0.029409313 0.03448276 1.461397e-04 -0.419680565   6.747188e-01\n[19,] 0.061466754 0.05747126 2.383385e-04  0.258805141   7.957856e-01\n[20,] 0.057656917 0.05747126 2.371303e-04  0.012056111   9.903808e-01\n[21,] 0.066518379 0.06896552 2.820326e-04 -0.145716531   8.841452e-01\n[22,] 0.045599896 0.04597701 1.928108e-04 -0.027158687   9.783332e-01\n[23,] 0.030646753 0.03448276 1.449523e-04 -0.318615290   7.500183e-01\n[24,] 0.035635552 0.04597701 1.906613e-04 -0.748946051   4.538897e-01\n[25,] 0.032606647 0.04597701 1.932888e-04 -0.961700582   3.362000e-01\n[26,] 0.035001352 0.04597701 1.897172e-04 -0.796851342   4.255374e-01\n[27,] 0.012746354 0.02298851 9.812587e-05 -1.033949773   3.011596e-01\n[28,] 0.061287917 0.06896552 2.773884e-04 -0.460979158   6.448136e-01\n[29,] 0.014277403 0.02298851 9.683314e-05 -0.885240161   3.760271e-01\n[30,] 0.009622875 0.01149425 4.924586e-05 -0.266671512   7.897221e-01\n[31,] 0.014258398 0.02298851 9.705244e-05 -0.886168613   3.755267e-01\n[32,] 0.005453443 0.01149425 4.986245e-05 -0.855476971   3.922871e-01\n[33,] 0.043283712 0.05747126 2.367109e-04 -0.922143185   3.564539e-01\n[34,] 0.020763514 0.03448276 1.393165e-04 -1.162328599   2.451020e-01\n[35,] 0.081261843 0.06896552 2.794398e-04  0.735582222   4.619850e-01\n[36,] 0.057419907 0.05747126 2.338437e-04 -0.003358489   9.973203e-01\n[37,] 0.013497133 0.02298851 9.624821e-05 -0.967459309   3.333145e-01\n[38,] 0.019289310 0.03448276 1.455643e-04 -1.259299080   2.079223e-01\n[39,] 0.025996272 0.04597701 1.892938e-04 -1.452256513   1.464303e-01\n[40,] 0.016092694 0.03448276 1.424776e-04 -1.540671121   1.233968e-01\n[41,] 0.035952614 0.05747126 2.379439e-04 -1.395011407   1.630124e-01\n[42,] 0.031690963 0.05747126 2.350604e-04 -1.681505286   9.266481e-02\n[43,] 0.018750079 0.03448276 1.433314e-04 -1.314110709   1.888090e-01\n[44,] 0.015449080 0.02298851 9.638666e-05 -0.767944457   4.425202e-01\n[45,] 0.065760689 0.06896552 2.760533e-04 -0.192889342   8.470456e-01\n[46,] 0.098966900 0.05747126 2.326002e-04  2.720804542   6.512325e-03\n[47,] 0.085415780 0.05747126 2.385746e-04  1.809191360   7.042128e-02\n[48,] 0.038816536 0.05747126 2.343951e-04 -1.218469473   2.230456e-01\n[49,] 0.038931873 0.04597701 1.893501e-04 -0.511984469   6.086619e-01\n[50,] 0.055098610 0.06896552 2.760948e-04 -0.834546363   4.039732e-01\n[51,] 0.033405005 0.04597701 1.916312e-04 -0.908179070   3.637836e-01\n[52,] 0.043040784 0.06896552 2.829941e-04 -1.541081516   1.232969e-01\n[53,] 0.011297699 0.02298851 9.615920e-05 -1.192199867   2.331829e-01\n[54,] 0.040968457 0.05747126 2.356318e-04 -1.075080164   2.823388e-01\n[55,] 0.023629663 0.04597701 1.877170e-04 -1.631075961   1.028743e-01\n[56,] 0.006281129 0.01149425 4.916619e-05 -0.743472246   4.571958e-01\n[57,] 0.063918654 0.05747126 2.369553e-04  0.418842387   6.753313e-01\n[58,] 0.070325003 0.05747126 2.381374e-04  0.832943753   4.048765e-01\n[59,] 0.025947288 0.03448276 1.444058e-04 -0.710289083   4.775249e-01\n[60,] 0.039752578 0.04597701 1.915656e-04 -0.449718820   6.529132e-01\n[61,] 0.049934283 0.05747126 2.334965e-04 -0.493238743   6.218439e-01\n[62,] 0.030964195 0.04597701 1.920248e-04 -1.083386776   2.786368e-01\n[63,] 0.058129184 0.05747126 2.343319e-04  0.042979051   9.657182e-01\n[64,] 0.046096514 0.04597701 1.932637e-04  0.008596093   9.931414e-01\n[65,] 0.012459080 0.01149425 5.008051e-05  0.136337469   8.915545e-01\n[66,] 0.091447733 0.05747126 2.377744e-04  2.203411744   2.756574e-02\n[67,] 0.049575872 0.02298851 9.766513e-05  2.690329952   7.138140e-03\n[68,] 0.107907212 0.04597701 1.933581e-04  4.453703219   8.440175e-06\n[69,] 0.019616151 0.02298851 9.789454e-05 -0.340842743   7.332220e-01\n[70,] 0.032923393 0.03448276 1.454032e-04 -0.129318589   8.971056e-01\n[71,] 0.030317663 0.02298851 9.867859e-05  0.737806634   4.606320e-01\n[72,] 0.019437582 0.03448276 1.455870e-04 -1.246912658   2.124295e-01\n[73,] 0.055245460 0.04597701 1.932838e-04  0.666667559   5.049845e-01\n[74,] 0.074278054 0.05747126 2.383538e-04  1.088613505   2.763244e-01\n[75,] 0.013269580 0.02298851 9.719982e-05 -0.985792573   3.242349e-01\n[76,] 0.049407829 0.03448276 1.463785e-04  1.233609606   2.173484e-01\n[77,] 0.028605749 0.03448276 1.455139e-04 -0.487196415   6.261191e-01\n[78,] 0.039087662 0.02298851 9.801040e-05  1.626174042   1.039126e-01\n[79,] 0.031447120 0.04597701 1.877464e-04 -1.060416797   2.889550e-01\n[80,] 0.064005294 0.05747126 2.359641e-04  0.425361422   6.705732e-01\n[81,] 0.044606529 0.05747126 2.357330e-04 -0.837897118   4.020885e-01\n[82,] 0.063700493 0.06896552 2.801427e-04 -0.314565243   7.530918e-01\n[83,] 0.051142205 0.04597701 1.933560e-04  0.371456331   7.102977e-01\n[84,] 0.102121112 0.04597701 1.610278e-04  4.424392623   9.671399e-06\n[85,] 0.021901462 0.02298851 9.843172e-05 -0.109566928   9.127528e-01\n[86,] 0.064931813 0.04597701 1.929430e-04  1.364597995   1.723794e-01\n[87,] 0.031747344 0.04597701 1.909867e-04 -1.029658605   3.031703e-01\n[88,] 0.015893319 0.02298851 9.765131e-05 -0.718000620   4.727569e-01\nattr(,\"cluster\")\n [1] Low  Low  High High High High High High High Low  Low  High Low  Low  Low \n[16] High High High High Low  High High Low  Low  High Low  Low  Low  Low  Low \n[31] Low  Low  Low  High Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  High Low  Low  Low  Low  Low  High Low  Low \n[61] Low  Low  Low  High High High Low  High Low  Low  High Low  High High Low \n[76] High Low  Low  Low  Low  Low  Low  High High Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = hunan$GDPPC, listw = wm62_lw)\nattr(,\"class\")\n[1] \"localG\"\n\n\nThe output of localG() is a vector of G or Gstar values, with attributes “gstari” set to TRUE or FALSE, “call” set to the function call, and class “localG”.\nThe Gi statistics is represented as a Z-score. Greater values represent a greater intensity of clustering and the direction (positive or negative) indicates high or low clusters.\nNext, we will join the Gi values to their corresponding hunan sf data frame\n\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.fixed)) %&gt;%\n  rename(gstat_fixed = as.matrix.gi.fixed.)\n\nThe code chuck does three things. First, it convert the output vector (i.e. gi.fixed) into r matrix object by using as.matrix(). Next, cbind() is used to join hunan@data and gi.fixed matrix to produce a new SpatialPolygonDataFrame called hunan.gi. Lastly, the field name of the gi values is renamed to gstat_fixed by using rename().\n\n\nMapping Gi values with fixed distance weights\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nGimap &lt;-tm_shape(hunan.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap, asp=1, ncol=2)\n\nVariable(s) \"gstat_fixed\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\nGi statistics using adaptive distance\n\nfips &lt;- order(hunan$County)\ngi.adaptive &lt;- localG(hunan$GDPPC, knn_lw)\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.adaptive)) %&gt;%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)\n\n\n\nMapping Gi values with adaptive distance weights\nIt is time for us to visualise the locations of hot spot and cold spot areas. The choropleth mapping functions of tmap package will be used to map the Gi values.\n\ngdppc&lt;- qtm(hunan, \"GDPPC\")\n\nGimap &lt;- tm_shape(hunan.gi) + \n  tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\", \n          palette=\"-RdBu\", \n          title = \"local Gi\") + \n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, \n             Gimap, \n             asp=1, \n             ncol=2)\n\nVariable(s) \"gstat_adaptive\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "title": "Hands-On Exercise 3: 1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "Spatial Point Pattern Analysis is a statistical technique used to study the spatial arrangement of points within a defined area or surface. These points typically represent the locations of specific events, objects, or phenomena. The primary goal of SPPA is to identify and analyze the underlying patterns in the distribution of these points, which could be clustered, random, or regularly spaced.\nThis exercise would be using functions spatstat for spatial point pattern analysis"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#overview",
    "title": "Hands-On Exercise 3: 1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "Spatial Point Pattern Analysis is a statistical technique used to study the spatial arrangement of points within a defined area or surface. These points typically represent the locations of specific events, objects, or phenomena. The primary goal of SPPA is to identify and analyze the underlying patterns in the distribution of these points, which could be clustered, random, or regularly spaced.\nThis exercise would be using functions spatstat for spatial point pattern analysis"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#setup",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#setup",
    "title": "Hands-On Exercise 3: 1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "2.0 Setup",
    "text": "2.0 Setup\n\n2.1 Imports\n\nsf: import, manage and process vector-based geospatial data in R.\nspatstat: Perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer.\nraster: Reads, writes, manipulates, analyses and model of gridded spatial data (i.e. raster).\nmaptools : Convert Spatial objects into ppp format of spatstat.\ntmap : Plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\n\n\n\n2.2 Data\n\nCHILDCARE from data.gov.sg\nMP14_SUBZONE_WEB_PL from data.gov.sg\nCostalOutline from SLA\n\n\n\n2.3 Imports\nImport the libraries\n\ninstall.packages(\"maptools\", repos = \"https://packagemanager.posit.co/cran/2023-10-13\")\n\nInstalling package into 'C:/Users/joshu/AppData/Local/R/win-library/4.4'\n(as 'lib' is unspecified)\n\n\npackage 'maptools' successfully unpacked and MD5 sums checked\n\n\nWarning: cannot remove prior installation of package 'maptools'\n\n\nWarning in file.copy(savedcopy, lib, recursive = TRUE): problem copying\nC:\\Users\\joshu\\AppData\\Local\\R\\win-library\\4.4\\00LOCK\\maptools\\libs\\x64\\maptools.dll\nto\nC:\\Users\\joshu\\AppData\\Local\\R\\win-library\\4.4\\maptools\\libs\\x64\\maptools.dll:\nPermission denied\n\n\nWarning: restored 'maptools'\n\n\n\nThe downloaded binary packages are in\n    C:\\Users\\joshu\\AppData\\Local\\Temp\\RtmpwfJsvZ\\downloaded_packages\n\n\n\npacman::p_load(sf, raster, spatstat, tmap, tidyverse,sp,maptools)\n\nImport Child Care Services dataset\n\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs=3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\SMU\\Y4S1\\IS415\\IS415\\Hands-on_Ex\\Hands-on_Ex03\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nImport MP14\n\nmpsz_sf &lt;- st_read(dsn = \"data/\", \n                layer = \"MP14_SUBZONE_WEB_PL\") %&gt;% \n  st_transform(crs=3414)\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\SMU\\Y4S1\\IS415\\IS415\\Hands-on_Ex\\Hands-on_Ex03\\data' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nImport Costal Outline\n\nsg_sf &lt;- st_read(dsn = \"data\", layer=\"CostalOutline\") %&gt;% \n  st_transform(crs=3414)\n\nReading layer `CostalOutline' from data source \n  `C:\\SMU\\Y4S1\\IS415\\IS415\\Hands-on_Ex\\Hands-on_Ex03\\data' using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\nChecking data\n\nst_crs(childcare_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#mapping",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#mapping",
    "title": "Hands-On Exercise 3: 1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "3.0 Mapping",
    "text": "3.0 Mapping\n\nDIY\n\ntm_shape(sg_sf) + \n  tm_polygons() + \n  tm_shape(mpsz_sf) + \n  tm_polygons()+ \n  tm_shape(childcare_sf)+ \n  tm_dots()\n\n\n\n\n\n\n\n\nPin Map\n\n#tmap_mode('view')\n#tm_shape(childcare_sf)+\n#  tm_dots()\n\n\n#tmap_mode('plot')\n\nInteractive pin map is it allows us to navigate and zoom around the map freely. We can also query the information of each simple feature (i.e. the point) by clicking on them."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#geospatial-data-wrangling",
    "title": "Hands-On Exercise 3: 1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "4.0 Geospatial Data wrangling",
    "text": "4.0 Geospatial Data wrangling\n\nConverting sf data frames to sp’s Spatial* class\n\nchildcare &lt;- as_Spatial(childcare_sf)\nmpsz &lt;- as_Spatial(mpsz_sf)\nsg &lt;- as_Spatial(sg_sf)\n\n\nchildcare\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description \nmin values  :   kml_1, &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;1, MARINA BOULEVARD, #B1 - 01, ONE MARINA BOULEVARD, SINGAPORE 018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;THE LITTLE SKOOL-HOUSE INTERNATIONAL PTE. LTD.&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;08F73931F4A691F4&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \nmax values  : kml_999,                  &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;200, PONGGOL SEVENTEENTH AVENUE, SINGAPORE 829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;Child Care Services&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;RAFFLES KIDZ @ PUNGGOL PTE LTD&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;379D017BF244B0FA&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \n\n\n\nmpsz\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792 \n\n\n\nsg\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 4\nnames       : GDO_GID, MSLINK, MAPID,              COSTAL_NAM \nmin values  :       1,      1,     0,             ISLAND LINK \nmax values  :      60,     67,     0, SINGAPORE - MAIN ISLAND \n\n\n\n\nConverting the Spatial* class into generic sp format\nspatstat requires the analytical data in ppp object form. There is no direct way to convert a Spatial* classes into ppp object. We need to convert the Spatial classes* into Spatial object first.\n\nchildcare_sp &lt;- as(childcare, \"SpatialPoints\")\nsg_sp &lt;- as(sg, \"SpatialPolygons\")\n\n\n\nConverting the generic sp format into spatstat’s ppp format\n\nchildcare_ppp &lt;- as(childcare_sp, \"ppp\")\nchildcare_ppp\n\nPlanar point pattern: 1545 points\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\n\nplot(childcare_ppp)\n\n\n\n\n\n\n\n\n\nsummary(childcare_ppp)\n\nPlanar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 11 decimal places\n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\n\n\nHandling duplicated points\n\nany(duplicated(childcare_ppp))\n\n[1] TRUE\n\n\ncount the number of co-indicence point\n\nmultiplicity(childcare_ppp)\n\n   1    2    3    4    5    6    7    8    9   10   11   12   13   14   15   16 \n   1    1    1    3    1    1    1    1    2    1    1    1    1    1    1    1 \n  17   18   19   20   21   22   23   24   25   26   27   28   29   30   31   32 \n   1    1    1    1    1    1    1    1    1    1    9    1    1    1    1    1 \n  33   34   35   36   37   38   39   40   41   42   43   44   45   46   47   48 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n  49   50   51   52   53   54   55   56   57   58   59   60   61   62   63   64 \n   1    1    1    1    1    1    2    1    1    3    1    1    1    1    1    1 \n  65   66   67   68   69   70   71   72   73   74   75   76   77   78   79   80 \n   1    1    1    1    1    2    1    1    1    1    1    2    1    1    1    1 \n  81   82   83   84   85   86   87   88   89   90   91   92   93   94   95   96 \n   1    1    1    3    1    1    1    1    1    1    1    1    1    1    1    1 \n  97   98   99  100  101  102  103  104  105  106  107  108  109  110  111  112 \n   1    1    1    1    1    1    1    1    2    1    1    1    1    1    1    1 \n 113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  128 \n   1    1    1    1    1    1    2    1    1    1    3    1    1    1    2    1 \n 129  130  131  132  133  134  135  136  137  138  139  140  141  142  143  144 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    3    2 \n 145  146  147  148  149  150  151  152  153  154  155  156  157  158  159  160 \n   1    2    1    1    1    2    2    3    1    5    1    5    1    1    1    2 \n 161  162  163  164  165  166  167  168  169  170  171  172  173  174  175  176 \n   1    1    1    1    2    1    1    1    1    1    1    2    1    1    1    1 \n 177  178  179  180  181  182  183  184  185  186  187  188  189  190  191  192 \n   1    4    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 193  194  195  196  197  198  199  200  201  202  203  204  205  206  207  208 \n   1    1    1    1    1    2    2    1    1    1    1    2    1    4    1    1 \n 209  210  211  212  213  214  215  216  217  218  219  220  221  222  223  224 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    1    1    1 \n 225  226  227  228  229  230  231  232  233  234  235  236  237  238  239  240 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 241  242  243  244  245  246  247  248  249  250  251  252  253  254  255  256 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 257  258  259  260  261  262  263  264  265  266  267  268  269  270  271  272 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    3 \n 273  274  275  276  277  278  279  280  281  282  283  284  285  286  287  288 \n   1    1    1    1    1    1    3    1    1    1    1    1    1    1    1    1 \n 289  290  291  292  293  294  295  296  297  298  299  300  301  302  303  304 \n   1    1    1    1    1    1    1    9    1    1    2    1    1    1    1    1 \n 305  306  307  308  309  310  311  312  313  314  315  316  317  318  319  320 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 321  322  323  324  325  326  327  328  329  330  331  332  333  334  335  336 \n   1    1    1    5    1    1    1    1    1    2    1    1    2    2    1    1 \n 337  338  339  340  341  342  343  344  345  346  347  348  349  350  351  352 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    2    2    1 \n 353  354  355  356  357  358  359  360  361  362  363  364  365  366  367  368 \n   1    1    1    1    9    1    1    1    1    1    1    1    1    1    1    1 \n 369  370  371  372  373  374  375  376  377  378  379  380  381  382  383  384 \n   1    3    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 385  386  387  388  389  390  391  392  393  394  395  396  397  398  399  400 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 401  402  403  404  405  406  407  408  409  410  411  412  413  414  415  416 \n   1    1    2    1    1    1    1    1    1    1    2    1    1    1    1    1 \n 417  418  419  420  421  422  423  424  425  426  427  428  429  430  431  432 \n   1    1    1    1    1    1    1    2    1    1    2    1    1    1    1    1 \n 433  434  435  436  437  438  439  440  441  442  443  444  445  446  447  448 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 449  450  451  452  453  454  455  456  457  458  459  460  461  462  463  464 \n   1    1    9    9    1    1    1    1    1    1    1    1    1    1    2    1 \n 465  466  467  468  469  470  471  472  473  474  475  476  477  478  479  480 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    2    1    1 \n 481  482  483  484  485  486  487  488  489  490  491  492  493  494  495  496 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 497  498  499  500  501  502  503  504  505  506  507  508  509  510  511  512 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    2 \n 513  514  515  516  517  518  519  520  521  522  523  524  525  526  527  528 \n   1    1    1    1    1    1    1    1    1    1    1    2    1    1    3    1 \n 529  530  531  532  533  534  535  536  537  538  539  540  541  542  543  544 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 545  546  547  548  549  550  551  552  553  554  555  556  557  558  559  560 \n   1    1    1    1    1    1    1    1    1    3    1    1    1    1    1    1 \n 561  562  563  564  565  566  567  568  569  570  571  572  573  574  575  576 \n   2    2    2    1    1    1    1    2    1    1    2    1    1    1    2    1 \n 577  578  579  580  581  582  583  584  585  586  587  588  589  590  591  592 \n   1    2    1    1    1    1    1    9    1    4    1    2    1    1    1    1 \n 593  594  595  596  597  598  599  600  601  602  603  604  605  606  607  608 \n   2    1    1    1    1    1    1    1    2    1    2    1    1    1    1    1 \n 609  610  611  612  613  614  615  616  617  618  619  620  621  622  623  624 \n   1    1    1    1    1    1    1    1    1    2    1    2    1    1    1    1 \n 625  626  627  628  629  630  631  632  633  634  635  636  637  638  639  640 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 641  642  643  644  645  646  647  648  649  650  651  652  653  654  655  656 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    4 \n 657  658  659  660  661  662  663  664  665  666  667  668  669  670  671  672 \n   1    1    1    1    1    1    1    3    1    1    1    1    1    1    1    1 \n 673  674  675  676  677  678  679  680  681  682  683  684  685  686  687  688 \n   1    1    1    1    1    4    1    1    1    1    1    4    1    1    1    1 \n 689  690  691  692  693  694  695  696  697  698  699  700  701  702  703  704 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 705  706  707  708  709  710  711  712  713  714  715  716  717  718  719  720 \n   1    1    2    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 721  722  723  724  725  726  727  728  729  730  731  732  733  734  735  736 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 737  738  739  740  741  742  743  744  745  746  747  748  749  750  751  752 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 753  754  755  756  757  758  759  760  761  762  763  764  765  766  767  768 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n 769  770  771  772  773  774  775  776  777  778  779  780  781  782  783  784 \n   1    1    1    1    1    1    1    1    1    4    1    1    1    1    1    1 \n 785  786  787  788  789  790  791  792  793  794  795  796  797  798  799  800 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 801  802  803  804  805  806  807  808  809  810  811  812  813  814  815  816 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 817  818  819  820  821  822  823  824  825  826  827  828  829  830  831  832 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 833  834  835  836  837  838  839  840  841  842  843  844  845  846  847  848 \n   1    1    1    1    1    1    1    2    1    1    1    1    1    1    1    1 \n 849  850  851  852  853  854  855  856  857  858  859  860  861  862  863  864 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 865  866  867  868  869  870  871  872  873  874  875  876  877  878  879  880 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 881  882  883  884  885  886  887  888  889  890  891  892  893  894  895  896 \n   3    1    1    1    2    1    1    1    3    1    1    3    1    1    1    1 \n 897  898  899  900  901  902  903  904  905  906  907  908  909  910  911  912 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 913  914  915  916  917  918  919  920  921  922  923  924  925  926  927  928 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 929  930  931  932  933  934  935  936  937  938  939  940  941  942  943  944 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 945  946  947  948  949  950  951  952  953  954  955  956  957  958  959  960 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 961  962  963  964  965  966  967  968  969  970  971  972  973  974  975  976 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 977  978  979  980  981  982  983  984  985  986  987  988  989  990  991  992 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 993  994  995  996  997  998  999 1000 1001 1002 1003 1004 1005 1006 1007 1008 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 \n   1    1    1    1    1    1    1    1    1    2    2    1    1    1    1    1 \n1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 \n   1    1    1    1    1    1    1    1    2    2    1    1    1    5    1    1 \n1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 \n   1    1    1    1    1    1    1    1    1    2    1    1    1    1    1    1 \n1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 \n   1    9    1    2    2    1    1    1    2    1    1    1    1    1    1    1 \n1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 \n   1    1    1    1    2    1    1    1    3    1    1    1    1    1    1    1 \n1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 \n   9    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 \n   1    1    1    2    1    1    1    1    1    1    1    1    1    1    1    1 \n1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 \n   1    1    1    2    1    2    1    1    1    2    2    2    1    1    1    1 \n1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 \n   1    1    2    1    1    1    1    1    1    1    1    1    2    1    1    1 \n1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 \n   1    1    1    1    3    1    1    1    1    1    1    1    1    1    1    1 \n1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 \n   1    1    1    1    1    1    1    1    4    1    1    1    1    1    2    1 \n1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 \n   1    1    1    1    1    1    1    1    1    9    1    1    1    1    1    1 \n1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    2    1 \n1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    1 \n1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 \n   1    1    1    1    1    1    1    1    1    1    5    1    1    1    1    1 \n1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 \n   1    1    1    1    1    2    1    1    1    1    2    1    1    1    1    3 \n1537 1538 1539 1540 1541 1542 1543 1544 1545 \n   1    1    1    1    1    1    2    1    1 \n\n\n\nsum(multiplicity(childcare_ppp) &gt; 1)\n\n[1] 128\n\n\nto view the location of the duplicated points\n\n#tmap_mode('view')\n#tm_shape(childcare) +\n#  tm_dots(alpha=0.4, \n#          size=0.05)\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\nHow to spot duplicates:\nThere are three possible solutions to address this problem. The simplest approach is to remove the duplicates, though this risks losing valuable point events.\nThe second option is to apply jittering, which introduces slight variations to the duplicate points, preventing them from occupying the same exact location.\nThe third approach involves making each point “unique” and associating the duplicates with the original points as marks or attributes. This would require using analytical techniques that can account for these attached marks.\n\nJittering\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-owin-object",
    "title": "Hands-On Exercise 3: 1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.0 Creating owin object",
    "text": "5.0 Creating owin object\nWhen analysing spatial point patterns, it is a good practice to confine the analysis with a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\n\nsg_owin &lt;- as.owin(sg_sf)\n\n\nplot(sg_owin)\n\n\n\n\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\n\nCombining point events object and owin object\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\n\nsummary(childcareSG_ppp)\n\nPlanar point pattern:  1545 points\nAverage intensity 2.129929e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 11 decimal places\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\n\nplot(childcareSG_ppp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#first-order-spatial-point-patterns-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#first-order-spatial-point-patterns-analysis",
    "title": "Hands-On Exercise 3: 1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "6.0 First-order Spatial Point Patterns Analysis",
    "text": "6.0 First-order Spatial Point Patterns Analysis\n\nKernel Density Estimation\n\nComputing kernel density estimation using automatic bandwidth selection method\n\nkde_childcareSG_bw &lt;- density(childcareSG_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\n\nplot(kde_childcareSG_bw)\n\n\n\n\n\n\n\n\n\nbw &lt;- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n298.4095 \n\n\n\n\nRescalling KDE values\n\nchildcareSG_ppp.km &lt;- rescale.ppp(childcareSG_ppp, 1000, \"km\")\n\n\nkde_childcareSG.bw &lt;- density(childcareSG_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG.bw)\n\n\n\n\n\n\n\n\n\n\n\nWorking with different automatic badwidth methods\n\n bw.CvL(childcareSG_ppp.km)\n\n   sigma \n4.543278 \n\n\n\nbw.scott(childcareSG_ppp.km)\n\n sigma.x  sigma.y \n2.224898 1.450966 \n\n\n\nbw.ppl(childcareSG_ppp.km)\n\n    sigma \n0.3897114 \n\n\n\nbw.diggle(childcareSG_ppp.km)\n\n    sigma \n0.2984095 \n\n\n\nkde_childcareSG.ppl &lt;- density(childcareSG_ppp.km, \n                               sigma=bw.ppl, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")\n\n\n\n\n\n\n\n\n\n\nWorking with different kernel methods\nBy default, the kernel method used in density.ppp() is gaussian. But there are three other options, namely: Epanechnikov, Quartic and Dics.\n\npar(mfrow = c(2,2))\npar(mar = c(3,2,2,1))\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#fixed-and-adaptive-kde",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#fixed-and-adaptive-kde",
    "title": "Hands-On Exercise 3: 1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "7.0 Fixed and Adaptive KDE",
    "text": "7.0 Fixed and Adaptive KDE\n\nkde_childcareSG_600 &lt;- density(childcareSG_ppp.km, sigma=0.6, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG_600)\n\n\n\n\n\n\n\n\n\nComputing KDE by using adaptive bandwidth\nFixed bandwidth method is very sensitive to highly skew distribution of spatial point patterns over geographical units for example urban versus rural. One way to overcome this problem is by using adaptive bandwidth instead.\n\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\n\n\n\ncompare the fixed and adaptive kernel density\n\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive bandwidth\")\n\n\n\n\n\n\n\n\n\n\nConverting KDE output into grid object\n\ngridded_kde_childcareSG_bw &lt;- as.SpatialGridDataFrame.im(kde_childcareSG_bw)\nspplot(gridded_kde_childcareSG_bw)\n\n\n\n\n\n\n\n\n\nConverting gridded output into raster\n\nkde_childcareSG_bw_raster &lt;- raster(kde_childcareSG.bw)\n\n\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : layer \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\n\n\nAssigning projection systems\n\nprojection(kde_childcareSG_bw_raster) &lt;- CRS(\"+init=EPSG:3414\")\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\n\n\n\nVisualising the output in tmap\n\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(\"layer\", palette = \"viridis\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\n\n\n\n\n\n\n\n\n\nComparing Spatial Point Patterns using KDE\nExtracting study area\n\npg &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\n\npar(mfrow=c(2,2))\nplot(pg, main = \"Punggol\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(tm, main = \"Tampines\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(ck, main = \"Choa Chu Kang\")\n\nWarning: plotting the first 10 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(jw, main = \"Jurong West\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nCreating owin object\n\npg_owin = as.owin(pg)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\njw_owin = as.owin(jw)\n\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\n\nchildcare_pg_ppp.km = rescale.ppp(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale.ppp(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale.ppp(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale.ppp(childcare_jw_ppp, 1000, \"km\")\n\n\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp.km, main=\"Punggol\")\nplot(childcare_tm_ppp.km, main=\"Tampines\")\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\nplot(childcare_jw_ppp.km, main=\"Jurong West\")\n\n\n\n\n\n\n\n\n\n\nComputing KDE\n\npar(mfrow = c(2,2))\npar(mar = c(3,2,2,1))\nplot(density(childcare_pg_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tempines\")\nplot(density(childcare_ck_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Jurong West\")\n\n\n\n\n\n\n\n\n\n\nComputing fixed bandwidth KDE\n\npar(mfrow = c(2,2))\npar(mar = c(3,2,2,1))\nplot(density(childcare_ck_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Chou Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Jurong West\")\nplot(density(childcare_pg_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#nearest-neighbour-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#nearest-neighbour-analysis",
    "title": "Hands-On Exercise 3: 1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "8.0 Nearest Neighbour Analysis",
    "text": "8.0 Nearest Neighbour Analysis\n\nTesting spatial point patterns using Clark and Evans Test\n\nclarkevans.test(childcareSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcareSG_ppp\nR = 0.55631, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\n\n\nClark and Evans Test: Choa Chu Kang planning area\n\nclarkevans.test(childcare_ck_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_ck_ppp\nR = 0.95797, p-value = 0.53\nalternative hypothesis: two-sided\n\n\n\n\nClark and Evans Test: Tampines planning area\n\nclarkevans.test(childcare_tm_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_tm_ppp\nR = 0.78446, p-value = 0.0001002\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#second-order-spatial-point-patterns-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#second-order-spatial-point-patterns-analysis",
    "title": "Hands-On Exercise 3: 1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "9.0 Second-order Spatial Point Patterns Analysis",
    "text": "9.0 Second-order Spatial Point Patterns Analysis"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analysing-spatial-point-process-using-g-function",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analysing-spatial-point-process-using-g-function",
    "title": "Hands-On Exercise 3: 1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "Analysing Spatial Point Process Using G-Function",
    "text": "Analysing Spatial Point Process Using G-Function\nThe G function measures the distribution of the distances from an arbitrary event to its nearest event. In this section, you will learn how to compute G-function estimation by using Gest() of spatstat package. You will also learn how to perform monta carlo simulation test using envelope() of spatstat package.\n\nChoa Chu Kang planning area\n\nComputing G-function estimation\n\nG_CK = Gest(childcare_ck_ppp, correction = \"border\")\nplot(G_CK, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\n\nG_CK.csr &lt;- envelope(childcare_ck_ppp, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(G_CK.csr)\n\n\n\n\n\n\n\n\n\n\n\nTampines planning area\n\nComputing G-function estimation\n\nG_tm = Gest(childcare_tm_ppp, correction = \"best\")\nplot(G_tm)\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\n\nG_tm.csr &lt;- envelope(childcare_tm_ppp, Gest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(G_tm.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analysing-spatial-point-process-using-f-function",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analysing-spatial-point-process-using-f-function",
    "title": "Hands-On Exercise 3: 1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "Analysing Spatial Point Process Using F-Function",
    "text": "Analysing Spatial Point Process Using F-Function\nThe F function estimates the empty space function F(r) or its hazard rate h(r) from a point pattern in a window of arbitrary shape.\n\nChoa Chu Kang planning area\n\nF_CK = Fest(childcare_ck_ppp)\nplot(F_CK)\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\n\nF_CK.csr &lt;- envelope(childcare_ck_ppp, Fest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(F_CK.csr)\n\n\n\n\n\n\n\n\n\n\nTampines planning area\n\nF_tm = Fest(childcare_tm_ppp, correction = \"best\")\nplot(F_tm)\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\n\nF_tm.csr &lt;- envelope(childcare_tm_ppp, Fest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(F_tm.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analysing-spatial-point-process-using-k-function",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analysing-spatial-point-process-using-k-function",
    "title": "Hands-On Exercise 3: 1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "Analysing Spatial Point Process Using K-Function",
    "text": "Analysing Spatial Point Process Using K-Function\n\nChoa Chu Kang planning area\n\nK_ck = Kest(childcare_ck_ppp, correction = \"Ripley\")\nplot(K_ck, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\n\nK_ck.csr &lt;- envelope(childcare_ck_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")\n\n\n\n\n\n\n\n\n\n\n\nTampines planning area\n\nComputing K-fucntion estimation\n\nK_tm = Kest(childcare_tm_ppp, correction = \"Ripley\")\nplot(K_tm, . -r ~ r, \n     ylab= \"K(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\n\nK_tm.csr &lt;- envelope(childcare_tm_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"K(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analysing-spatial-point-process-using-l-function",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analysing-spatial-point-process-using-l-function",
    "title": "Hands-On Exercise 3: 1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "Analysing Spatial Point Process Using L-Function",
    "text": "Analysing Spatial Point Process Using L-Function\n\nChoa Chu Kang planning area\n\nL_ck = Lest(childcare_ck_ppp, correction = \"Ripley\")\nplot(L_ck, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\n\nL_ck.csr &lt;- envelope(childcare_ck_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(L_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")\n\n\n\n\n\n\n\n\n\n\n\nTampines planning area\n\nL_tm = Lest(childcare_tm_ppp, correction = \"Ripley\")\nplot(L_tm, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\n\nPerforming Complete Spatial Randomness Test\n\nL_tm.csr &lt;- envelope(childcare_tm_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(L_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"L(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "Edit: Update Metadata"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#overview",
    "title": "Hands-on Exercise 1",
    "section": "1.0 Overview",
    "text": "1.0 Overview\nGeospatial Data Science is a process of importing, wrangling, integrating, and processing geographically referenced data sets. In this hands-on exercise, you will learn how to perform geospatial data science tasks in R by using sf package.\nBy the end of this hands-on exercise, you should acquire the following competencies:\n\ninstalling and loading sf and tidyverse packages into R environment,\nimporting geospatial data by using appropriate functions of sf package,\nimporting aspatial data by using appropriate function of readr package,\nexploring the content of simple feature data frame by using appropriate Base R and sf functions,\nassigning or transforming coordinate systems by using using appropriate sf functions,\nconverting an aspatial data into a sf data frame by using appropriate function of sf package,\nperforming geoprocessing tasks by using appropriate functions of sf package,\nperforming data wrangling tasks by using appropriate functions of dplyr package and\n\nperforming Exploratory Data Analysis (EDA) by using appropriate functions from ggplot2 package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#getting-started",
    "title": "Hands-on Exercise 1",
    "section": "2.0 Getting Started",
    "text": "2.0 Getting Started\nData are key to data analytics including geospatial analytics. Hence, before analysing, we need to assemble the necessary data. In this hands-on exercise, you are required to extract the necessary data sets from the following sources:\n\nMaster Plan 2014 Subzone Boundary (Web) from data.gov.sg\nPre-Schools Location from data.gov.sg\nCycling Path from LTADataMall\nLatest version of Singapore Airbnb listing data from Inside Airbnb\n\n\n2.1 Extracting the geospatial data sets\nNext, at the Hands-on_Ex01 folder, create a sub-folder called data. Then, inside the data sub-folder, create two sub-folders and name them geospatial and aspatial respectively.\nPlace Master Plan 2014 Subzone Boundary (Web), Pre-Schools Location and Cycling Path zipped files into geospatial sub-folder and unzipped them. Copy the unzipped files from their respective sub-folders and place them inside geospatial sub-folder.\n\n\n2.2 Extracting the aspatial data set\nNow, you will extract the downloaded listing data file. At Downloads folder, cut and paste listing.csv into aspatial sub-folder.\n\n\n2.3 Install R-Package\nIn this hands-on exercise, two R packages will be used. They are:\n\nsf for importing, managing, and processing geospatial data, and\ntidyverse for performing data science tasks such as importing, wrangling and visualising data.\n\nTidyverse consists of a family of R packages. In this hands-on exercise, the following packages will be used:\n\nreadr for importing csv data,\nreadxl for importing Excel worksheet,\ntidyr for manipulating data,\ndplyr for transforming data, and\nggplot2 for visualising data\n\nEnter the following:\n\npacman::p_load(sf, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-geospatial-data",
    "title": "Hands-on Exercise 1",
    "section": "3.0 Importing Geospatial Data",
    "text": "3.0 Importing Geospatial Data\nIn this section, you will import the following geospatial data into R by using st_read() of sf package:\n\nMP14_SUBZONE_WEB_PL, a polygon feature layer in ESRI shapefile format,\nCyclingPath, a line feature layer in ESRI shapefile format, and\nPreSchool, a point feature layer in kml file format.\n\n\n3.1 Importing polygon feature data in shapefile format\nThe the following code uses st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a polygon feature data frame.\n\nmpsz = st_read(dsn = \"../Hands-on_Ex01/data/geospatial/MasterPlan\", \n                  layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\SMU\\Y4S1\\IS415\\IS415\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\MasterPlan' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n3.2 Importing polyline feature data in shapefile form\nThe following code uses st_read() function of sf package to import CyclingPath shapefile into R as line feature data frame.\n\ncyclingpath = st_read(dsn = \"../Hands-on_Ex01/data/geospatial/CyclingPath\", \n                         layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\SMU\\Y4S1\\IS415\\IS415\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\CyclingPath' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3138 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42644.17 ymax: 48948.15\nProjected CRS: SVY21\n\n\n\n\n3.3 Importing GIS data in kml format\nThe PreSchoolsLocation is in kml format. The following code will be used to import the kml into R.\n\npreschool = st_read(\"../Hands-on_Ex01/data/geospatial/PreSchool/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\SMU\\Y4S1\\IS415\\IS415\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\PreSchool\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#checking-the-content-of-a-simple-feature-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#checking-the-content-of-a-simple-feature-data-frame",
    "title": "Hands-on Exercise 1",
    "section": "4.0 Checking the Content of A Simple Feature Data Frame",
    "text": "4.0 Checking the Content of A Simple Feature Data Frame\nThis section covers the different ways to retrieve information related to the contents of a data frame.\n\n4.1 st_geometry()\nThe column in the sf data.frame that contains the geometries is a list, of class sfc. We can retrieve the geometry list-column in this case by mpsz$geom or mpsz[[1]], but the more general way uses st_geometry() as shown in the following:\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303...\n\n\n\n\n4.2 glimpse()\nBeside the basic feature information, we also would like to learn more about the associated attribute information in the data frame. glimpse() of dplyr.\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\n\n\n4.3 head()\nSometimes we would like to reveal complete information of a feature object, this is the job of head() of Base R\n\nhead(mpsz, n=5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-geospatial-data",
    "title": "Hands-on Exercise 1",
    "section": "5.0 Plotting Geospatial Data",
    "text": "5.0 Plotting Geospatial Data\nIn geospatial data science, by looking at the feature information is not enough. We are also interested to visualise the geospatial features. This is the time you will find plot() of R Graphic comes in very handy as shown in the following:\n\nplot(mpsz)\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\nThe default plot of an sf object is a multi-plot of all attributes, up to a reasonable maximum as shown above. We can, however, choose to plot only the geometry by using the following:\n\nplot(st_geometry(mpsz))\n\n\n\n\n\n\n\n\nAlternatively, we can also choose the plot the sf object by using a specific attribute as shown in the following:\n\nplot(mpsz[\"PLN_AREA_N\"])"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-projection",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-projection",
    "title": "Hands-on Exercise 1",
    "section": "6.0 Working with Projection",
    "text": "6.0 Working with Projection\nMap projection is an important property of a geospatial data. In order to perform geoprocessing using two geospatial data, we need to ensure that both geospatial data are projected using similar coordinate system.\nIn this section, you will project a simple feature data frame form one coordinate system to another coordinate system. The technical term of this process is called projection transformation.\n\n6.1 Assigning EPSG code to a simple feature data frame\nOne of the common issue that can happen during importing geospatial data into R is that the coordinate system of the source data was either missing (such as due to missing .proj for ESRI shapefile) or wrongly assigned during the importing process.\nAn example the coordinate system of mpsz simple feature data frame by using st_crs() of sf package as shown in the following:\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough mpsz data frame is projected in svy21 but when we read until the end of the print, it indicates that the EPSG is 9001. This is a wrong EPSG code because the correct EPSG code for svy21 should be 3414.\nIn order to assign the correct EPSG code to mpsz data frame, st_set_crs() of sf package is used as shown in the following:\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\ncheck the CSR again by using the following:\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n6.2 Transforming the projection of preschool from wgs84 to svy21\nIn geospatial analytics, it is very common for us to transform the original data from geographic coordinate system to projected coordinate system. This is because geographic coordinate system is not appropriate if the analysis need to use distance or/and area measurements.\nLet us take preschool simple feature data frame as an example. The print below reveals that it is in wgs84 coordinate system.\nGeometry set for 2290 features  Geometry type: POINT Dimension:     XYZ Bounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134 z_range:       zmin: 0 zmax: 0 Geodetic CRS:  WGS 84 First 5 geometries:\nIn this scenario st_set_crs() is not appropriate and st_transform() of sf package should be used. This is because we need to reproject preschool from one coordinate system to another coordinate system mathemetically.\nPerform the projection transformation by using the following:\n\npreschool3414 &lt;- st_transform(preschool, \n                              crs = 3414)\n\nNext, let us display the content of preschool3414 sf data frame as shown below.\nGeometry set for 2290 features  Geometry type: POINT Dimension:     XYZ Bounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88 z_range:       zmin: 0 zmax: 0 Projected CRS: SVY21 / Singapore TM First 5 geometries:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-and-converting-an-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-and-converting-an-aspatial-data",
    "title": "Hands-on Exercise 1",
    "section": "7.0 Importing and Converting An Aspatial Data",
    "text": "7.0 Importing and Converting An Aspatial Data\nIn practice, it is not unusual that we will come across data such as listing of Inside Airbnb. We call this kind of data aspatial data. This is because it is not a geospatial data but among the data fields, there are two fields that capture the x- and y-coordinates of the data points.\nIn this section, you will learn how to import an aspatial data into R environment and save it as a tibble data frame. Next, you will convert it into a simple feature data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-aspatial-data",
    "title": "Hands-on Exercise 1",
    "section": "7.1 Importing the aspatial data",
    "text": "7.1 Importing the aspatial data\nSince listings data set is in csv file format, we will use read_csv() of readr package to import listing.csv as shown the code chunk below. The output R object is called listings and it is a tibble data frame.\n\nlistings &lt;- read_csv(\"../Hands-on_Ex01/data/aspatial/listings.csv\")\n\nRows: 3540 Columns: 18\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (6): name, host_name, neighbourhood_group, neighbourhood, room_type, l...\ndbl  (11): id, host_id, latitude, longitude, price, minimum_nights, number_o...\ndate  (1): last_review\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\nThe following shows list() of Base R instead of glimpse()\n\nlist(listings) \n\n[[1]]\n# A tibble: 3,540 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;               &lt;chr&gt;            &lt;dbl&gt;\n 1  71609 Ensuite …  367042 Belinda   East Region         Tampines          1.35\n 2  71896 B&B  Roo…  367042 Belinda   East Region         Tampines          1.35\n 3  71903 Room 2-n…  367042 Belinda   East Region         Tampines          1.35\n 4 275343 10min wa… 1439258 Kay       Central Region      Bukit Merah       1.29\n 5 275344 15 mins … 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 289234 Booking …  367042 Belinda   East Region         Tampines          1.34\n 7 294281 5 mins w… 1521514 Elizabeth Central Region      Newton            1.31\n 8 324945 Comforta… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 330095 Relaxing… 1439258 Kay       Central Region      Bukit Merah       1.29\n10 344803 Budget s…  367042 Belinda   East Region         Tampines          1.35\n# ℹ 3,530 more rows\n# ℹ 11 more variables: longitude &lt;dbl&gt;, room_type &lt;chr&gt;, price &lt;dbl&gt;,\n#   minimum_nights &lt;dbl&gt;, number_of_reviews &lt;dbl&gt;, last_review &lt;date&gt;,\n#   reviews_per_month &lt;dbl&gt;, calculated_host_listings_count &lt;dbl&gt;,\n#   availability_365 &lt;dbl&gt;, number_of_reviews_ltm &lt;dbl&gt;, license &lt;chr&gt;\n\n\n\n7.2 Creating a simple feature data frame from an aspatial data frame\nThe following listing data frame into a simple feature data frame by using st_as_sf() of sf packages\n\nlistings_sf &lt;- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\nLet us examine the content of this newly created simple feature data frame.\n\nglimpse(listings_sf)\n\nRows: 3,540\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Ensuite Room (Room 1 & 2) near EXPO\", …\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; NA, 80, 80, 50, 50, NA, 85, 65, 45, 54,…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 180, 180, 92, 92, 180, 180,…\n$ number_of_reviews              &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 131, 17, 5, 60,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.12, 0.15, 0.29, 0.15, 0.11, 0.08, 0.8…\n$ calculated_host_listings_count &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49, 49, 6, 7, 7,…\n$ availability_365               &lt;dbl&gt; 89, 148, 90, 62, 0, 88, 365, 0, 0, 365,…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 2, 0, 0, 1, 1, 1, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geoprocessing-with-sf-package",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geoprocessing-with-sf-package",
    "title": "Hands-on Exercise 1",
    "section": "8.0 Geoprocessing with sf package",
    "text": "8.0 Geoprocessing with sf package\nBesides providing functions to handling (i.e. importing, exporting, assigning projection, transforming projection etc) geospatial data, sf package also offers a wide range of geoprocessing (also known as GIS analysis) functions.\nIn this section, you will learn how to perform two commonly used geoprocessing functions, namely buffering and point in polygon count.\n\n8.1 Buffering\nThe scenario:\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\nThe solution:\nFirstly, st_buffer() of sf package is used to compute the 5-meter buffers around cycling paths\n\nbuffer_cycling &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 30)\n\nThis is followed by calculating the area of the buffers as shown in the following:\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nLastly, sum() of Base R will be used to derive the total land involved\n\nsum(buffer_cycling$AREA)\n\n2218855 [m^2]\n\n\n\n\n8.2 Point-in-polygon count\nThe scenario:\nA pre-school service group want to find out the numbers of pre-schools in each Planning Subzone.\nThe solution:\nThe code chunk below performs two operations at one go. Firstly, identify pre-schools located inside each Planning Subzone by using st_intersects(). Next, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\n\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\nYou can check the summary statistics of the newly derived PreSch Count field by using summary() as shown in the following:\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nTo list the planning subzone with the most number of pre-school, the top_n() of dplyr package is used as shown in the following:\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\n\nCalculate the density of pre-school by planning subzone\n\nFirstly, the code chunk below uses st_area() of sf package to derive the area of each planning subzone.\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%\n  st_area()\n\nNext, mutate() of dplyr package is used to compute the density by using the following\n\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#exploratory-data-analysis-eda",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#exploratory-data-analysis-eda",
    "title": "Hands-on Exercise 1",
    "section": "9.0 Exploratory Data Analysis (EDA)",
    "text": "9.0 Exploratory Data Analysis (EDA)\nIn practice, many geospatial analytics start with Exploratory Data Analysis. In this section, you will learn how to use appropriate ggplot2 functions to create functional and yet truthful statistical graphs for EDA purposes.\nFirstly, we will plot a histogram to reveal the distribution of PreSch Density. Conventionally, hist() of R Graphics will be used as shown in the following\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\n\n\n\n\nAlthough the syntax is very easy to use however the output is far from meeting publication quality. Furthermore, the function has limited room for further customisation.\nIn the code chunk below, appropriate ggplot2 functions will be used.\n\nggplot(data=mpsz3414, \n       aes(x= as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  labs(title = \"Are pre-school even distributed in Singapore?\",\n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Frequency\")\n\n\n\n\n\n\n\n\n\nUsing ggplot2 method, plot a scatterplot showing the relationship between Pre-school Density and Pre-school Count\n\n\nggplot(data=mpsz3414, \n       aes(y = `PreSch Count`, \n           x= as.numeric(`PreSch Density`)))+\n  geom_point(color=\"black\", \n             fill=\"light blue\") +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(title = \"\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Pre-school count\")\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands On Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "",
    "text": "Thematic mapping uses symbols on maps to visualize non-visible geographic properties like population, temperature, or crime rate. Geovisualization, however, graphically represents places, phenomena, or processes, engaging human spatial cognition and the eye-brain vision system for better understanding."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#overview",
    "title": "Hands On Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "",
    "text": "Thematic mapping uses symbols on maps to visualize non-visible geographic properties like population, temperature, or crime rate. Geovisualization, however, graphically represents places, phenomena, or processes, engaging human spatial cognition and the eye-brain vision system for better understanding."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#getting-started",
    "title": "Hands On Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "2.0 Getting Started",
    "text": "2.0 Getting Started\ntmap is the main package used, but four other packages are also used\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data.\n\n readr, tidyr and dplyr are part of tidyverse package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#dataset",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#dataset",
    "title": "Hands On Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "2.1 Dataset",
    "text": "2.1 Dataset\nMaster Plan 2014 Subzone Boundary (Web)\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-the-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-the-data-into-r",
    "title": "Hands On Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "2.2 Importing the data into R",
    "text": "2.2 Importing the data into R\n\npacman::p_load(sf, tmap, tidyverse)\n\n\nmpsz &lt;- st_read(dsn = \"data/geospatial/MasterPlan\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\SMU\\Y4S1\\IS415\\IS415\\Hands-on_Ex\\Hands-on_Ex02\\data\\geospatial\\MasterPlan' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nmpsz can be used to examine the contents\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nto import respopagsex2011to2020.csv file read_csv is used\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\nRows: 984656 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-preparation",
    "title": "Hands On Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "2.3 Data Preparation",
    "text": "2.3 Data Preparation\nTo prepare a thematic map with 2020 data, you first need to organize your data into a table with the following variables: PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n2.3.1 Data wrangling\nThese 2 will be used for data wrangling and transformation\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:13])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\n\n\n2.3.2 Joining attribute and geospatial data\nBefore performing the georelational join, the values in the PA and SZ fields need to be converted to uppercase. This step ensures consistency because the corresponding fields, SUBZONE_N and PLN_AREA_N, are already in uppercase. By converting PA and SZ to uppercase, you align the data formats, allowing the join operation to match values correctly across these fields.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nSave as rds file\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Hands On Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "3.0 Choropleth Mapping Geospatial Data Using tmap",
    "text": "3.0 Choropleth Mapping Geospatial Data Using tmap\nChoropleth mapping uses area patterns or graduated colors to symbolize enumeration units, like countries or census units. For instance, a social scientist could use a choropleth map to show the spatial distribution of the aged population in Singapore by the Master Plan 2014 Subzone Boundary.\nWhen using the tmap package in R, there are two approaches to create thematic maps:\n\nQuick Thematic Mapping with qtm(): This function allows for rapid creation of thematic maps with minimal code and default settings.\nCustomizable Thematic Mapping with tmap Elements: This approach enables the creation of more detailed and customized maps by combining various tmap elements, offering greater flexibility in design and layout.\n\n\n3.1 Plotting a choropleth map quickly by using qtm()\ntmap qtm() is the easiest and quickest way to draw a choropleth map. It provides a good default visualisation\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)\n\n\n\n3.2 Creating a choropleth map by using tmap’s elements\nWhile qtm() is useful for quickly and easily creating a choropleth map, its drawback is that it limits control over the aesthetics of individual layers. To produce a high-quality cartographic choropleth map, it’s better to use tmap’s drawing elements. This allows for precise control over the map’s appearance, such as color schemes, legend placement, and more detailed customization, resulting in a polished and professional map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\nDrawing a base map\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons().\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\ntm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons\n\n\nDrawing a choropleth map using tm_polygons()\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\nThe default interval binning used to draw the choropleth map is called “pretty”.\nThe default colour scheme used is YlOrRd of ColorBrewer.\nBy default, Missing value will be shaded in grey.\n\n\n\nDrawing a choropleth map using tm_fill() and *tm_border()**\nActually, tm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\ntm_borders is used to add the boundary of the planning zones\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\n\n\n\nAdditional arguments for tm_borders()\n\ncol = border colour,\nlwd = border line width. The default is 1\nlty = border line type. The default is “solid”"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-classification-methods-of-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-classification-methods-of-tmap",
    "title": "Hands On Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "4.0 Data classification methods of tmap",
    "text": "4.0 Data classification methods of tmap\nChoropleth maps often use data classification methods to group large numbers of observations into meaningful ranges or classes\ntmap provides ten data classification methods for this purpose:\n\nfixed\nsd\nequal\npretty\nquantile\nkmeans\nhclust\nbclust\nfisher\njenks\n\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\n4.1 Plotting choropleth maps with built-in classification methods\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nequal data classification method\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n4.2 Plotting choropleth map with custome break\nTo override the default category breaks in tmap, use the breaks argument in tm_fill(). When setting breaks, include both the minimum and maximum values, so for n categories, n+1 breakpoints must be provided. It’s recommended to first calculate descriptive statistics for the variable before setting the breakpoints. The code below shows how to compute and display descriptive statistics for the DEPENDENCY field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1000  0.5724  0.6170  0.6921  0.6804 19.0000      92 \n\n\nusing the reference, set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\nWarning: Values have found that are higher than the highest break"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#colour-scheme",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#colour-scheme",
    "title": "Hands On Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "5.0 Colour Scheme",
    "text": "5.0 Colour Scheme\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n5.1 Using ColourBrewer palette\nto change the color, assign it to tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nto reverse the color shading add a “-” prefix\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n5.2 Map Layouts\nMap layout involves combining various elements to create a cohesive map. These elements include the mapped objects, title, scale bar, compass, margins, and aspect ratios. Color settings and data classification methods, such as palette and breakpoints, also influence the map’s appearance.\n\n5.2.1 Map Legend\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\ntmap_style() can be used to change the layout settings\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\ntmap style set to \"classic\"\n\n\nother available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"watercolor\" \n\n\n\n\n\n\n\n\n\nMap furniture such as compass, scale bar and grid lines can also be drawn\ntm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nto reset to the default style\n\ntmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n5.3 Drawing Small Multiple Choropleth Maps\nSmall multiple maps, or facet maps, display several maps side-by-side or stacked to show how spatial relationships change with respect to another variable, like time.\nIn tmap, small multiple maps can be created in three ways:\n\nAssigning multiple values to at least one aesthetic argument.\nDefining a group-by variable using tm_facets().\nCreating multiple stand-alone maps with tmap_arrange().\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\n\n\n\nsmall multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n5.3.1 By defining a group-by variable in tm_facets()\nmultiple small choropleth maps are created by using tm_facets()\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\nWarning: The argument drop.shapes has been renamed to drop.units, and is\ntherefore deprecated\n\n\n\n\n\n\n\n\n\n\n\n5.3.2 Mappping Spatial Object Meeting a Selection Criterion\nInstead of creating small multiple choropleth map, selection function can be used to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\nWarning in pre_process_gt(x, interactive = interactive, orig_crs =\ngm$shape.orig_crs): legend.width controls the width of the legend within a map.\nPlease use legend.outside.size to control the width of the outside legend"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "title": "Hands-On Exercise 5: Spatial Weights and Applications",
    "section": "",
    "text": "This hands on teaches you how to compute spatial weights using R."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#overview",
    "title": "Hands-On Exercise 5: Spatial Weights and Applications",
    "section": "",
    "text": "This hands on teaches you how to compute spatial weights using R."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#data",
    "title": "Hands-On Exercise 5: Spatial Weights and Applications",
    "section": "2.0 Data",
    "text": "2.0 Data\n\nHunan county boundary layer. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#getting-started",
    "title": "Hands-On Exercise 5: Spatial Weights and Applications",
    "section": "3.0 Getting started",
    "text": "3.0 Getting started\nLoad the required packages\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#import-data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#import-data",
    "title": "Hands-On Exercise 5: Spatial Weights and Applications",
    "section": "4.0 Import Data",
    "text": "4.0 Import Data\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\SMU\\Y4S1\\IS415\\IS415\\Hands-on_Ex\\Hands-on_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWe have to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe by using left_join()\n\nhunan &lt;- left_join(hunan,hunan2012)%&gt;%\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-the-data",
    "title": "Hands-On Exercise 5: Spatial Weights and Applications",
    "section": "5.0 Visualising the data",
    "text": "5.0 Visualising the data\n\nbasemap &lt;- tm_shape(hunan) +\n  tm_polygons() +\n  tm_text(\"NAME_3\", size=0.5)\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\ntmap_arrange(basemap, gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#computing-contiguity-spatial-weights",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#computing-contiguity-spatial-weights",
    "title": "Hands-On Exercise 5: Spatial Weights and Applications",
    "section": "6.0 Computing Contiguity Spatial Weights",
    "text": "6.0 Computing Contiguity Spatial Weights\nThis section teaches the poly2nb() of spdep package to compute contiguity weight matrices for the study area\n\n6.1 QUEEN Contiguity Based Neighbours\n\nwm_q &lt;- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one heighbours.\nFor each polygon in our polygon object, wm_q lists all neighboring polygons.\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\nRetrive the county name of Polygon ID=1\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\nTo reveal the county names of the five neighboring polygons\n\nhunan$NAME_3[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nTo retrieve the GDPPC of these 5 countries\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nTo display the complete weight matrix\n\nstr(wm_q)\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"snap\")= num 9e-08\n - attr(*, \"sym\")= logi TRUE\n - attr(*, \"ncomp\")=List of 2\n  ..$ nc     : int 1\n  ..$ comp.id: int [1:88] 1 1 1 1 1 1 1 1 1 1 ...\n\n\n\n\n6.2 Creating (ROOK) contiguity based neighbours\nCompute ROOK contiguity weight matrix\n\nwm_r &lt;- poly2nb(hunan, queen=FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connect area unit has 10 neighbours. There are two area units with only one heighbours.\n\n\n6.3 Visualising contiguity weights\nA connectivity graph takes a point and displays a line to each neighboring point. We are working with polygons at the moment, so we will need to get points in order to make our connectivity graphs. The most typically method for this will be polygon centroids. We will calculate these in the sf package before moving onto the graphs. Getting Latitude and Longitude of Polygon Centroids\nWe will need points to associate with each polygon before we can make our connectivity graph. It will be a little more complicated than just running st_centroid on the sf object: us.bound. We need the coordinates in a separate data frame for this to work. To do this we will use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of us.bound. Our function will be st_centroid. We will be using map_dbl variation of map from the purrr package. For more documentation, check out map documentation\nTo get our longitude values we map the st_centroid function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nDo the same for latitude but we access the second value per each centroid with [[2]]\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\ncbind to put longitude and latitude into the same object\n\ncoords &lt;- cbind(longitude, latitude)\n\ncheck formatting\n\nhead(coords)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\n\nPlotting Queen contiguity based neighbours map\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\n\n\n\n\n\n\n\n\n\n\nPlotting Rook contiguity based neighbours map\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\n\n\n\nPlotting both Queen and Rook contiguity based neighbours maps\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"Queen Contiguity\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\nplot(hunan$geometry, border=\"lightgrey\", main=\"Rook Contiguity\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#computing-distance-based-neighbours",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#computing-distance-based-neighbours",
    "title": "Hands-On Exercise 5: Spatial Weights and Applications",
    "section": "7.0 Computing distance based neighbours",
    "text": "7.0 Computing distance based neighbours\nThis section teachs how to derive distance-based weight matrices by using dnearneigh() of spdep package\n\n7.1 Determine the cut-off distance\nFirstly, we need to determine the upper limit for distance band by using the steps below:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\n#coords &lt;- coordinates(hunan)\nk1 &lt;- knn2nb(knearneigh(coords))\n\nWarning in knn2nb(knearneigh(coords)): neighbour object has 25 sub-graphs\n\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\n\n\n7.2 Computing fixed distance weight matrix\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nDisplay the content of wm_d62 weight matrix\n\nstr(wm_d62)\n\nList of 88\n $ : int [1:5] 3 4 5 57 64\n $ : int [1:4] 57 58 78 85\n $ : int [1:4] 1 4 5 57\n $ : int [1:3] 1 3 5\n $ : int [1:4] 1 3 4 85\n $ : int 69\n $ : int [1:2] 67 84\n $ : int [1:4] 9 46 47 78\n $ : int [1:4] 8 46 68 84\n $ : int [1:4] 16 22 70 72\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:2] 11 17\n $ : int 13\n $ : int [1:4] 10 17 22 83\n $ : int [1:3] 11 14 16\n $ : int [1:3] 20 22 63\n $ : int [1:5] 20 21 73 74 82\n $ : int [1:5] 18 19 21 22 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:4] 10 16 18 20\n $ : int [1:3] 41 77 82\n $ : int [1:4] 25 28 31 54\n $ : int [1:4] 24 28 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:2] 26 29\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:2] 27 37\n $ : int 33\n $ : int [1:2] 24 36\n $ : int 50\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:5] 31 34 45 56 80\n $ : int [1:2] 29 42\n $ : int [1:3] 44 77 79\n $ : int [1:4] 40 42 43 81\n $ : int [1:3] 39 45 79\n $ : int [1:5] 23 35 45 79 82\n $ : int [1:5] 26 37 39 43 81\n $ : int [1:3] 39 42 44\n $ : int [1:2] 38 43\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:5] 8 9 35 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:4] 48 49 50 52\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:2] 48 55\n $ : int [1:5] 24 28 49 50 52\n $ : int [1:4] 48 50 53 75\n $ : int 36\n $ : int [1:5] 1 2 3 58 64\n $ : int [1:5] 2 57 64 66 68\n $ : int [1:3] 60 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:5] 12 60 62 63 87\n $ : int [1:4] 61 63 77 87\n $ : int [1:5] 12 18 61 62 83\n $ : int [1:4] 1 57 58 76\n $ : int 76\n $ : int [1:5] 58 67 68 76 84\n $ : int [1:2] 7 66\n $ : int [1:4] 9 58 66 84\n $ : int [1:2] 6 75\n $ : int [1:3] 10 72 73\n $ : int [1:2] 73 74\n $ : int [1:3] 10 11 70\n $ : int [1:4] 19 70 71 74\n $ : int [1:5] 19 21 71 73 86\n $ : int [1:2] 55 69\n $ : int [1:3] 64 65 66\n $ : int [1:3] 23 38 62\n $ : int [1:2] 2 8\n $ : int [1:4] 38 40 41 45\n $ : int [1:5] 34 35 36 45 47\n $ : int [1:5] 25 26 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:4] 12 13 16 63\n $ : int [1:4] 7 9 66 68\n $ : int [1:2] 2 5\n $ : int [1:4] 21 46 47 74\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language dnearneigh(x = coords, d1 = 0, d2 = 62, longlat = TRUE)\n - attr(*, \"dnn\")= num [1:2] 0 62\n - attr(*, \"bounds\")= chr [1:2] \"GE\" \"LE\"\n - attr(*, \"nbtype\")= chr \"distance\"\n - attr(*, \"sym\")= logi TRUE\n - attr(*, \"ncomp\")=List of 2\n  ..$ nc     : int 1\n  ..$ comp.id: int [1:88] 1 1 1 1 1 1 1 1 1 1 ...\n\n\nAnother way to display the structure of the weight matrix is to combine table() and card() of spdep\n\ntable(hunan$County, card(wm_d62))\n\n               \n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\n\nn_comp &lt;- n.comp.nb(wm_d62)\nn_comp$nc\n\n[1] 1\n\n\n\ntable(n_comp$comp.id)\n\n\n 1 \n88 \n\n\n\n\n7.3 Plotting fixed distance weight matrix\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE)\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\n\n\n\n\n\n\n\n\nThe red lines show the links of 1st nearest neighbours and the black lines show the links of neighbours within the cut-off distance of 62km.\nAnother way to plot them next to each other\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"1st nearest neighbours\")\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\nplot(hunan$geometry, border=\"lightgrey\", main=\"Distance link\")\nplot(wm_d62, coords, add=TRUE, pch = 19, cex = 0.6)\n\n\n\n\n\n\n\n\n\n\n7.4 Computing adaptive distance weight matrix\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry\n\nknn6 &lt;- knn2nb(knearneigh(coords, k=6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\n\nstr(knn6)\n\nList of 88\n $ : int [1:6] 2 3 4 5 57 64\n $ : int [1:6] 1 3 57 58 78 85\n $ : int [1:6] 1 2 4 5 57 85\n $ : int [1:6] 1 3 5 6 69 85\n $ : int [1:6] 1 3 4 6 69 85\n $ : int [1:6] 3 4 5 69 75 85\n $ : int [1:6] 9 66 67 71 74 84\n $ : int [1:6] 9 46 47 78 80 86\n $ : int [1:6] 8 46 66 68 84 86\n $ : int [1:6] 16 19 22 70 72 73\n $ : int [1:6] 10 14 16 17 70 72\n $ : int [1:6] 13 15 60 61 63 83\n $ : int [1:6] 12 15 60 61 63 83\n $ : int [1:6] 11 15 16 17 72 83\n $ : int [1:6] 12 13 14 17 60 83\n $ : int [1:6] 10 11 17 22 72 83\n $ : int [1:6] 10 11 14 16 72 83\n $ : int [1:6] 20 22 23 63 77 83\n $ : int [1:6] 10 20 21 73 74 82\n $ : int [1:6] 18 19 21 22 23 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:6] 10 16 18 19 20 83\n $ : int [1:6] 18 20 41 77 79 82\n $ : int [1:6] 25 28 31 52 54 81\n $ : int [1:6] 24 28 31 33 54 81\n $ : int [1:6] 25 27 29 33 42 81\n $ : int [1:6] 26 29 30 37 42 81\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:6] 26 27 37 42 43 81\n $ : int [1:6] 26 27 28 33 49 81\n $ : int [1:6] 24 25 36 39 40 54\n $ : int [1:6] 24 31 50 54 55 56\n $ : int [1:6] 25 26 28 30 49 81\n $ : int [1:6] 36 40 41 45 56 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:6] 26 27 29 42 43 44\n $ : int [1:6] 23 43 44 62 77 79\n $ : int [1:6] 25 40 42 43 44 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:6] 26 27 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:6] 37 38 39 42 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:6] 8 9 35 47 78 86\n $ : int [1:6] 8 21 35 46 80 86\n $ : int [1:6] 49 50 51 52 53 55\n $ : int [1:6] 28 33 48 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:6] 28 48 49 50 52 54\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:6] 48 50 51 52 55 75\n $ : int [1:6] 24 28 49 50 51 52\n $ : int [1:6] 32 48 50 52 53 75\n $ : int [1:6] 32 34 36 78 80 85\n $ : int [1:6] 1 2 3 58 64 68\n $ : int [1:6] 2 57 64 66 68 78\n $ : int [1:6] 12 13 60 61 87 88\n $ : int [1:6] 12 13 59 61 63 87\n $ : int [1:6] 12 13 60 62 63 87\n $ : int [1:6] 12 38 61 63 77 87\n $ : int [1:6] 12 18 60 61 62 83\n $ : int [1:6] 1 3 57 58 68 76\n $ : int [1:6] 58 64 66 67 68 76\n $ : int [1:6] 9 58 67 68 76 84\n $ : int [1:6] 7 65 66 68 76 84\n $ : int [1:6] 9 57 58 66 78 84\n $ : int [1:6] 4 5 6 32 75 85\n $ : int [1:6] 10 16 19 22 72 73\n $ : int [1:6] 7 19 73 74 84 86\n $ : int [1:6] 10 11 14 16 17 70\n $ : int [1:6] 10 19 21 70 71 74\n $ : int [1:6] 19 21 71 73 84 86\n $ : int [1:6] 6 32 50 53 55 69\n $ : int [1:6] 58 64 65 66 67 68\n $ : int [1:6] 18 23 38 61 62 63\n $ : int [1:6] 2 8 9 46 58 68\n $ : int [1:6] 38 40 41 43 44 45\n $ : int [1:6] 34 35 36 41 45 47\n $ : int [1:6] 25 26 28 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:6] 12 13 15 16 22 63\n $ : int [1:6] 7 9 66 68 71 74\n $ : int [1:6] 2 3 4 5 56 69\n $ : int [1:6] 8 9 21 46 47 74\n $ : int [1:6] 59 60 61 62 63 88\n $ : int [1:6] 59 60 61 62 63 87\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language knearneigh(x = coords, k = 6)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 6\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"ncomp\")=List of 2\n  ..$ nc     : int 1\n  ..$ comp.id: int [1:88] 1 1 1 1 1 1 1 1 1 1 ...\n\n\nPlot the distance based neighbours\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#weights-based-on-idw",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#weights-based-on-idw",
    "title": "Hands-On Exercise 5: Spatial Weights and Applications",
    "section": "8.0 Weights based on IDW",
    "text": "8.0 Weights based on IDW\nThis section we will learn how to derive a spatial weight matrix based on Inversed Distance method.\nFirst, we will compute the distances between areas by using nbdists() of spdep.\n\ndist &lt;- nbdists(wm_q, coords, longlat = TRUE)\nids &lt;- lapply(dist, function(x) 1/(x))\nids\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n[[2]]\n[1] 0.01535405 0.01764308 0.01925924 0.02323898 0.01719350\n\n[[3]]\n[1] 0.03916350 0.02822040 0.03695795 0.01395765\n\n[[4]]\n[1] 0.01820896 0.02822040 0.03414741 0.01539065\n\n[[5]]\n[1] 0.03695795 0.03414741 0.01524598 0.01618354\n\n[[6]]\n[1] 0.015390649 0.015245977 0.021748129 0.011883901 0.009810297\n\n[[7]]\n[1] 0.01708612 0.01473997 0.01150924 0.01872915\n\n[[8]]\n[1] 0.02022144 0.03453056 0.02529256 0.01036340 0.02284457 0.01500600 0.01515314\n\n[[9]]\n[1] 0.02022144 0.01574888 0.02109502 0.01508028 0.02902705 0.01502980\n\n[[10]]\n[1] 0.02281552 0.01387777 0.01538326 0.01346650 0.02100510 0.02631658 0.01874863\n[8] 0.01500046\n\n[[11]]\n[1] 0.01882869 0.02243492 0.02247473\n\n[[12]]\n[1] 0.02779227 0.02419652 0.02333385 0.02986130 0.02335429\n\n[[13]]\n[1] 0.02779227 0.02650020 0.02670323 0.01714243\n\n[[14]]\n[1] 0.01882869 0.01233868 0.02098555\n\n[[15]]\n[1] 0.02650020 0.01233868 0.01096284 0.01562226\n\n[[16]]\n[1] 0.02281552 0.02466962 0.02765018 0.01476814 0.01671430\n\n[[17]]\n[1] 0.01387777 0.02243492 0.02098555 0.01096284 0.02466962 0.01593341 0.01437996\n\n[[18]]\n[1] 0.02039779 0.02032767 0.01481665 0.01473691 0.01459380\n\n[[19]]\n[1] 0.01538326 0.01926323 0.02668415 0.02140253 0.01613589 0.01412874\n\n[[20]]\n[1] 0.01346650 0.02039779 0.01926323 0.01723025 0.02153130 0.01469240 0.02327034\n\n[[21]]\n[1] 0.02668415 0.01723025 0.01766299 0.02644986 0.02163800\n\n[[22]]\n[1] 0.02100510 0.02765018 0.02032767 0.02153130 0.01489296\n\n[[23]]\n[1] 0.01481665 0.01469240 0.01401432 0.02246233 0.01880425 0.01530458 0.01849605\n\n[[24]]\n[1] 0.02354598 0.01837201 0.02607264 0.01220154 0.02514180\n\n[[25]]\n[1] 0.02354598 0.02188032 0.01577283 0.01949232 0.02947957\n\n[[26]]\n[1] 0.02155798 0.01745522 0.02212108 0.02220532\n\n[[27]]\n[1] 0.02155798 0.02490625 0.01562326\n\n[[28]]\n[1] 0.01837201 0.02188032 0.02229549 0.03076171 0.02039506\n\n[[29]]\n[1] 0.02490625 0.01686587 0.01395022\n\n[[30]]\n[1] 0.02090587\n\n[[31]]\n[1] 0.02607264 0.01577283 0.01219005 0.01724850 0.01229012 0.01609781 0.01139438\n[8] 0.01150130\n\n[[32]]\n[1] 0.01220154 0.01219005 0.01712515 0.01340413 0.01280928 0.01198216 0.01053374\n[8] 0.01065655\n\n[[33]]\n[1] 0.01949232 0.01745522 0.02229549 0.02090587 0.01979045\n\n[[34]]\n[1] 0.03113041 0.03589551 0.02882915\n\n[[35]]\n[1] 0.01766299 0.02185795 0.02616766 0.02111721 0.02108253 0.01509020\n\n[[36]]\n[1] 0.01724850 0.03113041 0.01571707 0.01860991 0.02073549 0.01680129\n\n[[37]]\n[1] 0.01686587 0.02234793 0.01510990 0.01550676\n\n[[38]]\n[1] 0.01401432 0.02407426 0.02276151 0.01719415\n\n[[39]]\n[1] 0.01229012 0.02172543 0.01711924 0.02629732 0.01896385\n\n[[40]]\n[1] 0.01609781 0.01571707 0.02172543 0.01506473 0.01987922 0.01894207\n\n[[41]]\n[1] 0.02246233 0.02185795 0.02205991 0.01912542 0.01601083 0.01742892\n\n[[42]]\n[1] 0.02212108 0.01562326 0.01395022 0.02234793 0.01711924 0.01836831 0.01683518\n\n[[43]]\n[1] 0.01510990 0.02629732 0.01506473 0.01836831 0.03112027 0.01530782\n\n[[44]]\n[1] 0.01550676 0.02407426 0.03112027 0.01486508\n\n[[45]]\n[1] 0.03589551 0.01860991 0.01987922 0.02205991 0.02107101 0.01982700\n\n[[46]]\n[1] 0.03453056 0.04033752 0.02689769\n\n[[47]]\n[1] 0.02529256 0.02616766 0.04033752 0.01949145 0.02181458\n\n[[48]]\n[1] 0.02313819 0.03370576 0.02289485 0.01630057 0.01818085\n\n[[49]]\n[1] 0.03076171 0.02138091 0.02394529 0.01990000\n\n[[50]]\n[1] 0.01712515 0.02313819 0.02551427 0.02051530 0.02187179\n\n[[51]]\n[1] 0.03370576 0.02138091 0.02873854\n\n[[52]]\n[1] 0.02289485 0.02394529 0.02551427 0.02873854 0.03516672\n\n[[53]]\n[1] 0.01630057 0.01979945 0.01253977\n\n[[54]]\n[1] 0.02514180 0.02039506 0.01340413 0.01990000 0.02051530 0.03516672\n\n[[55]]\n[1] 0.01280928 0.01818085 0.02187179 0.01979945 0.01882298\n\n[[56]]\n[1] 0.01036340 0.01139438 0.01198216 0.02073549 0.01214479 0.01362855 0.01341697\n\n[[57]]\n[1] 0.028079221 0.017643082 0.031423501 0.029114131 0.013520292 0.009903702\n\n[[58]]\n[1] 0.01925924 0.03142350 0.02722997 0.01434859 0.01567192\n\n[[59]]\n[1] 0.01696711 0.01265572 0.01667105 0.01785036\n\n[[60]]\n[1] 0.02419652 0.02670323 0.01696711 0.02343040\n\n[[61]]\n[1] 0.02333385 0.01265572 0.02343040 0.02514093 0.02790764 0.01219751 0.02362452\n\n[[62]]\n[1] 0.02514093 0.02002219 0.02110260\n\n[[63]]\n[1] 0.02986130 0.02790764 0.01407043 0.01805987\n\n[[64]]\n[1] 0.02911413 0.01689892\n\n[[65]]\n[1] 0.02471705\n\n[[66]]\n[1] 0.01574888 0.01726461 0.03068853 0.01954805 0.01810569\n\n[[67]]\n[1] 0.01708612 0.01726461 0.01349843 0.01361172\n\n[[68]]\n[1] 0.02109502 0.02722997 0.03068853 0.01406357 0.01546511\n\n[[69]]\n[1] 0.02174813 0.01645838 0.01419926\n\n[[70]]\n[1] 0.02631658 0.01963168 0.02278487\n\n[[71]]\n[1] 0.01473997 0.01838483 0.03197403\n\n[[72]]\n[1] 0.01874863 0.02247473 0.01476814 0.01593341 0.01963168\n\n[[73]]\n[1] 0.01500046 0.02140253 0.02278487 0.01838483 0.01652709\n\n[[74]]\n[1] 0.01150924 0.01613589 0.03197403 0.01652709 0.01342099 0.02864567\n\n[[75]]\n[1] 0.011883901 0.010533736 0.012539774 0.018822977 0.016458383 0.008217581\n\n[[76]]\n[1] 0.01352029 0.01434859 0.01689892 0.02471705 0.01954805 0.01349843 0.01406357\n\n[[77]]\n[1] 0.014736909 0.018804247 0.022761507 0.012197506 0.020022195 0.014070428\n[7] 0.008440896\n\n[[78]]\n[1] 0.02323898 0.02284457 0.01508028 0.01214479 0.01567192 0.01546511 0.01140779\n\n[[79]]\n[1] 0.01530458 0.01719415 0.01894207 0.01912542 0.01530782 0.01486508 0.02107101\n\n[[80]]\n[1] 0.01500600 0.02882915 0.02111721 0.01680129 0.01601083 0.01982700 0.01949145\n[8] 0.01362855\n\n[[81]]\n[1] 0.02947957 0.02220532 0.01150130 0.01979045 0.01896385 0.01683518\n\n[[82]]\n[1] 0.02327034 0.02644986 0.01849605 0.02108253 0.01742892\n\n[[83]]\n[1] 0.023354289 0.017142433 0.015622258 0.016714303 0.014379961 0.014593799\n[7] 0.014892965 0.018059871 0.008440896\n\n[[84]]\n[1] 0.01872915 0.02902705 0.01810569 0.01361172 0.01342099 0.01297994\n\n[[85]]\n [1] 0.011451133 0.017193502 0.013957649 0.016183544 0.009810297 0.010656545\n [7] 0.013416965 0.009903702 0.014199260 0.008217581 0.011407794\n\n[[86]]\n[1] 0.01515314 0.01502980 0.01412874 0.02163800 0.01509020 0.02689769 0.02181458\n[8] 0.02864567 0.01297994\n\n[[87]]\n[1] 0.01667105 0.02362452 0.02110260 0.02058034\n\n[[88]]\n[1] 0.01785036 0.02058034"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#row-standardised-weights-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#row-standardised-weights-matrix",
    "title": "Hands-On Exercise 5: Spatial Weights and Applications",
    "section": "9.0 Row-standardised Weights Matrix",
    "text": "9.0 Row-standardised Weights Matrix\nNext, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summaries the neighbors’ values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”\n\nrswm_q &lt;- nb2listw(wm_q, style=\"W\", zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nTo see the weight of the first polygon’s eight neighbors type:\n\nrswm_q$weights[10]\n\n[[1]]\n[1] 0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125\n\n\nUsing the same method, we can also derive a row standardised distance weight matrix \n\nrswm_ids &lt;- nb2listw(wm_q, glist=ids, style=\"B\", zero.policy=TRUE)\nrswm_ids\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn       S0        S1     S2\nB 88 7744 8.786867 0.3776535 3.8137\n\n\n\nrswm_ids$weights[1]\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n\n\nsummary(unlist(rswm_ids$weights))\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.008218 0.015088 0.018739 0.019614 0.022823 0.040338"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#application-of-spatial-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#application-of-spatial-weight-matrix",
    "title": "Hands-On Exercise 5: Spatial Weights and Applications",
    "section": "10.0 Application of Spatial Weight Matrix",
    "text": "10.0 Application of Spatial Weight Matrix\n\n10.1 Spatial lag with row-standardized weights\nCompute average neighbour GDPPC value for each polygon\n\nGDPPC.lag &lt;- lag.listw(rswm_q, hunan$GDPPC)\nGDPPC.lag\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nAppend the spatially lag GDPPC values onto hunan sf data frame\n\nlag.list &lt;- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag.list)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag GDPPC\")\nhunan &lt;- left_join(hunan,lag.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\nshow average neighbouring income values\n\nhead(hunan)\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3  County GDPPC lag GDPPC\n1 Changde 21098 Anxiang      County Anxiang 23667  24847.20\n2 Changde 21100 Hanshou      County Hanshou 20981  22724.80\n3 Changde 21101  Jinshi County City  Jinshi 34592  24143.25\n4 Changde 21102      Li      County      Li 24473  27737.50\n5 Changde 21103   Linli      County   Linli 25554  27270.25\n6 Changde 21104  Shimen      County  Shimen 27137  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\nplot both the GDPPC and spatial lag GDPPC for comparison\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_gdppc &lt;- qtm(hunan, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n10.2 Spatial lag as a sum of neighboring values\nWe can calculate spatial lag as a sum of neighboring values by assigning binary weights. This requires us to go back to our neighbors list, then apply a function that will assign binary weights, then we use glist = in the nb2listw function to explicitly assign these weights.\n\nb_weights &lt;- lapply(wm_q, function(x) 0*x + 1)\nb_weights2 &lt;- nb2listw(wm_q, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nUse lag.listw to compute a lag variable\n\nlag_sum &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag_sum)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag_sum GDPPC\")\n\n\nlag_sum\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\nAppend the lag_sum GDPPC field into hunan sf data frame\n\nhunan &lt;- left_join(hunan, lag.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\nPlot both the GDPPC and Spatial Lag Sum GDPPC for comparison\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_sum_gdppc &lt;- qtm(hunan, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n10.3 Spatial window average\nThe spatial window average uses row-standardized weights and includes the diagonal element. To do this in R, we need to go back to the neighbors structure and add the diagonal element before assigning weights.\n\nwm_qs &lt;- include.self(wm_q)\n\nneighbour list of area 1\n\nwm_qs[[1]]\n\n[1]  1  2  3  4 57 85\n\n\n\nwm_qs &lt;- nb2listw(wm_qs)\nwm_qs\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\n\n\nCreate lag variable from weight structure and GDPPC variable\n\nlag_w_avg_gpdpc &lt;- lag.listw(wm_qs, \n                             hunan$GDPPC)\nlag_w_avg_gpdpc\n\n [1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17 47621.20 37160.12\n [9] 49224.71 29886.89 26627.50 22690.17 25366.40 25825.75 30329.00 32682.83\n[17] 25948.62 23987.67 25463.14 21904.38 23127.50 25949.83 20018.75 19524.17\n[25] 18955.00 17800.40 15883.00 18831.33 14832.50 17965.00 17159.89 16199.44\n[33] 18764.50 26878.75 23188.86 20788.14 12365.20 15985.00 13764.83 11907.43\n[41] 17128.14 14593.62 11644.29 12706.00 21712.29 43548.25 35049.00 16226.83\n[49] 19294.40 18156.00 19954.75 18145.17 12132.75 18419.29 14050.83 23619.75\n[57] 24552.71 24733.67 16762.60 20932.60 19467.75 18334.00 22541.00 26028.00\n[65] 29128.50 46569.00 47576.60 36545.50 20838.50 22531.00 42115.50 27619.00\n[73] 27611.33 44523.29 18127.43 28746.38 20734.50 33880.62 14716.38 28516.22\n[81] 18086.14 21244.50 29568.80 48119.71 22310.75 43151.60 17133.40 17009.33\n\n\nConvert lag variable into listw object\n\nlag.list.wm_qs &lt;- list(hunan$NAME_3, lag.listw(wm_qs, hunan$GDPPC))\nlag_wm_qs.res &lt;- as.data.frame(lag.list.wm_qs)\ncolnames(lag_wm_qs.res) &lt;- c(\"NAME_3\", \"lag_window_avg GDPPC\")\n\nappend lag_window_avg GDPPC values onto hunan sf data.frame\n\nhunan &lt;- left_join(hunan, lag_wm_qs.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\ncompare the values of lag GDPPC and Spatial window average\n\nhunan %&gt;%\n  select(\"County\", \n         \"lag GDPPC\", \n         \"lag_window_avg GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag GDPPC\nlag_window_avg GDPPC\ngeometry\n\n\n\n\nAnxiang\n24847.20\n24650.50\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n22724.80\n22434.17\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n24143.25\n26233.00\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n27737.50\n27084.60\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n27270.25\n26927.00\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n21248.80\n22230.17\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n43747.00\n47621.20\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n33582.71\n37160.12\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n45651.17\n49224.71\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n32027.62\n29886.89\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n32671.00\n26627.50\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n20810.00\n22690.17\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n25711.50\n25366.40\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n30672.33\n25825.75\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n33457.75\n30329.00\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n31689.20\n32682.83\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n20269.00\n25948.62\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n23901.60\n23987.67\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n25126.17\n25463.14\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n21903.43\n21904.38\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n22718.60\n23127.50\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n25918.80\n25949.83\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n20307.00\n20018.75\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n20023.80\n19524.17\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n16576.80\n18955.00\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n18667.00\n17800.40\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n14394.67\n15883.00\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n19848.80\n18831.33\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n15516.33\n14832.50\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518.00\n17965.00\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n17572.00\n17159.89\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n15200.12\n16199.44\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n18413.80\n18764.50\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n14419.33\n26878.75\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n24094.50\n23188.86\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n22019.83\n20788.14\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n12923.50\n12365.20\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n14756.00\n15985.00\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n13869.80\n13764.83\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n12296.67\n11907.43\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n15775.17\n17128.14\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n14382.86\n14593.62\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n11566.33\n11644.29\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n13199.50\n12706.00\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n23412.00\n21712.29\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n39541.00\n43548.25\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n36186.60\n35049.00\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n16559.60\n16226.83\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n20772.50\n19294.40\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n19471.20\n18156.00\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n19827.33\n19954.75\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n15466.80\n18145.17\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n12925.67\n12132.75\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n18577.17\n18419.29\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n14943.00\n14050.83\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n24913.00\n23619.75\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n25093.00\n24552.71\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n24428.80\n24733.67\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n17003.00\n16762.60\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n21143.75\n20932.60\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n20435.00\n19467.75\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n17131.33\n18334.00\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n24569.75\n22541.00\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n23835.50\n26028.00\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360.00\n29128.50\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n47383.40\n46569.00\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n55157.75\n47576.60\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n37058.00\n36545.50\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n21546.67\n20838.50\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n23348.67\n22531.00\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n42323.67\n42115.50\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n28938.60\n27619.00\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n25880.80\n27611.33\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n47345.67\n44523.29\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n18711.33\n18127.43\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n29087.29\n28746.38\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n20748.29\n20734.50\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n35933.71\n33880.62\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n15439.71\n14716.38\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n29787.50\n28516.22\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n18145.00\n18086.14\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n21617.00\n21244.50\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n29203.89\n29568.80\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n41363.67\n48119.71\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n22259.09\n22310.75\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n44939.56\n43151.60\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n16902.00\n17133.40\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n16930.00\n17009.33\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nplot the lag_gdppc and w_ave_gdppc \n\nw_avg_gdppc &lt;- qtm(hunan, \"lag_window_avg GDPPC\")\ntmap_arrange(lag_gdppc, w_avg_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n10.4 Spatial window sum\nThe spatial window sum is the counter part of the window average, but without using row-standardized weights.\n\nwm_qs &lt;- include.self(wm_q)\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\n\nb_weights &lt;- lapply(wm_qs, function(x) 0*x + 1)\nb_weights[1]\n\n[[1]]\n[1] 1 1 1 1 1 1\n\n\n\nb_weights2 &lt;- nb2listw(wm_qs, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 536 1072 14160\n\n\ncompute the lag variable\n\nw_sum_gdppc &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nw_sum_gdppc\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 147903 134605 131165 135423 134635 133381 238106 297281 344573 268982\n[11] 106510 136141 126832 103303 151645 196097 207589 143926 178242 175235\n[21] 138765 155699 160150 117145 113730  89002  63532 112988  59330  35930\n[31] 154439 145795 112587 107515 162322 145517  61826  79925  82589  83352\n[41] 119897 116749  81510  63530 151986 174193 210294  97361  96472 108936\n[51]  79819 108871  48531 128935  84305 188958 171869 148402  83813 104663\n[61] 155742  73336 112705  78084  58257 279414 237883 219273  83354  90124\n[71] 168462 165714 165668 311663 126892 229971 165876 271045 117731 256646\n[81] 126603 127467 295688 336838 267729 431516  85667  51028\n\n\nconvert the lag variable listw object into a data.frame\n\nw_sum_gdppc.res &lt;- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) &lt;- c(\"NAME_3\", \"w_sum GDPPC\")\n\nappend w_sum GDPPC values onto hunan sf data.frame\n\nhunan &lt;- left_join(hunan, w_sum_gdppc.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\ncompare the values of lag GDPPC and Spatial window sum\n\nhunan %&gt;%\n  select(\"County\", \"lag_sum GDPPC\", \"w_sum GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag_sum GDPPC\nw_sum GDPPC\ngeometry\n\n\n\n\nAnxiang\n124236\n147903\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n113624\n134605\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n96573\n131165\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n110950\n135423\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n109081\n134635\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n106244\n133381\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n174988\n238106\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n235079\n297281\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n273907\n344573\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n256221\n268982\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n98013\n106510\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n104050\n136141\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n102846\n126832\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n92017\n103303\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n133831\n151645\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n158446\n196097\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n141883\n207589\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n119508\n143926\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n150757\n178242\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n153324\n175235\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n113593\n138765\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n129594\n155699\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n142149\n160150\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n100119\n117145\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n82884\n113730\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n74668\n89002\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n43184\n63532\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n99244\n112988\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n46549\n59330\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518\n35930\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n140576\n154439\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n121601\n145795\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n92069\n112587\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n43258\n107515\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n144567\n162322\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n132119\n145517\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n51694\n61826\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n59024\n79925\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n69349\n82589\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n73780\n83352\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n94651\n119897\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n100680\n116749\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n69398\n81510\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n52798\n63530\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n140472\n151986\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n118623\n174193\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n180933\n210294\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n82798\n97361\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n83090\n96472\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n97356\n108936\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n59482\n79819\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n77334\n108871\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n38777\n48531\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n111463\n128935\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n74715\n84305\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n174391\n188958\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n150558\n171869\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n122144\n148402\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n68012\n83813\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n84575\n104663\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n143045\n155742\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n51394\n73336\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n98279\n112705\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n47671\n78084\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360\n58257\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n236917\n279414\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n220631\n237883\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n185290\n219273\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n64640\n83354\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n70046\n90124\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n126971\n168462\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n144693\n165714\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n129404\n165668\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n284074\n311663\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n112268\n126892\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n203611\n229971\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n145238\n165876\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n251536\n271045\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n108078\n117731\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n238300\n256646\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n108870\n126603\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n108085\n127467\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n262835\n295688\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n248182\n336838\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n244850\n267729\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n404456\n431516\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n67608\n85667\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n33860\n51028\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nplot the lag_sum GDPPC and w_sum_gdppc \n\nw_sum_gdppc &lt;- qtm(hunan, \"w_sum GDPPC\")\ntmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/data/MPSZ-2019.html",
    "href": "In-class_Ex/In-class_Ex01/data/MPSZ-2019.html",
    "title": "IS415",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/data/MPSZ-2019.html",
    "href": "In-class_Ex/In-class_Ex02/data/MPSZ-2019.html",
    "title": "IS415",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "title": "In Class Exercise 3",
    "section": "",
    "text": "pacman::p_load(sf, raster, spatstat, tmap, tidyverse,sp,maptools)\n\n\ninstall.packages(\"maptools\", repos = \"https://packagemanager.posit.co/cran/2023-10-13\")\n\n\n#sg_sf &lt;- mpsz_sf %&gt;%\n#  st_union()\n\ndataframe as sf as.ppp but if i have it as sp model then use ppp\n\nacled_sf &lt;- st_read(\"data/ACLED_Myanmar.csv\") %&gt;%\n  st_as_sf(coords = c(\n    \"longitude\", \"latitude\"),\n    crs=4326) %&gt;%\n  st_transform(crs = 32647) %&gt;%\n  mutate(event_date = dmy(event_date))\n\nReading layer `ACLED_Myanmar' from data source \n  `C:\\SMU\\Y4S1\\IS415\\IS415\\In-class_Ex\\In-class_Ex03\\data\\ACLED_Myanmar.csv' \n  using driver `CSV'\n\n\nWarning: no simple feature geometries present: returning a data.frame or tbl_df\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\nacled_sf %&gt;%\n  filter(year == 2023 | event_type == \"political viloence\") %&gt;%\n  tm_shape()+\n  tm_dots()\n\n\n\n\n\n\n\n#tmap_mode(\"plot\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "In Class Exercise 4",
    "section": "",
    "text": "load packages\n\npacman::p_load(sf, raster, spatstat, tmap, tidyverse,sparr)\n\nImport the study area\n\nkbb &lt;- st_read(dsn=\"data/rawdata/\",layer = \"Kepulauan_Bangka_Belitung\")\n\nReading layer `Kepulauan_Bangka_Belitung' from data source \n  `C:\\SMU\\Y4S1\\IS415\\IS415\\In-class_Ex\\In-class_Ex04\\data\\rawdata' \n  using driver `ESRI Shapefile'\nSimple feature collection with 298 features and 27 fields\nGeometry type: POLYGON\nDimension:     XYZ\nBounding box:  xmin: 105.1085 ymin: -3.116593 xmax: 106.8488 ymax: -1.501603\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nrevised import code\n\nkbb_sf &lt;- st_read(dsn=\"data/rawdata/\",\n                  layer = \"Kepulauan_Bangka_Belitung\") %&gt;%\n  st_union() %&gt;%\n  st_zm(drop = TRUE, what = \"ZM\") %&gt;%\n  st_transform(crs = 32748)\n\nReading layer `Kepulauan_Bangka_Belitung' from data source \n  `C:\\SMU\\Y4S1\\IS415\\IS415\\In-class_Ex\\In-class_Ex04\\data\\rawdata' \n  using driver `ESRI Shapefile'\nSimple feature collection with 298 features and 27 fields\nGeometry type: POLYGON\nDimension:     XYZ\nBounding box:  xmin: 105.1085 ymin: -3.116593 xmax: 106.8488 ymax: -1.501603\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nst_as_s2(): dropping Z and/or M coordinate\n\n\nConverting to OWIN\n\nkbb_owin &lt;- as.owin(kbb_sf)\nkbb_owin\n\nwindow: polygonal boundary\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n\n\ncheck class to confirm output\n\nclass(kbb_owin)\n\n[1] \"owin\"\n\n\nImport forest fire data\n\nfire_sf &lt;- read_csv(\"data/rawdata/forestfires.csv\") %&gt;%\n  st_as_sf(coords = c(\"longitude\", \"latitude\"),\n                        crs = 4326) %&gt;%\n  st_transform(crs = 32748)\n\nRows: 741 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (3): satellite, instrument, daynight\ndbl  (11): latitude, longitude, brightness, scan, track, acq_time, confidenc...\ndate  (1): acq_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nconvert data type of acq_date to numeric\n\nfire_sf &lt;- fire_sf %&gt;%\n  mutate(DayofYear = yday(acq_date)) %&gt;%\n  mutate(Month_num = month(acq_date)) %&gt;%\n  mutate(Month_fac = month(acq_date, label = TRUE, abbr = FALSE))\n\nOverall Plot\n\ntm_shape(kbb_sf)+\n  tm_polygons() +\ntm_shape(fire_sf) +\n  tm_dots()\n\n\n\n\n\n\n\n\nvisualise by months\n\ntm_shape(kbb_sf)+\n  tm_polygons() +\ntm_shape(fire_sf) +\n  tm_dots(size = 0.1) +\ntm_facets(by=\"Month_fac\",\n            free.coords=FALSE,\n            drop.units = TRUE)\n\n\n\n\n\n\n\n\nsparr able to incoorperate the control group, able to compare with the control group\nComputing STKDE\nextracting forest fires by month\n\nfire_month &lt;- fire_sf %&gt;%\n  select(Month_num)\n\nCreating ppp\n\nfire_month_ppp &lt;- as.ppp(fire_month)\nfire_month_ppp\n\nMarked planar point pattern: 741 points\nmarks are numeric, of storage type  'double'\nwindow: rectangle = [521564.1, 695791] x [9658137, 9828767] units\n\n\nuse summary to checkout output is in the correct object class\n\nsummary(fire_month_ppp)\n\nMarked planar point pattern:  741 points\nAverage intensity 2.49258e-08 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   8.000   9.000   8.579  10.000  12.000 \n\nWindow: rectangle = [521564.1, 695791] x [9658137, 9828767] units\n                    (174200 x 170600 units)\nWindow area = 29728200000 square units\n\n\ncheck for duplicated\n\nany(duplicated(fire_month_ppp))\n\n[1] FALSE\n\n\ncreate owin object\ncombine origin_am_ppp and am_owin objects into one\n\nfire_month_owin &lt;- fire_month_ppp[kbb_owin]\nsummary(fire_month_owin)\n\nMarked planar point pattern:  741 points\nAverage intensity 6.424519e-08 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   8.000   9.000   8.579  10.000  12.000 \n\nWindow: polygonal boundary\n2 separate polygons (no holes)\n           vertices        area relative.area\npolygon 1     47493 11533600000      1.00e+00\npolygon 2       256      306427      2.66e-05\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n                     (193500 x 178600 units)\nWindow area = 11533900000 square units\nFraction of frame area: 0.334\n\n\nCompute Spatio-temporal KDE\nspattemp.density() of sparr package to compute STKDE\n\nst_kde &lt;- spattemp.density(fire_month_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nsummary(st_kde)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 15102.47 (spatial)\n  lambda = 0.0304 (temporal)\n\nNo. of observations\n  741 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [512066.8, 705559.4] x [9655398, 9834006]\n\nTemporal bound\n  [1, 12]\n\nEvaluation\n  128 x 128 x 12 trivariate lattice\n  Density range: [1.233458e-27, 8.202976e-10]\n\n\nplotting the spatio-temporal KDE object\n\ntims &lt;- c(7,8,9,10,11,12)\n  par(mfcol=c(2,3))\nfor (i in tims){\n  plot(st_kde, i,\n       override.par=FALSE,\n       fix.range=TRUE,\n       main=paste(\"KDE at month\",i))\n}"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IS415",
    "section": "",
    "text": "Hello! I’m Kwee Cheng and this is my journey with IS415"
  },
  {
    "objectID": "index.html#section",
    "href": "index.html#section",
    "title": "IS415",
    "section": "",
    "text": "Take-Home Exercise 2\n\n\n\n\n\n\nTake-Home\n\n\nCode\n\n\n\n\n\n\n\n\n\nSep 25, 2024\n\n\nKwee Cheng\n\n\n\n\n\n\n\n\n\n\n\n\nIn Class Exercise 6\n\n\n\n\n\n\nIn-Class\n\n\nCode\n\n\n\n\n\n\n\n\n\nSep 23, 2024\n\n\nKwee Cheng\n\n\n\n\n\n\n\n\n\n\n\n\nHands-On Exercise 6: Global Measures of Spatial Autocorrelation\n\n\n\n\n\n\nHands-On\n\n\nCode\n\n\n\n\n\n\n\n\n\nSep 21, 2024\n\n\nKwee Cheng\n\n\n\n\n\n\n\n\n\n\n\n\nIn Class Exercise 5\n\n\n\n\n\n\nIn-Class\n\n\nCode\n\n\n\n\n\n\n\n\n\nSep 16, 2024\n\n\nKwee Cheng\n\n\n\n\n\n\n\n\n\n\n\n\nHands-On Exercise 5: Spatial Weights and Applications\n\n\n\n\n\n\nHands-On\n\n\nCode\n\n\n\n\n\n\n\n\n\nSep 14, 2024\n\n\nKwee Cheng\n\n\n\n\n\n\n\n\n\n\n\n\nTake-Home Exercise 1\n\n\n\n\n\n\nTake-Home\n\n\nCode\n\n\n\n\n\n\n\n\n\nSep 14, 2024\n\n\nKwee Cheng\n\n\n\n\n\n\n\n\n\n\n\n\nIn Class Exercise 4\n\n\n\n\n\n\nIn-Class\n\n\nCode\n\n\n\n\n\n\n\n\n\nSep 9, 2024\n\n\nKwee Cheng\n\n\n\n\n\n\n\n\n\n\n\n\nIn Class Exercise 3\n\n\n\n\n\n\nIn-Class\n\n\nCode\n\n\n\n\n\n\n\n\n\nSep 2, 2024\n\n\nKwee Cheng\n\n\n\n\n\n\n\n\n\n\n\n\nHands-On Exercise 3: 1st & 2nd Order Spatial Point Patterns Analysis Methods\n\n\n\n\n\n\nHands-On\n\n\nCode\n\n\n\n\n\n\n\n\n\nAug 30, 2024\n\n\nKwee Cheng\n\n\n\n\n\n\n\n\n\n\n\n\nIn class exercise 2\n\n\n\n\n\n\nIn-Class\n\n\nCode\n\n\n\n\n\n\n\n\n\nAug 26, 2024\n\n\nKwee Cheng\n\n\n\n\n\n\n\n\n\n\n\n\nHands-On Exercise 2: Thematic Mapping and GeoVisualisation with R\n\n\n\n\n\n\nHands-On\n\n\nCode\n\n\n\n\n\n\n\n\n\nAug 24, 2024\n\n\nKwee Cheng\n\n\n\n\n\n\n\n\n\n\n\n\nIn-class Exercise 1\n\n\n\n\n\n\nIn-Class\n\n\nCode\n\n\n\n\n\n\n\n\n\nAug 19, 2024\n\n\nKwee Cheng\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 1\n\n\n\n\n\n\nHands-On\n\n\nCode\n\n\n\n\n\n\n\n\n\nAug 17, 2024\n\n\nKwee Cheng\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#kde-insights",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#kde-insights",
    "title": "Take-Home Exercise 1",
    "section": "KDE insights",
    "text": "KDE insights\nA lot of the conflicts that seems to be happening is around the central area of Myanmar and along the outskirts. Some explanations for activities around the central of Myanmar is that the capital city is there, and one of the biggest region in population Madalay is there. As for the outskirt events it could be due to it being the region with the highest population. Interestingly, for the year 2021 there wasn’t much conflicts in the first 2 quarters but it slowly got more. Transitioning into 2022 and 2023 where it seems to be the peak of when a lot of conflicts seems to be happening. With the data given as of now for 2024, the amount of conflicts for the Q2 is lesser than Q1."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#nd-order-stkde",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#nd-order-stkde",
    "title": "Take-Home Exercise 1",
    "section": "2nd Order STKDE",
    "text": "2nd Order STKDE\n\nsummary(conflict_quarter_2021)\n\n    quarter               geometry    \n Min.   :1.000   POINT        :16269  \n 1st Qu.:2.000   epsg:32647   :    0  \n Median :2.000   +proj=utm ...:    0  \n Mean   :2.529                        \n 3rd Qu.:4.000                        \n Max.   :4.000"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#stkde-insights",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#stkde-insights",
    "title": "Take-Home Exercise 1",
    "section": "STKDE Insights",
    "text": "STKDE Insights\nIntuitively you will think that KDE and STKDE would give the same results cause at the end of the day we are using the same data points. However something STKDE have an advantage is that it takes over a period of time as a consideration.\nFor the most part STKDE show similar insights in that the conflicts happen in the middle of Myanmar and the outskirts. But something different would be the intensity of the density, as with KDE we changed our own sigma to make it more visible which could explain the difference. Our STKDE has lower intensity for some of the years for example 2023 Q3, which suggest that there is not much conflict clustering as we initially thought. Another one would be 2024 Q2, our KDE suggest that there isn’t much conflicts as the intensity of the density is quite low generally around the whole of Myanmar. But our STKDE suggest that for 2024 Q2 there is a lot of conflicts on the central and outskirts of Myanmar, again this could be due to it factoring a period of time into the computation.\nOverall both KDE and STKDE, shows that there are conflicts around the central of Myanmar and for the outskirts its generally the South of Myanmar. And currently in the year 2024 its correlating to the Rakhine State where the Arakan Army insurgency took place earlier this year and is still ongoing."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#nd-order-analysis-stkde",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#nd-order-analysis-stkde",
    "title": "Take-Home Exercise 1",
    "section": "2nd Order Analysis STKDE",
    "text": "2nd Order Analysis STKDE\nThere not much tutorial in class for performing 2nd order analysis for STKDE, so the closest that prof has provided us is https://pages.charlotte.edu/eric-delmelle/wp-content/uploads/sites/150/2019/09/Spatiotemporal-Point-Pattern-Analysis-Using-Ripleys-K-Function.pdf which is to use Ripleys K function for 2nd order analysis which would be what I’m doing.\nLikewise for what we did in 2nd order analysis for KDE let’s split up the data into the years and event_type. I shall only focus on Mandalay region and for the year 2024. Since from the STKDE it has difference from the KDE. Also as with K function it is already computationally intensive and our dataset is huge, its better to narrow it down.\nLet’s first split acled_sf_2024 into the four main event_type again and only selecting the quarter.\n\nacled_stkde_2024_battle &lt;- acled_sf_2024 %&gt;% filter(event_type == \"Battles\") %&gt;% select(quarter)\nacled_stkde_2024_explosion &lt;- acled_sf_2024 %&gt;% filter(event_type == \"Explosions/Remote violence\") %&gt;% select(quarter)\nacled_stkde_2024_strat &lt;- acled_sf_2024 %&gt;% filter(event_type == \"Strategic developments\")%&gt;% select(quarter)\nacled_stkde_2024_violence &lt;- acled_sf_2024 %&gt;% filter(event_type == \"Violence against civilians\") %&gt;% select(quarter)\n\n\nPPP object\nLet’s convert into ppp object\n\nstkde_ppp_battle &lt;- as.ppp(acled_stkde_2024_battle)\nstkde_ppp_explosion &lt;- as.ppp(acled_stkde_2024_explosion)\nstkde_ppp_strat &lt;- as.ppp(acled_stkde_2024_strat)\nstkde_ppp_violence &lt;- as.ppp(acled_stkde_2024_violence)\n\nLet’s check for duplicates\n\nany(duplicated(stkde_ppp_battle))\n\n[1] TRUE\n\nany(duplicated(stkde_ppp_explosion))\n\n[1] TRUE\n\nany(duplicated(stkde_ppp_strat))\n\n[1] TRUE\n\nany(duplicated(stkde_ppp_violence))\n\n[1] TRUE\n\n\nLet’s remove the duplicates\n\nstkde_ppp_battle &lt;- rjitter(stkde_ppp_battle, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\nstkde_ppp_explosion &lt;- rjitter(stkde_ppp_explosion, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\nstkde_ppp_strat &lt;- rjitter(stkde_ppp_strat, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\nstkde_ppp_violence &lt;- rjitter(stkde_ppp_violence, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\nMaking sure that there are no more duplicates\n\nany(duplicated(stkde_ppp_battle))\n\n[1] FALSE\n\nany(duplicated(stkde_ppp_explosion))\n\n[1] FALSE\n\nany(duplicated(stkde_ppp_strat))\n\n[1] FALSE\n\nany(duplicated(stkde_ppp_violence))\n\n[1] FALSE\n\n\nLet’s finally combine it with the mandalay owin object\n\nstkde_owin_battle &lt;- stkde_ppp_battle[mandalay_owin]\nstkde_owin_explosion &lt;- stkde_ppp_explosion[mandalay_owin]\nstkde_owin_strat &lt;- stkde_ppp_strat[mandalay_owin]\nstkde_owin_violence &lt;- stkde_ppp_violence[mandalay_owin]\n\n\nBattleExplosion/Remote violenceStrategic DevelopmentViolence against civilians\n\n\n\nK_battle = Kest(stkde_owin_battle, correction = \"Ripley\")\nplot(K_battle, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\n\n\nK_explosion = Kest(stkde_owin_explosion, correction = \"Ripley\")\nplot(K_explosion, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\n\n\nK_Strat = Kest(stkde_owin_strat, correction = \"Ripley\")\nplot(K_Strat, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\n\n\nK_violence = Kest(stkde_owin_violence, correction = \"Ripley\")\nplot(K_violence, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\n\n\nThen let’s run the CSR simulation and plot it. If its\n\nAbove the envelop: significant cluster pattern\nBelow the envelop: significant regular\nInside the envelop: CSR\n\n\nBattlesExplosion/Remote violenceStrategic DevelopmentViolence against civilians\n\n\n\nK_battle.csr &lt;- envelope(stkde_owin_battle, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\nplot(K_battle.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")\n\n\n\n\n\n\n\n\n\n\n\nK_explosion.csr &lt;- envelope(stkde_owin_explosion, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\nplot(K_explosion.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")\n\n\n\n\n\n\n\n\n\n\n\nK_Strat.csr &lt;- envelope(stkde_owin_strat, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3,\n [3:12 remaining] 4,  [2:58 remaining] 5,  [2:51 remaining] 6,\n [2:41 remaining] 7,  [2:43 remaining] 8,  [2:42 remaining] 9,\n [2:43 remaining] 10,  [2:35 remaining] 11,  [2:36 remaining] 12,\n [2:34 remaining] 13,  [2:34 remaining] 14,  [2:35 remaining] 15,\n [2:36 remaining] 16,  [2:40 remaining] 17,  [2:37 remaining] 18,\n [2:33 remaining] 19,  [2:32 remaining] 20,  [2:31 remaining] 21,\n [2:30 remaining] 22,  [2:29 remaining] 23,  [2:29 remaining] 24,\n [2:25 remaining] 25,  [2:22 remaining] 26,  [2:21 remaining] 27,\n [2:19 remaining] 28,  [2:16 remaining] 29,  [2:13 remaining] 30,\n [2:10 remaining] 31,  [2:08 remaining] 32,  [2:06 remaining] 33,\n [2:06 remaining] 34,  [2:05 remaining] 35,  [2:03 remaining] 36,\n [2:01 remaining] 37,  [1:59 remaining] 38,  [1:56 remaining] 39,\n [1:54 remaining] 40,  [1:52 remaining] 41,  [1:52 remaining] 42,\n [1:50 remaining] 43,  [1:48 remaining] 44,  [1:46 remaining] 45,\n [1:44 remaining] 46,  [1:42 remaining] 47,  [1:40 remaining] 48,\n [1:38 remaining] 49,  [1:37 remaining] 50,  [1:35 remaining] 51,\n [1:33 remaining] 52,  [1:31 remaining] 53,  [1:29 remaining] 54,\n [1:27 remaining] 55,  [1:25 remaining] 56,  [1:23 remaining] 57,\n [1:22 remaining] 58,  [1:20 remaining] 59,  [1:18 remaining] 60,\n [1:17 remaining] 61,  [1:15 remaining] 62,  [1:13 remaining] 63,\n [1:11 remaining] 64,  [1:09 remaining] 65,  [1:08 remaining] 66,\n [1:06 remaining] 67,  [1:04 remaining] 68,  [1:02 remaining] 69,\n [1:00 remaining] 70,  [58 sec remaining] 71,  [56 sec remaining] 72,\n [54 sec remaining] 73,  [52 sec remaining] 74,  [50 sec remaining] 75,\n [48 sec remaining] 76,  [46 sec remaining] 77,  [44 sec remaining] 78,\n [43 sec remaining] 79,  [41 sec remaining] 80,  [39 sec remaining] 81,\n [37 sec remaining] 82,  [35 sec remaining] 83,  [33 sec remaining] 84,\n [31 sec remaining] 85,  [29 sec remaining] 86,  [26 sec remaining] 87,\n [24 sec remaining] 88,  [22 sec remaining] 89,  [20 sec remaining] 90,\n [18 sec remaining] 91,  [16 sec remaining] 92,  [14 sec remaining] 93,\n [12 sec remaining] 94,  [10 sec remaining] 95,  [8 sec remaining] 96,\n [6 sec remaining] 97,  [4 sec remaining] 98,  [2 sec remaining] \n99.\n\nDone.\n\nplot(K_Strat.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")\n\n\n\n\n\n\n\n\n\n\n\nK_violence.csr &lt;- envelope(stkde_owin_violence, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\nplot(K_violence.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")\n\n\n\n\n\n\n\n\n\n\n\nLikewise it does show that the conflicts in 2024 are all generally clustered as it is above the envelope"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#kde-on-openstreetmap",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#kde-on-openstreetmap",
    "title": "Take-Home Exercise 1",
    "section": "KDE on OpenStreetMap",
    "text": "KDE on OpenStreetMap\nFrom the various testing, I realised that we can’t use the rescale version of the ppp object as their unit of measurement is different so the raster layer and osm can’t be overlay\nWith that let’s start plotting the different maps, because we are using the meters version we would have to adjust the sigma to reflect it better\n\n2021202220232024\n\n\n\npar(mfrow=c(2,2), cex.main = 3.5)\nmap_density &lt;- density(acledMyanmar_ppp_2021_Q1, \n             sigma=25000, \n             edge=TRUE, \n             kernel=\"gaussian\")\ndensity_raster &lt;- raster(map_density)\nprojection(density_raster) &lt;- CRS(\"+init=EPSG:32647\")\n\nm1 &lt;- tm_shape(density_raster) +\n  tm_raster() +\n  tm_shape(osm_myanmar) +\n  tm_lines(\"black\")\n\nmap_density &lt;- density(acledMyanmar_ppp_2021_Q2, \n             sigma=25000, \n             edge=TRUE, \n             kernel=\"gaussian\")\ndensity_raster &lt;- raster(map_density)\nprojection(density_raster) &lt;- CRS(\"+init=EPSG:32647\")\n\nm2 &lt;- tm_shape(density_raster) +\n  tm_raster() +\n  tm_shape(osm_myanmar) +\n  tm_lines(\"black\")\n\nmap_density &lt;- density(acledMyanmar_ppp_2021_Q3, \n             sigma=25000, \n             edge=TRUE, \n             kernel=\"gaussian\")\ndensity_raster &lt;- raster(map_density)\nprojection(density_raster) &lt;- CRS(\"+init=EPSG:32647\")\n\nm3 &lt;- tm_shape(density_raster) +\n  tm_raster() +\n  tm_shape(osm_myanmar) +\n  tm_lines(\"black\")\n\nmap_density &lt;- density(acledMyanmar_ppp_2021_Q4, \n             sigma=25000, \n             edge=TRUE, \n             kernel=\"gaussian\")\ndensity_raster &lt;- raster(map_density)\nprojection(density_raster) &lt;- CRS(\"+init=EPSG:32647\")\n\nm4 &lt;- tm_shape(density_raster) +\n  tm_raster() +\n  tm_shape(osm_myanmar) +\n  tm_lines(\"black\")\n\ntmap_arrange(m1, m2, m3, m4, asp=1, ncol=2, nrow=2)\n\n\n\n\n\n\n\n\n\n\n\npar(mfrow=c(2,2), cex.main = 3.5)\nmap_density &lt;- density(acledMyanmar_ppp_2022_Q1, \n             sigma=25000, \n             edge=TRUE, \n             kernel=\"gaussian\")\ndensity_raster &lt;- raster(map_density)\nprojection(density_raster) &lt;- CRS(\"+init=EPSG:32647\")\n\nm1 &lt;- tm_shape(density_raster) +\n  tm_raster() +\n  tm_shape(osm_myanmar) +\n  tm_lines(\"black\")\n\nmap_density &lt;- density(acledMyanmar_ppp_2022_Q2, \n             sigma=25000, \n             edge=TRUE, \n             kernel=\"gaussian\")\ndensity_raster &lt;- raster(map_density)\nprojection(density_raster) &lt;- CRS(\"+init=EPSG:32647\")\n\nm2 &lt;- tm_shape(density_raster) +\n  tm_raster() +\n  tm_shape(osm_myanmar) +\n  tm_lines(\"black\")\n\nmap_density &lt;- density(acledMyanmar_ppp_2022_Q3, \n             sigma=25000, \n             edge=TRUE, \n             kernel=\"gaussian\")\ndensity_raster &lt;- raster(map_density)\nprojection(density_raster) &lt;- CRS(\"+init=EPSG:32647\")\n\nm3 &lt;- tm_shape(density_raster) +\n  tm_raster() +\n  tm_shape(osm_myanmar) +\n  tm_lines(\"black\")\n\nmap_density &lt;- density(acledMyanmar_ppp_2022_Q4, \n             sigma=25000, \n             edge=TRUE, \n             kernel=\"gaussian\")\ndensity_raster &lt;- raster(map_density)\nprojection(density_raster) &lt;- CRS(\"+init=EPSG:32647\")\n\nm4 &lt;- tm_shape(density_raster) +\n  tm_raster() +\n  tm_shape(osm_myanmar) +\n  tm_lines(\"black\")\n\ntmap_arrange(m1, m2, m3, m4, asp=1, ncol=2, nrow=2)\n\nVariable(s) \"NA\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\npar(mfrow=c(2,2), cex.main = 3.5)\nmap_density &lt;- density(acledMyanmar_ppp_2023_Q1, \n             sigma=25000, \n             edge=TRUE, \n             kernel=\"gaussian\")\ndensity_raster &lt;- raster(map_density)\nprojection(density_raster) &lt;- CRS(\"+init=EPSG:32647\")\n\nm1 &lt;- tm_shape(density_raster) +\n  tm_raster() +\n  tm_shape(osm_myanmar) +\n  tm_lines(\"black\")\n\nmap_density &lt;- density(acledMyanmar_ppp_2023_Q2, \n             sigma=25000, \n             edge=TRUE, \n             kernel=\"gaussian\")\ndensity_raster &lt;- raster(map_density)\nprojection(density_raster) &lt;- CRS(\"+init=EPSG:32647\")\n\nm2 &lt;- tm_shape(density_raster) +\n  tm_raster() +\n  tm_shape(osm_myanmar) +\n  tm_lines(\"black\")\n\nmap_density &lt;- density(acledMyanmar_ppp_2023_Q3, \n             sigma=25000, \n             edge=TRUE, \n             kernel=\"gaussian\")\ndensity_raster &lt;- raster(map_density)\nprojection(density_raster) &lt;- CRS(\"+init=EPSG:32647\")\n\nm3 &lt;- tm_shape(density_raster) +\n  tm_raster() +\n  tm_shape(osm_myanmar) +\n  tm_lines(\"black\")\n\nmap_density &lt;- density(acledMyanmar_ppp_2023_Q4, \n             sigma=25000, \n             edge=TRUE, \n             kernel=\"gaussian\")\ndensity_raster &lt;- raster(map_density)\nprojection(density_raster) &lt;- CRS(\"+init=EPSG:32647\")\n\nm4 &lt;- tm_shape(density_raster) +\n  tm_raster() +\n  tm_shape(osm_myanmar) +\n  tm_lines(\"black\")\n\ntmap_arrange(m1, m2, m3, m4, asp=1, ncol=2, nrow=2)\n\nVariable(s) \"NA\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\nVariable(s) \"NA\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\npar(mfrow=c(2,2), cex.main = 3.5)\nmap_density &lt;- density(acledMyanmar_ppp_2024_Q1, \n             sigma=25000, \n             edge=TRUE, \n             kernel=\"gaussian\")\ndensity_raster &lt;- raster(map_density)\nprojection(density_raster) &lt;- CRS(\"+init=EPSG:32647\")\n\nm1 &lt;- tm_shape(density_raster) +\n  tm_raster() +\n  tm_shape(osm_myanmar) +\n  tm_lines(\"black\")\n\nmap_density &lt;- density(acledMyanmar_ppp_2024_Q2, \n             sigma=25000, \n             edge=TRUE, \n             kernel=\"gaussian\")\ndensity_raster &lt;- raster(map_density)\nprojection(density_raster) &lt;- CRS(\"+init=EPSG:32647\")\n\nm2 &lt;- tm_shape(density_raster) +\n  tm_raster() +\n  tm_shape(osm_myanmar) +\n  tm_lines(\"black\")\n\ntmap_arrange(m1, m2, asp=1, ncol=2)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#stkde-on-openstreetmap",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#stkde-on-openstreetmap",
    "title": "Take-Home Exercise 1",
    "section": "STKDE on OpenStreetMap",
    "text": "STKDE on OpenStreetMap"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "title": "In Class Exercise 6",
    "section": "",
    "text": "pacman::p_load(sf, sfdep, tmap, tidyverse)\n\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\SMU\\Y4S1\\IS415\\IS415\\In-class_Ex\\In-class_Ex06\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nhunan &lt;- left_join(hunan,hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`\n\n\n\nwm_q &lt;- hunan %&gt;% mutate(nb = st_contiguity(geometry), wt = st_weights(nb,style= \"W\"), .before = 1)\n\n\nmoranI &lt;- global_moran(wm_q$GDPPC, wm_q$nb, wm_q$wt)\nglimpse(moranI)\n\nList of 2\n $ I: num 0.301\n $ K: num 7.64\n\n\n\nPerforming Global Moran’sI test\n\nglobal_moran_test(wm_q$GDPPC, wm_q$nb, wm_q$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\n\nPerforming Global Moran’I permutation test\n\nset.seed(1234)\n\n\nglobal_moran_perm(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt,\n                  nsim = 99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\nComputing local Moran’s I\n\nlisa &lt;- wm_q %&gt;% \n  mutate(local_moran = local_moran(\n    GDPPC, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nunest need to see ur data in a table\n\n\nVisualising local Moran’s I\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of GDPPC\",\n            main.title.size = 0.8)\n\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\nVisualising p-value of local Moran’s I\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(lisa) +\n  tm_fill(\"p_ii_sim\") + \n  tm_borders(alpha = 0.5) +\n   tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 0.8)\n\n\n\n\n\n\n\n\n\n\nVisuaising local Moran’s I and p-value\n\n\nShow the code\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\nShow the code\nmap1 &lt;- tm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of GDPPC\",\n            main.title.size = 0.8)\n\nmap2 &lt;- tm_shape(lisa) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)\n\n\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\nvisualising LISA map\n\nlisa_sig &lt;- lisa  %&gt;%\n  filter(p_ii &lt; 0.05)\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(lisa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\n\n\n\n\n\n\nComputing local Gi* statistics\n\nwm_idw &lt;- hunan %&gt;%\n  mutate(nb = st_contiguity(geometry),\n         wts = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\n\n! Polygon provided. Using point on surface.\n\n\nWarning: There was 1 warning in `stopifnot()`.\nℹ In argument: `wts = st_inverse_distance(nb, geometry, scale = 1, alpha = 1)`.\nCaused by warning in `st_point_on_surface.sfc()`:\n! st_point_on_surface may not give correct results for longitude/latitude data\n\n\n\nHCSA &lt;- wm_idw %&gt;% \n  mutate(local_Gi = local_gstar_perm(\n    GDPPC, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi)\nHCSA\n\nSimple feature collection with 88 features and 18 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n# A tibble: 88 × 19\n   gi_star cluster   e_gi     var_gi std_dev p_value p_sim p_folded_sim skewness\n     &lt;dbl&gt; &lt;fct&gt;    &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1  0.0416 Low     0.0114 0.00000641  0.0493 9.61e-1  0.7          0.35    0.875\n 2 -0.333  Low     0.0106 0.00000384 -0.0941 9.25e-1  1            0.5     0.661\n 3  0.281  High    0.0126 0.00000751 -0.151  8.80e-1  0.9          0.45    0.640\n 4  0.411  High    0.0118 0.00000922  0.264  7.92e-1  0.6          0.3     0.853\n 5  0.387  High    0.0115 0.00000956  0.339  7.34e-1  0.62         0.31    1.07 \n 6 -0.368  High    0.0118 0.00000591 -0.583  5.60e-1  0.72         0.36    0.594\n 7  3.56   High    0.0151 0.00000731  2.61   9.01e-3  0.06         0.03    1.09 \n 8  2.52   High    0.0136 0.00000614  1.49   1.35e-1  0.2          0.1     1.12 \n 9  4.56   High    0.0144 0.00000584  3.53   4.17e-4  0.04         0.02    1.23 \n10  1.16   Low     0.0104 0.00000370  1.82   6.86e-2  0.12         0.06    0.416\n# ℹ 78 more rows\n# ℹ 10 more variables: kurtosis &lt;dbl&gt;, nb &lt;nb&gt;, wts &lt;list&gt;, NAME_2 &lt;chr&gt;,\n#   ID_3 &lt;int&gt;, NAME_3 &lt;chr&gt;, ENGTYPE_3 &lt;chr&gt;, County &lt;chr&gt;, GDPPC &lt;dbl&gt;,\n#   geometry &lt;POLYGON [°]&gt;\n\n\ngstat hot and spot, lisa cluster\n\nHCSA_sig &lt;- HCSA  %&gt;%\n  filter(p_sim &lt; 0.05)\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(HCSA) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "title": "Take-Home Exercise 2",
    "section": "",
    "text": "Drug abuse is associated with significant negative health, financial and social consequences. Yet, illicit drug consumption remains highly prevalent and continues to be a growing problem worldwide. In 2021, 1 in 17 people aged 15–64 in the world had used a drug in the past 12 months. Notwithstanding population growth, the estimated number of drug users grew from 240 million in 2011 to 296 million in 2021.\nThe geopolitics of Thailand which is near the Golden Triangle of Indochina, the largest drug production site in Asia, and the constant transportation infrastructure development made Thailand became market and transit routes for drug trafficking to the third countries.\nIn Thailand, drug abuse is one of the major social issue. There are about 2.7 million youths using drugs in Thailand. Among youths aged between 15 and 19 years, there are about 300,000 who have needs for drug treatment. Most of Thai youths involved with drugs are vocational-school students, which nearly doubles in number compared to secondary-school students."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#background",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#background",
    "title": "Take-Home Exercise 2",
    "section": "",
    "text": "Drug abuse is associated with significant negative health, financial and social consequences. Yet, illicit drug consumption remains highly prevalent and continues to be a growing problem worldwide. In 2021, 1 in 17 people aged 15–64 in the world had used a drug in the past 12 months. Notwithstanding population growth, the estimated number of drug users grew from 240 million in 2011 to 296 million in 2021.\nThe geopolitics of Thailand which is near the Golden Triangle of Indochina, the largest drug production site in Asia, and the constant transportation infrastructure development made Thailand became market and transit routes for drug trafficking to the third countries.\nIn Thailand, drug abuse is one of the major social issue. There are about 2.7 million youths using drugs in Thailand. Among youths aged between 15 and 19 years, there are about 300,000 who have needs for drug treatment. Most of Thai youths involved with drugs are vocational-school students, which nearly doubles in number compared to secondary-school students."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#objectives",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#objectives",
    "title": "Take-Home Exercise 2",
    "section": "Objectives",
    "text": "Objectives\n\nIf the key indicators of drug abuse of Thailand are independent from space.\nIf the indicators of drug abuse is indeed spatial dependent, then, you would like to detect where are the clusters and outliers, and the hotspots.\nLast but not least, you are also interested to investigate how the observation above evolve over time."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#dataset",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#dataset",
    "title": "Take-Home Exercise 2",
    "section": "Dataset",
    "text": "Dataset\n\nThailand Drug Offenses [2017-2022] at Kaggle.\nThailand - Subnational Administrative Boundaries at HDX. You are required to use the province boundary data set."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#packages",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#packages",
    "title": "Take-Home Exercise 2",
    "section": "Packages",
    "text": "Packages\n\nsf provides a standardised way to work with spatial vector data (points, lines, polygons)\nspdep focuses on spatial econometrics and spatial statistics\ntmap create thematic maps\ntidyverse for easy data manipulation and some visualisation\nknitr facilitates the integration of R code and documentation in reproducible research reports\n\n\npacman::p_load(sf, sfdep, tmap, tidyverse, knitr)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#importing-data",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#importing-data",
    "title": "Take-Home Exercise 2",
    "section": "Importing data",
    "text": "Importing data\nLet’s load the csv file from kaggle about Thailand’s drug offenses\n\nthai_drug &lt;- read_csv(\"data/thai_drug_offenses_2017_2022.csv\")\n\nRows: 7392 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): types_of_drug_offenses, province_th, province_en\ndbl (2): fiscal_year, no_cases\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nset.seed(2932)\n\n\nclass(thai_drug)\n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\n\nNext let’s load the shapefile of Thailand’s province boundary\n\nthai_sf &lt;- st_read(dsn = \"data/\", \n                 layer = \"tha_admbnda_adm1_rtsd_20220121\")\n\nReading layer `tha_admbnda_adm1_rtsd_20220121' from data source \n  `C:\\IS415\\Take-home_Ex\\Take-home_Ex02\\data' using driver `ESRI Shapefile'\nSimple feature collection with 77 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n\n\n\nthai_sf\n\nSimple feature collection with 77 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\nFirst 10 features:\n   Shape_Leng Shape_Area                  ADM1_EN       ADM1_TH ADM1_PCODE\n1    2.417227 0.13133873                  Bangkok  กรุงเทพมหานคร       TH10\n2    1.695100 0.07926199             Samut Prakan    สมุทรปราการ       TH11\n3    1.251111 0.05323766               Nonthaburi         นนทบุรี       TH12\n4    1.884945 0.12698345             Pathum Thani        ปทุมธานี       TH13\n5    3.041716 0.21393797 Phra Nakhon Si Ayutthaya พระนครศรีอยุธยา       TH14\n6    1.739908 0.07920961                Ang Thong        อ่างทอง       TH15\n7    5.693342 0.54578838                 Lop Buri          ลพบุรี       TH16\n8    1.778326 0.06872655                Sing Buri         สิงห์บุรี       TH17\n9    2.896316 0.20907828                 Chai Nat         ชัยนาท       TH18\n10   4.766446 0.29208711                 Saraburi         สระบุรี       TH19\n   ADM1_REF ADM1ALT1EN ADM1ALT2EN ADM1ALT1TH ADM1ALT2TH  ADM0_EN   ADM0_TH\n1      &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย\n2      &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย\n3      &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย\n4      &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย\n5      &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย\n6      &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย\n7      &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย\n8      &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย\n9      &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย\n10     &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย\n   ADM0_PCODE       date    validOn    validTo                       geometry\n1          TH 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((100.6139 13...\n2          TH 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((100.7306 13...\n3          TH 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((100.3415 14...\n4          TH 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((100.8916 14...\n5          TH 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((100.5131 14...\n6          TH 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((100.3332 14...\n7          TH 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((101.3453 15...\n8          TH 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((100.3691 15...\n9          TH 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((100.1199 15...\n10         TH 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((101.3994 15..."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-wrangling",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-wrangling",
    "title": "Take-Home Exercise 2",
    "section": "Data Wrangling",
    "text": "Data Wrangling\n\nMisspelled province\nI would like to perform a left join on province_en of thai_drug and ADM1_EN of thai_sf, so I would have to check if there are any missing data or mismatch\n\ncombined_data &lt;- bind_cols(thai_drug = sort(unique(thai_drug$province_en)), thai_sf = sort(unique(thai_sf$ADM1_EN)))\n\n# Create a new column to compare the values\ncombined_data &lt;- combined_data %&gt;%\n  mutate(same_values = thai_drug == thai_sf) %&gt;% filter(same_values == FALSE)\n\n# View the result\ncombined_data\n\n# A tibble: 3 × 3\n  thai_drug thai_sf   same_values\n  &lt;chr&gt;     &lt;chr&gt;     &lt;lgl&gt;      \n1 buogkan   Bueng Kan FALSE      \n2 Loburi    Loei      FALSE      \n3 Loei      Lop Buri  FALSE      \n\n\nFrom here we can see that there is a mismatch in the data where there are spelling errors from the data provided kaggle so lets change it.\n\nthai_drug &lt;- thai_drug %&gt;%\n  mutate(province_en = recode(province_en,\n                              \"buogkan\" = \"Bueng Kan\",\n                              \"Loburi\" = \"Lop Buri\"))\n\nLet’s check if there is any mismatch again\n\ncombined_data &lt;- bind_cols(thai_drug = sort(unique(thai_drug$province_en)), thai_sf = sort(unique(thai_sf$ADM1_EN)))\n\n\ncombined_data &lt;- combined_data %&gt;%\n  mutate(same_values = thai_drug == thai_sf) %&gt;% filter(same_values == FALSE)\n\n\ncombined_data\n\n# A tibble: 0 × 3\n# ℹ 3 variables: thai_drug &lt;chr&gt;, thai_sf &lt;chr&gt;, same_values &lt;lgl&gt;\n\n\n\n\nCRS check\nLet’s check the crs of the Thai boundary file\n\nst_crs(thai_sf)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\nLet’s convert it into the projected coordinate system of 32647\n\nthai_sf &lt;- thai_sf %&gt;% st_transform(crs = 32647)\nst_crs(thai_sf)\n\nCoordinate Reference System:\n  User input: EPSG:32647 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 47N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 47N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",99,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\"],\n        BBOX[0,96,84,102]],\n    ID[\"EPSG\",32647]]\n\n\n\n\nHole in boundary file\nNext check if there are any holes with the boundary file\n\nu_thai &lt;- st_union(thai_sf)\nplot(u_thai)\n\n\n\n\n\n\n\n\n\n\nMissing row check\nLastly check for the drug abuse csv if there are any missing rows\n\nna &lt;- thai_drug %&gt;%\n  summarise(na_year = sum(is.na(fiscal_year)),\n            na_province = sum(is.na(province_en)),\n            na_drug_offense = sum(is.na(types_of_drug_offenses)),\n            na_cases = sum(is.na(no_cases)))\nprint(na)\n\n# A tibble: 1 × 4\n  na_year na_province na_drug_offense na_cases\n    &lt;int&gt;       &lt;int&gt;           &lt;int&gt;    &lt;int&gt;\n1       0           0               0        0\n\n\n\n\nLeft Join\nGreat now let’s left join both the boundary file and the csv\n\nthai &lt;- left_join(thai_sf,thai_drug, by = c(\"ADM1_EN\" = \"province_en\")) %&gt;%\n        select(1:3, 17:19,21)\n\nAs the combined file is quite huge let’s see how we can split it even more, let’s choose the only relevant type of drug offenses\n\nunique(thai$types_of_drug_offenses)\n\n [1] \"drug_use_cases\"                                        \n [2] \"suspects_in_drug_use_cases\"                            \n [3] \"possession_cases\"                                      \n [4] \"suspects_in_possession_cases\"                          \n [5] \"possession_with_intent_to_distribute_cases\"            \n [6] \"suspects_in_possession_with_intent_to_distribute_cases\"\n [7] \"trafficking_cases\"                                     \n [8] \"suspects_in_trafficking_cases\"                         \n [9] \"production_cases\"                                      \n[10] \"suspects_in_production_cases\"                          \n[11] \"import_cases\"                                          \n[12] \"suspects_in_import_cases\"                              \n[13] \"export_cases\"                                          \n[14] \"suspects_in_export_cases\"                              \n[15] \"conspiracy_cases\"                                      \n[16] \"suspects_in_conspiracy_cases\"                          \n\n\nLet’s choose everything but the suspects as suspects are not really confirmed cases but it could provide some supplementary in comparison.\n\ndrug_offenses &lt;- c(\n  \"drug_use_cases\", \"possession_cases\", \"possession_with_intent_to_distribute_cases\", \"trafficking_cases\", \"production_cases\", \"import_cases\", \"export_cases\", \"conspiracy_cases\"\n)\n\nthai &lt;- thai %&gt;% filter(types_of_drug_offenses %in% drug_offenses )\n\nNext let’s split it up by the years\n\ndrug &lt;- list()\nfor (year in 2017:2022) {\n  drug[[as.character(year)]] &lt;- thai %&gt;% filter(fiscal_year == year)\n}\n\nglimpse(drug[[\"2017\"]])\n\nRows: 616\nColumns: 7\n$ Shape_Leng             &lt;dbl&gt; 2.417227, 2.417227, 2.417227, 2.417227, 2.41722…\n$ Shape_Area             &lt;dbl&gt; 0.13133873, 0.13133873, 0.13133873, 0.13133873,…\n$ ADM1_EN                &lt;chr&gt; \"Bangkok\", \"Bangkok\", \"Bangkok\", \"Bangkok\", \"Ba…\n$ fiscal_year            &lt;dbl&gt; 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017,…\n$ types_of_drug_offenses &lt;chr&gt; \"drug_use_cases\", \"possession_cases\", \"possessi…\n$ no_cases               &lt;dbl&gt; 11871, 9224, 6374, 950, 316, 0, 2, 10, 820, 334…\n$ geometry               &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((674339.8 15..., MU…\n\n\n\n\nSimple Visualisations\nLet’s just do a simple visualisation of the drug uses in the year 2017 to see what we are dealing with\n\nqtm(drug[[\"2017\"]], \"no_cases\")\n\nSome legend labels were too wide. These labels have been resized to 0.62, 0.58. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\n\n\n\n\n\n\n\n\n\nNothing much can be visualised so let’s separate out the type of cases again to only drug use\n\ntemp &lt;- drug[[\"2017\"]]\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntemp %&gt;%\n  filter(types_of_drug_offenses == \"drug_use_cases\") %&gt;%\n  tm_shape() +\n  tm_fill(\"no_cases\",\n            n = 5,\n            style = \"equal\") +  \n    tm_borders(alpha = 0.5)\n\nSome legend labels were too wide. These labels have been resized to 0.62. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#global-measures-of-spatial-autocorrelation",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#global-measures-of-spatial-autocorrelation",
    "title": "Take-Home Exercise 2",
    "section": "Global Measures of Spatial Autocorrelation",
    "text": "Global Measures of Spatial Autocorrelation\n\nCalculating Neighbours and Weights\nI would be defining neighbour’s based on Queens contiguity, and also let’s assign spatial weights to each neighbouring polygon\n\nwm_q_list &lt;- list()\nfor (year in 2017:2022) {\n  wm_q &lt;- drug[[as.character(year)]] %&gt;%\n    mutate(nb = st_contiguity((.), queen=TRUE),\n           wt = st_weights(nb, style = \"W\",allow_zero=TRUE),\n           .before = 1)\n  wm_q_list[[as.character(year)]] &lt;- wm_q\n  \n}\n\nAs this takes a lot of time lets save this list into a rds file\n\nwrite_rds(wm_q_list, \"data/rds/wm_q_list.rds\")\n\n\n\nGlobal Moran’s I Test\nTo assess spatial autocorrelation in our dataset, or how the presence of drug use cases in a province may form clusters.\n\n201720182019202020212022\n\n\n\nwm_q &lt;- wm_q_list[[\"2017\"]]\nglobal_moran_test(wm_q$no_cases,\n           wm_q$nb,\n           wm_q$wt,\n           zero.policy = TRUE,\n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.8794, p-value = 5.319e-07\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     3.981645e-02     -1.626016e-03      7.213589e-05 \n\n\n\n\n\nwm_q &lt;- wm_q_list[[\"2018\"]]\nglobal_moran_test(wm_q$no_cases,\n           wm_q$nb,\n           wm_q$wt,\n           zero.policy = TRUE,\n           na.action = na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 3.6488, p-value = 0.0001318\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     2.910879e-02     -1.626016e-03      7.095291e-05 \n\n\n\n\n\nwm_q &lt;- wm_q_list[[\"2019\"]]\nglobal_moran_test(wm_q$no_cases,\n           wm_q$nb,\n           wm_q$wt,\n           zero.policy = TRUE,\n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 3.2694, p-value = 0.0005389\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     2.654296e-02     -1.626016e-03      7.423478e-05 \n\n\n\n\n\nwm_q &lt;- wm_q_list[[\"2020\"]]\nglobal_moran_test(wm_q$no_cases,\n           wm_q$nb,\n           wm_q$wt,\n           zero.policy = TRUE,\n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 2.9975, p-value = 0.001361\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     2.444995e-02     -1.626016e-03      7.567537e-05 \n\n\n\n\n\nwm_q &lt;- wm_q_list[[\"2021\"]]\nglobal_moran_test(wm_q$no_cases,\n           wm_q$nb,\n           wm_q$wt,\n           zero.policy = TRUE,\n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 2.6409, p-value = 0.004134\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     2.149092e-02     -1.626016e-03      7.662109e-05 \n\n\n\n\n\nwm_q &lt;- wm_q_list[[\"2022\"]]\nglobal_moran_test(wm_q$no_cases,\n           wm_q$nb,\n           wm_q$wt,\n           zero.policy = TRUE,\n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 1.8315, p-value = 0.03351\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     1.448435e-02     -1.626016e-03      7.737631e-05 \n\n\n\n\n\nFrom the test for the different years, the positive moran’s I statistic suggests that there is clustering, or a degree of spatial autocorrelation. This might be expected as spreading the use of drugs to neighbouring places seems like a common thing to do, if you wanna spread your influence.\nWe can also see that the P-value is small. From a frequentist approach, we can see that this is unlikely to have occured by chance.\nTo strengthen our findings, we run a monte-carlo simulation.\n\n\nGlobal Moran’s I permutation test\n\n201720182019202020212022\n\n\n\nwm_q &lt;- wm_q_list[[\"2017\"]]\nglobal_moran_perm(wm_q$no_cases,\n           wm_q$nb,\n           wm_q$wt,\n           zero.policy = TRUE,\n           nsim = 999,\n           na.action=na.omit)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.039816, observed rank = 998, p-value = 0.004\nalternative hypothesis: two.sided\n\n\n\n\n\nwm_q &lt;- wm_q_list[[\"2018\"]]\nglobal_moran_perm(wm_q$no_cases,\n           wm_q$nb,\n           wm_q$wt,\n           zero.policy = TRUE,\n           nsim = 999,\n           na.action=na.omit)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.029109, observed rank = 999, p-value = 0.002\nalternative hypothesis: two.sided\n\n\n\n\n\nwm_q &lt;- wm_q_list[[\"2019\"]]\nglobal_moran_perm(wm_q$no_cases,\n           wm_q$nb,\n           wm_q$wt,\n           zero.policy = TRUE,\n           nsim = 999,\n           na.action=na.omit)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.026543, observed rank = 997, p-value = 0.006\nalternative hypothesis: two.sided\n\n\n\n\n\nwm_q &lt;- wm_q_list[[\"2020\"]]\nglobal_moran_perm(wm_q$no_cases,\n           wm_q$nb,\n           wm_q$wt,\n           zero.policy = TRUE,\n           nsim = 999,\n           na.action=na.omit)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.02445, observed rank = 985, p-value = 0.03\nalternative hypothesis: two.sided\n\n\n\n\n\nwm_q &lt;- wm_q_list[[\"2021\"]]\nglobal_moran_perm(wm_q$no_cases,\n           wm_q$nb,\n           wm_q$wt,\n           zero.policy = TRUE,\n           nsim = 999,\n           na.action=na.omit)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.021491, observed rank = 986, p-value = 0.028\nalternative hypothesis: two.sided\n\n\n\n\n\nwm_q &lt;- wm_q_list[[\"2022\"]]\nglobal_moran_perm(wm_q$no_cases,\n           wm_q$nb,\n           wm_q$wt,\n           zero.policy = TRUE,\n           nsim = 999,\n           na.action=na.omit)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.014484, observed rank = 954, p-value = 0.092\nalternative hypothesis: two.sided\n\n\n\n\n\nFrom the outputs above, we can observe that the Moran’s I statistic (after 1000 permutations) for the year 2017 0.039816 with a p-value &lt; 2.2e-16, year 2018 0.029109 with a p-value 0.002, year 2019 0.026543 with a p-value 0.006, year 2020 0.02445 with a p-value 0.03, year 2021 0.014484 with a p-value 0.092. All of these are almost identical to the previous result with low p-value which suggest that it did not happen randomly.\nWe can visualise it with a histogram\n\n20172018201920202021\n\n\n\nwm_q &lt;- wm_q_list[[\"2017\"]]\ngmres &lt;-global_moran_perm(wm_q$no_cases,\n                   wm_q$nb,\n                   wm_q$wt,\n                   zero.policy = TRUE,\n                   nsim = 999,\n                   na.action=na.omit)\n\nhist(gmres$res, main=\"Histogram of Global Moran's I Monte-Carlo Simulation 2017\", xlab=\"Monte-Carlo Results\", ylab=\"Frequency\")\n\nabline(v = gmres$statistic, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\nwm_q &lt;- wm_q_list[[\"2018\"]]\ngmres &lt;-global_moran_perm(wm_q$no_cases,\n                   wm_q$nb,\n                   wm_q$wt,\n                   zero.policy = TRUE,\n                   nsim = 999,\n                   na.action=na.omit)\n\nhist(gmres$res, main=\"Histogram of Global Moran's I Monte-Carlo Simulation 2018\", xlab=\"Monte-Carlo Results\", ylab=\"Frequency\")\n\nabline(v = gmres$statistic, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\nwm_q &lt;- wm_q_list[[\"2019\"]]\ngmres &lt;-global_moran_perm(wm_q$no_cases,\n                   wm_q$nb,\n                   wm_q$wt,\n                   zero.policy = TRUE,\n                   nsim = 999,\n                   na.action=na.omit)\n\nhist(gmres$res, main=\"Histogram of Global Moran's I Monte-Carlo Simulation 2019\", xlab=\"Monte-Carlo Results\", ylab=\"Frequency\")\n\nabline(v = gmres$statistic, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\nwm_q &lt;- wm_q_list[[\"2020\"]]\ngmres &lt;-global_moran_perm(wm_q$no_cases,\n                   wm_q$nb,\n                   wm_q$wt,\n                   zero.policy = TRUE,\n                   nsim = 999,\n                   na.action=na.omit)\n\nhist(gmres$res, main=\"Histogram of Global Moran's I Monte-Carlo Simulation 2020\", xlab=\"Monte-Carlo Results\", ylab=\"Frequency\")\n\nabline(v = gmres$statistic, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\nwm_q &lt;- wm_q_list[[\"2021\"]]\ngmres &lt;-global_moran_perm(wm_q$no_cases,\n                   wm_q$nb,\n                   wm_q$wt,\n                   zero.policy = TRUE,\n                   nsim = 999,\n                   na.action=na.omit)\n\nhist(gmres$res, main=\"Histogram of Global Moran's I Monte-Carlo Simulation 2021\", xlab=\"Monte-Carlo Results\", ylab=\"Frequency\")\n\nabline(v = gmres$statistic, col = \"red\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#local-moran-i",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#local-moran-i",
    "title": "Take-Home Exercise 2",
    "section": "Local Moran I",
    "text": "Local Moran I\nLocal Indicators of Spatial Association, or LISA, let us evaluate clusters between provinces. Where higher values denote that the region is more heavily influenced by its surroundings.\n\nCalculating Local Moran I\nCalculating local Moran’s I statistics and append the results to the original dataframe as new columns.\n\nlisa_list &lt;- list()\nfor (year in 2017:2022) {\n  wm_q &lt;- wm_q_list[[as.character(year)]] %&gt;%\n          mutate(local_moran = local_moran(\n            no_cases, nb, wt, nsim = 999, zero.policy=TRUE),\n                 .before = 1) %&gt;%\n          unnest(local_moran)\n  lisa_list[[as.character(year)]] &lt;- wm_q\n  \n}\n\n\n\nVisualising Local Moran I\n\n201720182019202020212022\n\n\n\nlisa &lt;- lisa_list[[\"2017\"]]\nmap1 &lt;- tm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of No of cases\",\n            main.title.size = 0.8)\n\nmap2 &lt;- tm_shape(lisa) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)\n\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\nFrom this map, we can observe statistically significant spatial autocorrelation in some central and central south province and the southern region. In the case of the central region, the significant local Moran’s I statistics tell us that for this province may or may not be a cluster as its quite close to being statistically insignificant or it could be an outlier. However for the central south of Thailand it seems to be statistically significant and the cluster did not happen by choice. Upon further looking at the province Bangkok seems to be one of the areas. The high clustering could be due to it being a tourist spot where they target foreigners which would have the money to buy drugs? But nothing much could be known.\n\nAs for the very south of Thailand it could be outliers which affect the southern Islands as it is surround by statistically insignificant places. And it is not really a widely popular tourist spot, where it could have a market for it.\n\n\n\n\nlisa &lt;- lisa_list[[\"2018\"]]\nmap1 &lt;- tm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of No of cases\",\n            main.title.size = 0.8)\n\nmap2 &lt;- tm_shape(lisa) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)\n\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\nFrom this map, we can observe again that there is statistically significant spatial autocorrelation in central south province and the southern region. In the case of the central south it is the same few provinces which have high statistical significance which shows that the clustering wasn’t random and it is indeed a cluster with high drug cases. Also the central province is not gone, which means that it was indeed an outlier. For the southern province, it seems like the previous few islands were indeed outliers, and now the the remaining province seems to be becoming less statistically insignificant.\n\n\n\nlisa &lt;- lisa_list[[\"2019\"]]\nmap1 &lt;- tm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of No of cases\",\n            main.title.size = 0.8)\n\nmap2 &lt;- tm_shape(lisa) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)\n\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\nLikewise it is the same as for the year 2018, however something to be seen is that the central south province, the p-value seems to be getting higher but is of statistical significance. Could it be that the drug operations are being handled and therefore they have to change the base of operation?\n\n\n\nlisa &lt;- lisa_list[[\"2020\"]]\nmap1 &lt;- tm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of No of cases\",\n            main.title.size = 0.8)\n\nmap2 &lt;- tm_shape(lisa) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)\n\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\nIt seems like the hotspot of clustering of near central south seems to be dispersing, and the outlier of the central province seems to be back. However interesting the southern region seems to be expanding and the clustering seems like its starting to be satistically significant.\n\n\n\nlisa &lt;- lisa_list[[\"2021\"]]\nmap1 &lt;- tm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of No of cases\",\n            main.title.size = 0.8)\n\nmap2 &lt;- tm_shape(lisa) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)\n\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\nThe central south provinces which was a hotspot in 2017-2019 seems to be completely gone and the area which we thought was an outlier in central area. It seems to have spread its fluence suggesting that there might be some clustering happening. However there could be a potential outlier in the far east. Likewise there is still some sort of clustering at the southern region.\n\n\n\nlisa &lt;- lisa_list[[\"2022\"]]\nmap1 &lt;- tm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of No of cases\",\n            main.title.size = 0.8)\n\nmap2 &lt;- tm_shape(lisa) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)\n\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\nFor this year there was complete shift, the previous years clustering seems to be completely gone and it has now been shift to the north-eastern region of Thailand which is rather interesting as there was no prior suggestion that it could happen. Near the western region there is some small clustering happening.\n\n\n\n\n\nLISA\nThe local indicator of spatial association (LISA) for each observation gives an indication of the extent of significant spatial clustering of similar values around that observation. LISA map is a categorical map showing type of outliers and clusters. There are two types of outliers namely: High-Low and Low-High outliers. Likewise, there are two type of clusters namely: High-High and Low-Low cluaters.\n\nHigh-Low Outliers: Provinces with a high value of drug cases, surrounded by neighbouring provinces with low values of drug cases.\nLow-High Outliers: Provinces with a low value of drug cases, surrounded by neighbouring provinces with high values of drug cases.\nHigh-High Clusters: Provinces with a high value of drug cases, surrounded by neighbouring provinces with high values of drug cases.\nLow-Low Clusters: Provinces with a low value of drug cases, surrounded by neighbouring provinces with low values of drug cases.\n\n\nlisa2017_sig &lt;- lisa_list[[\"2017\"]] %&gt;% filter(p_ii_sim &lt; 0.05)\nlisa2018_sig &lt;- lisa_list[[\"2018\"]] %&gt;% filter(p_ii_sim &lt; 0.05)\nlisa2019_sig &lt;- lisa_list[[\"2019\"]] %&gt;% filter(p_ii_sim &lt; 0.05)\nlisa2020_sig &lt;- lisa_list[[\"2020\"]] %&gt;% filter(p_ii_sim &lt; 0.05)\nlisa2021_sig &lt;- lisa_list[[\"2021\"]] %&gt;% filter(p_ii_sim &lt; 0.05)\nlisa2022_sig &lt;- lisa_list[[\"2022\"]] %&gt;% filter(p_ii_sim &lt; 0.05)\n\n\n# Create individual maps\nmap_2017 &lt;- tm_shape(lisa_list[[\"2017\"]]) +\n  tm_polygons() + \n  tm_borders(alpha = 0.5) + \n  tm_shape(lisa2017_sig) + \n  tm_fill(\"mean\", title = \"LISA class\") +\n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"LISA map of drug cases 2017\", main.title.size = 1)\n\nmap_2018 &lt;- tm_shape(lisa_list[[\"2018\"]]) +\n  tm_polygons() + \n  tm_borders(alpha = 0.5) + \n  tm_shape(lisa2018_sig) + \n  tm_fill(\"mean\", title = \"LISA class\") +\n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"LISA map of drug cases 2018\", main.title.size = 1)\n\nmap_2019 &lt;- tm_shape(lisa_list[[\"2019\"]]) +\n  tm_polygons() + \n  tm_borders(alpha = 0.5) + \n  tm_shape(lisa2019_sig) + \n  tm_fill(\"mean\", title = \"LISA class\") +\n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"LISA map of drug cases 2019\", main.title.size = 1)\n\nmap_2020 &lt;- tm_shape(lisa_list[[\"2020\"]]) +\n  tm_polygons() + \n  tm_borders(alpha = 0.5) + \n  tm_shape(lisa2020_sig) + \n  tm_fill(\"mean\", title = \"LISA class\") +\n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"LISA map of drug cases 2020\", main.title.size = 1)\n\nmap_2021 &lt;- tm_shape(lisa_list[[\"2021\"]]) +\n  tm_polygons() + \n  tm_borders(alpha = 0.5) + \n  tm_shape(lisa2021_sig) + \n  tm_fill(\"mean\", title = \"LISA class\") +\n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"LISA map of drug cases 2021\", main.title.size = 1)\n\nmap_2022 &lt;- tm_shape(lisa_list[[\"2022\"]]) +\n  tm_polygons() + \n  tm_borders(alpha = 0.5) + \n  tm_shape(lisa2022_sig) + \n  tm_fill(\"mean\", title = \"LISA class\") +\n  tm_borders(alpha = 0.4) +\n  tm_layout(main.title = \"LISA map of drug cases 2022\", main.title.size = 1)\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntmap_arrange(map_2017, map_2018, map_2019, map_2020, map_2021, map_2022, ncol = 3)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\n\n\n\n\n\nHigh-Low Outliers: Interestingly this only occurs for the year 2017, 2018 and 2020. And are generally found near low-low class\nLow-High Outliers: Most of the province classified under this are situated near the central south of Thailand which is near the tourist area and also the very southern region. And for 2022 its actually in the northern eastern region.\nHigh-High Clusters: There is an absence of any high-high classification, suggest that there are no high-value province surrounded by high-value province\nLow-Low Clusters: Many of the provinces classified here are actually found in the western part of Thailand which is somewhat near the tourist area of Bangkok where there are low-high outliers."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#emerging-hot-spot-analysis",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#emerging-hot-spot-analysis",
    "title": "Take-Home Exercise 2",
    "section": "Emerging Hot Spot Analysis",
    "text": "Emerging Hot Spot Analysis\n\nCalculating the local Gi*\nEmerging hot spot Analysis (EHSA) is a technique that falls under exploratory spatial data analysis (ESDA). It combines the traditional ESDA technique of hot spot analysis using the Getis-Ord Gi* statistic with the traditional time-series Mann-Kendall test for monotonic trends.\nThe goal of EHSA is to evaluate how hot and cold spots are changing over time. It helps us answer the questions: are they becoming increasingly hotter, are they cooling down, or are they staying the same?\nIn brief, EHSA works by calculating the Gi* for each time period. The series of Gi* at each location is treated as a time-series and evaluated for a trend using the Mann-Kendall statistic. The Gi* and the Mann-Kendall are compared together to create 17 unique classifications to help better understand how the locations have changed over time.\nFirst we create a neighbor list ensuring that the self is included and then create the weights list from the new neighbors list. Let’s do this for the year 2017 only\n\nwm_idw_2017 &lt;- drug[[\"2017\"]] %&gt;%\n    mutate(nb = include_self(st_contiguity(geometry)),\n           wt = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1),\n           .before = 1)\n\nBefore we forget let’s write the wm_idw_2017 into an rds file for faster access\n\nwrite_rds(wm_idw_2017, \"data/rds/wm_idw_2017.rds\")\n\nFollowing, we calculate the local Gi* using local_gstar_perm() on the no_cases column which creates a new data frame column called gi_star. We then unnest it using tidyr::unnest().\n\ncases_gistar_2017 &lt;- wm_idw_2017 %&gt;% \n  transmute(gi_star = local_gstar_perm(no_cases, nb, wt, nsim = 199)) %&gt;% \n  tidyr::unnest(gi_star)\n\nLastly, we classify the clusters using a combination of mutate() and case_when() which is then piped into a ggplot map. While not a perfect recreation of the GeoDa map, it is very close—the differences likely due to conditional permutation (see conditional permutation vignette for more on significance calculation).\n\ncases_gistar_2017 %&gt;% \n  mutate(cluster = case_when(\n    p_folded_sim &gt; 0.05 ~ \"Not Significant\",\n    p_folded_sim &lt;= 0.05 & gi_star &lt; 0 ~ \"Low\",\n    p_folded_sim &lt;= 0.05 & gi_star &gt; 0 ~ \"High\"\n  )) |&gt; \n  ggplot(aes(fill = cluster)) +\n  geom_sf(lwd = 0.2, color = \"black\") +\n  scale_fill_manual(values = c(\"High\" = \"red\",\n                               \"Low\" = \"Blue\", \n                               \"Not Significant\" = \"white\")) +\n  theme_void()\n\n\n\n\n\n\n\n\nIndeed the High cluster and low cluster is similar to what we see in our LISA map.\n\n\nPerforming Emerging Hot Spot Analysis\nWhile we can do the calculations manually as above, this is limited in two ways. Primarily that in the above example we used spatial neighbors only. Whereas in EHSA we can—and likely should—incorporate the time-lag of our spatial neighbors. Secondly, there are classifications proposed by ESRI which help us understand how each location is changing over time. Both of these are handled by the emerging_hotspot_analysis() function.\nThis emerging_hotspot_analysis() takes a spacetime object x, and the quoted name of the variable of interested in .var at minimum. We can specify the number of time lags using the argument k which is set to 1 by default.\nFor this let’s create a st_data without the geometry and only doing it for the drug_use cases\n\ndrug_offenses &lt;- c(\n  \"drug_use_cases\"\n)\n\nthai_df &lt;- thai %&gt;% filter(types_of_drug_offenses %in% drug_offenses )\nthai_df &lt;- thai_df %&gt;%\n  select(fiscal_year, no_cases, ADM1_EN) %&gt;%\n  st_drop_geometry()\n\nNext is to create a spacetime object\n\nthai_spt &lt;- spacetime(thai_df, thai_sf,\n                 .loc_col = \"ADM1_EN\",\n                 .time_col = \"fiscal_year\")\n\nLet’s check if it is indeed a spacetime object\n\nis_spacetime_cube(thai_spt)\n\n[1] TRUE\n\n\nLastly, we will perform EHSA analysis by using emerging_hotspot_analysis() of sfdep package. It takes a spacetime object thai_spt, and the name of the variable of interest no_cases for .var argument.\n\nehsa &lt;- emerging_hotspot_analysis(\n  x = thai_spt, \n  .var = \"no_cases\", \n  k = 1, \n  nsim = 99\n)\n\nWarning in spdep::poly2nb(geometry, queen = queen, ...): some observations have no neighbours;\nif this seems unexpected, try increasing the snap argument.\n\n\nWarning in spdep::poly2nb(geometry, queen = queen, ...): neighbour object has 2 sub-graphs;\nif this sub-graph count seems unexpected, try increasing the snap argument.\n\n\nWe can then join them together\n\nehsa_sf &lt;- left_join(thai_sf, ehsa, by = c(\"ADM1_EN\" = \"location\"))\n\n\n\nVisualising Distribution of EHSA\nWe can use a bar graph to show the distribution of the EHSA class\n\nggplot(data = ehsa,\n       aes(y = classification,fill = classification)) +\n  geom_bar(show.legend = FALSE)\n\n\n\n\n\n\n\n\nThere are a total of 5 distinct hotspot and coldspot classes. For hotspot we have sporadic hotspot, oscilating hotspot, new hotspot. For cold we have sporadic coldspot, new coldspot.\n\n\nPlotting of Tau, Classification and p-value\n\ne_p &lt;- tm_shape(ehsa_sf) +\n  tm_fill(\"p_value\", palette = \"Purples\") + \n  tm_borders(alpha=0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"EHSA p-value\", main.title.size = 1)\n\ne_c &lt;- tm_shape(ehsa_sf) +\n  tm_fill(\"classification\", palette = \"Spectral\") + \n  tm_borders(alpha=0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"EHSA Classification\", main.title.size = 1)\n\ne_t &lt;- tm_shape(ehsa_sf) +\n  tm_fill(\"tau\") + \n  tm_borders(alpha=0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"EHSA tau-value\", main.title.size = 1)\n\ntmap_arrange(e_t, e_c, e_p, ncol = 3)\n\nVariable(s) \"tau\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\nLegend labels were too wide. The labels have been resized to 0.41, 0.61, 0.66, 0.42, 0.46, 0.46, 0.49. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\n\n\n\n\n\n\n\n\n\n\n\nPlotting emerging Hotspot and Coldspot\n\nehsa_sf_cold &lt;- ehsa_sf %&gt;% filter(classification %in% c(\"sporadic coldspot\",\"new coldspot\"))\n\nehsa_sf_hot &lt;- ehsa_sf %&gt;% filter(classification %in% c(\"sporadic hotspot\",\"oscilating hotspot\", \"new hotspot\"))\n\n\n\nEmerging Hotspots of Drug Use Cases\n\ntmap_mode(\"plot\")  \n\ntmap mode set to plotting\n\ntm_shape(ehsa_sf)+\n  tm_polygons()+\n  tm_borders(col = \"black\", alpha = 0.6)+\ntm_shape(ehsa_sf_hot)+\n  tm_fill(\"classification\", \n          palette = c(\"#de573e\",\"#f67774\",\"#f8b675\",\"#f8d673\"),\n          title = \"classification\",\n          midpoint = 0) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Emerging Hotspots of Drug Cases\") +\n  tm_borders(alpha = 0.5) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\nSome legend labels were too wide. These labels have been resized to 0.47, 0.50. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\n\n\n\n\n\n\n\n\n\n\n\nEmerging Coldspots of Drug Use Cases\n\ntmap_mode(\"plot\")  \n\ntmap mode set to plotting\n\ntm_shape(ehsa_sf)+\n  tm_polygons()+\n  tm_borders(col = \"black\", alpha = 0.6)+\ntm_shape(ehsa_sf_cold)+\n  tm_fill(\"classification\", \n          palette = c(\"#57bfc0\",\"#7977f3\"),\n          title = \"classification\",\n          midpoint = 0) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Emerging Coldspots of Drug Cases\") +\n  tm_borders(alpha = 0.5) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\nLegend labels were too wide. The labels have been resized to 0.62, 0.47. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\n\n\n\n\n\n\n\n\n\nAlthough it is not a 1 to 1 comparison of the data we have as we only did drug_use_cases here. It does give some insight to the potential provinces which could have high value of drug_use_cases that could potential influence neighbouring provinces to have a high value. It also give provinces with low value of drug_use_cases, which may or may not influence nearby provinces or just disappear altogether"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#conclusion",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#conclusion",
    "title": "Take-Home Exercise 2",
    "section": "Conclusion",
    "text": "Conclusion\nThis take home exercise has taught me about spatial autocorrelation and how although something looks one way. The values calculated could mean some sort statistical significance. This take home also taught me how to be cautious and that the data set provided only is not always ready to use when downloaded shown by the spelling error.\nAs for the actual data itself, it shows that there are certain hotspots for the drug abuses and how it affects neighbouring provinces. But it also does not necessarily stay there throughout for all 6 years but it shifts around. This could be that they are trying to avoid the police and trying to relocate so that they are harder to track but who knows. However it is still unclear on how the drug cases arise as the provinces that it appears on is rather random. As seen from the provinces that drug cases arises from 2020-2022"
  }
]