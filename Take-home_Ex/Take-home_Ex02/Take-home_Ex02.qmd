---
title: "Take-Home Exercise 2"
author: "Kwee Cheng"
date: "September 25, 2024"
date-modified: "last-modified"
execute: 
  eval: true
  echo: true
  freeze: true
categories: [Take-Home, Code]
---

## Background

Drug abuse is associated with significant negative health, financial and social consequences. Yet, illicit drug consumption remains highly prevalent and continues to be a growing problem worldwide. In 2021, 1 in 17 people aged 15–64 in the world had used a drug in the past 12 months. Notwithstanding population growth, the estimated number of drug users grew from 240 million in 2011 to 296 million in 2021.

The geopolitics of Thailand which is near the [Golden Triangle](https://en.wikipedia.org/wiki/Golden_Triangle_(Southeast_Asia)) of Indochina, the largest drug production site in Asia, and the constant transportation infrastructure development made Thailand became market and transit routes for drug trafficking to the third countries.

In Thailand, drug abuse is one of the major social issue. There are about 2.7 million youths using drugs in Thailand. Among youths aged between 15 and 19 years, there are about 300,000 who have needs for drug treatment. Most of Thai youths involved with drugs are vocational-school students, which nearly doubles in number compared to secondary-school students.

## Objectives

-   If the key indicators of drug abuse of Thailand are independent from space.

-   If the indicators of drug abuse is indeed spatial dependent, then, you would like to detect where are the clusters and outliers, and the hotspots.

-   Last but not least, you are also interested to investigate how the observation above evolve over time.

## Dataset

-   [Thailand Drug Offenses \[2017-2022\]](https://www.kaggle.com/datasets/thaweewatboy/thailand-drug-offenses-2017-2022) at Kaggle.

-   [Thailand - Subnational Administrative Boundaries](https://data.humdata.org/dataset/cod-ab-tha?) at HDX. You are required to use the province boundary data set.

## Packages

-   **sf** provides a standardised way to work with spatial vector data (points, lines, polygons)

-   **spdep** focuses on spatial econometrics and spatial statistics

-   **tmap** create thematic maps

-   **tidyverse** for easy data manipulation and some visualisation

-   **knitr** facilitates the integration of R code and documentation in reproducible research reports

```{r}
pacman::p_load(sf, sfdep, tmap, tidyverse, knitr)
```

## **Importing data**

Let's load the csv file from kaggle about Thailand's drug offenses

```{r}
thai_drug <- read_csv("data/thai_drug_offenses_2017_2022.csv")
```

```{r}
set.seed(2932)
```

```{r}
class(thai_drug)
```

Next let's load the shapefile of Thailand's province boundary

```{r}
thai_sf <- st_read(dsn = "data/", 
                 layer = "tha_admbnda_adm1_rtsd_20220121")
```

```{r}
thai_sf
```

## Data Wrangling

### Misspelled province

I would like to perform a left join on province_en of *thai_drug* and ADM1_EN of *thai_sf*, so I would have to check if there are any missing data or mismatch

```{r}
combined_data <- bind_cols(thai_drug = sort(unique(thai_drug$province_en)), thai_sf = sort(unique(thai_sf$ADM1_EN)))

# Create a new column to compare the values
combined_data <- combined_data %>%
  mutate(same_values = thai_drug == thai_sf) %>% filter(same_values == FALSE)

# View the result
combined_data
```

From here we can see that there is a mismatch in the data where there are spelling errors from the data provided kaggle so lets change it.

```{r}
thai_drug <- thai_drug %>%
  mutate(province_en = recode(province_en,
                              "buogkan" = "Bueng Kan",
                              "Loburi" = "Lop Buri"))
```

Let's check if there is any mismatch again

```{r}
combined_data <- bind_cols(thai_drug = sort(unique(thai_drug$province_en)), thai_sf = sort(unique(thai_sf$ADM1_EN)))


combined_data <- combined_data %>%
  mutate(same_values = thai_drug == thai_sf) %>% filter(same_values == FALSE)


combined_data
```

### CRS check

Let's check the crs of the Thai boundary file

```{r}
st_crs(thai_sf)
```

Let's convert it into the projected coordinate system of 32647

```{r}
thai_sf <- thai_sf %>% st_transform(crs = 32647)
st_crs(thai_sf)
```

### Hole in boundary file

Next check is there any holes with the boundary file

```{r}
u_thai <- st_union(thai_sf)
plot(u_thai)
```

### Missing row check

Lastly check for the drug abuse csv if there are any missing rows

```{r}
na <- thai_drug %>%
  summarise(na_year = sum(is.na(fiscal_year)),
            na_province = sum(is.na(province_en)),
            na_drug_offense = sum(is.na(types_of_drug_offenses)),
            na_cases = sum(is.na(no_cases)))
print(na)
```

### Left Join

Great now let's left join both the boundary file and the csv

```{r}
thai <- left_join(thai_sf,thai_drug, by = c("ADM1_EN" = "province_en")) %>%
        select(1:3, 17:19,21)
```

As the combined file is quite huge let's see how we can split it even more, let's choose the only relevant type of drug offenses

```{r}
unique(thai$types_of_drug_offenses)
```

Let's choose everything but the suspects because suspects are not really confirmed in the cases but it could provide some supplementary.

```{r}
drug_offenses <- c(
  "drug_use_cases", "possession_cases", "possession_with_intent_to_distribute_cases", "trafficking_cases", "production_cases", "import_cases", "export_cases", "conspiracy_cases"
)
thai <- thai %>% filter(types_of_drug_offenses %in% drug_offenses )
```

Next let's split it up by the years

```{r}
drug <- list()
for (year in 2017:2022) {
  drug[[as.character(year)]] <- thai %>% filter(fiscal_year == year)
}

glimpse(drug[["2017"]])
```

### Simple Visualisations

Let's just do a simple visualisation of the drug uses in the year 2017 to see what we are dealing with

```{r}
qtm(drug[["2017"]], "no_cases")
```

## **Global Measures of Spatial Autocorrelation**

### **Calculating Neighbours and Weights**

I would be defining neighbour's based on Queens contiguity, and also let's assign spatial weights to each neighbouring polygon

```{r}
#| eval: false
wm_q_list <- list()
for (year in 2017:2022) {
  wm_q <- drug[[as.character(year)]] %>%
    mutate(nb = st_contiguity((.), queen=TRUE),
           wt = st_weights(nb, style = "W",allow_zero=TRUE),
           .before = 1)
  wm_q_list[[as.character(year)]] <- wm_q
  
}
```

As this takes a lot of time lets save this list into a rds file

```{r}
#| eval: false
write_rds(wm_q_list, "data/rds/wm_q_list.rds")
```

```{r}
#| echo: false
wm_q_list <- read_rds("data/rds/wm_q_list.rds")
```

### **Global Moran’s I Test**

::: panel-tabset
### 2017

```{r}
wm_q <- wm_q_list[["2017"]]
global_moran_test(wm_q$no_cases,
           wm_q$nb,
           wm_q$wt,
           zero.policy = TRUE,
           na.action=na.omit)
```

### 2018

```{r}
wm_q <- wm_q_list[["2018"]]
global_moran_test(wm_q$no_cases,
           wm_q$nb,
           wm_q$wt,
           zero.policy = TRUE,
           na.action = na.omit)
```

### 2019

```{r}
wm_q <- wm_q_list[["2019"]]
global_moran_test(wm_q$no_cases,
           wm_q$nb,
           wm_q$wt,
           zero.policy = TRUE,
           na.action=na.omit)
```

### 2020

```{r}
wm_q <- wm_q_list[["2020"]]
global_moran_test(wm_q$no_cases,
           wm_q$nb,
           wm_q$wt,
           zero.policy = TRUE,
           na.action=na.omit)
```

### 2021

```{r}
wm_q <- wm_q_list[["2021"]]
global_moran_test(wm_q$no_cases,
           wm_q$nb,
           wm_q$wt,
           zero.policy = TRUE,
           na.action=na.omit)
```

### 2022

```{r}
wm_q <- wm_q_list[["2022"]]
global_moran_test(wm_q$no_cases,
           wm_q$nb,
           wm_q$wt,
           zero.policy = TRUE,
           na.action=na.omit)
```
:::

### **Global Moran’s** I permutation test

::: panel-tabset
### 2017

```{r}
wm_q <- wm_q_list[["2017"]]
gmres <-global_moran_perm(wm_q$no_cases,
                   wm_q$nb,
                   wm_q$wt,
                   zero.policy = TRUE,
                   nsim = 999,
                   na.action=na.omit)
```

**Visualising Monte Carlo Moran’s I**

```{r}
gmres
summary(gmres$res[1:999])
```

### 2018

```{r}
wm_q <- wm_q_list[["2018"]]
global_moran_perm(wm_q$no_cases,
           wm_q$nb,
           wm_q$wt,
           zero.policy = TRUE,
           nsim = 999,
           na.action=na.omit)
```

### 2019

```{r}
wm_q <- wm_q_list[["2019"]]
global_moran_perm(wm_q$no_cases,
           wm_q$nb,
           wm_q$wt,
           zero.policy = TRUE,
           nsim = 999,
           na.action=na.omit)
```

### 2020

```{r}
wm_q <- wm_q_list[["2020"]]
global_moran_perm(wm_q$no_cases,
           wm_q$nb,
           wm_q$wt,
           zero.policy = TRUE,
           nsim = 999,
           na.action=na.omit)
```

### 2021

```{r}
wm_q <- wm_q_list[["2021"]]
global_moran_perm(wm_q$no_cases,
           wm_q$nb,
           wm_q$wt,
           zero.policy = TRUE,
           nsim = 999,
           na.action=na.omit)
```

### 2022

```{r}
wm_q <- wm_q_list[["2022"]]
global_moran_perm(wm_q$no_cases,
           wm_q$nb,
           wm_q$wt,
           zero.policy = TRUE,
           nsim = 999,
           na.action=na.omit)
```
:::

## Local Moran I

### Calculating Local Moran I

```{r}
lisa_list <- list()
for (year in 2017:2022) {
  wm_q <- wm_q_list[[as.character(year)]] %>%
          mutate(local_moran = local_moran(
            no_cases, nb, wt, nsim = 999, zero.policy=TRUE),
                 .before = 1) %>%
          unnest(local_moran)
  lisa_list[[as.character(year)]] <- wm_q
  
}
```

### Visualising Local Moran I

::: panel-tabset
### 2017

```{r}
lisa <- lisa_list[["2017"]]
map1 <- tm_shape(lisa) +
  tm_fill("ii") + 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "local Moran's I of No of cases",
            main.title.size = 0.8)

map2 <- tm_shape(lisa) +
  tm_fill("p_ii",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "p-value of local Moran's I",
            main.title.size = 0.8)

tmap_arrange(map1, map2, ncol = 2)
```

### 2018

```{r}
lisa <- lisa_list[["2018"]]
map1 <- tm_shape(lisa) +
  tm_fill("ii") + 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "local Moran's I of No of cases",
            main.title.size = 0.8)

map2 <- tm_shape(lisa) +
  tm_fill("p_ii",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "p-value of local Moran's I",
            main.title.size = 0.8)

tmap_arrange(map1, map2, ncol = 2)
```

### 2019

```{r}
lisa <- lisa_list[["2019"]]
map1 <- tm_shape(lisa) +
  tm_fill("ii") + 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "local Moran's I of No of cases",
            main.title.size = 0.8)

map2 <- tm_shape(lisa) +
  tm_fill("p_ii",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "p-value of local Moran's I",
            main.title.size = 0.8)

tmap_arrange(map1, map2, ncol = 2)
```

### 2020

```{r}
lisa <- lisa_list[["2020"]]
map1 <- tm_shape(lisa) +
  tm_fill("ii") + 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "local Moran's I of No of cases",
            main.title.size = 0.8)

map2 <- tm_shape(lisa) +
  tm_fill("p_ii",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "p-value of local Moran's I",
            main.title.size = 0.8)

tmap_arrange(map1, map2, ncol = 2)
```

### 2021

```{r}
lisa <- lisa_list[["2021"]]
map1 <- tm_shape(lisa) +
  tm_fill("ii") + 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "local Moran's I of No of cases",
            main.title.size = 0.8)

map2 <- tm_shape(lisa) +
  tm_fill("p_ii",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "p-value of local Moran's I",
            main.title.size = 0.8)

tmap_arrange(map1, map2, ncol = 2)
```

### 2022

```{r}
lisa <- lisa_list[["2022"]]
map1 <- tm_shape(lisa) +
  tm_fill("ii") + 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "local Moran's I of No of cases",
            main.title.size = 0.8)

map2 <- tm_shape(lisa) +
  tm_fill("p_ii",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "p-value of local Moran's I",
            main.title.size = 0.8)

tmap_arrange(map1, map2, ncol = 2)
```
:::
